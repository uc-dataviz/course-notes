[{"path":"index.html","id":"syllabus","chapter":"Syllabus","heading":"Syllabus","text":"","code":""},{"path":"index.html","id":"contact-information","chapter":"Syllabus","heading":"Contact information","text":"","code":""},{"path":"index.html","id":"course-description","chapter":"Syllabus","heading":"Course description","text":"Social scientists frequently wish convey information broader audience cohesive interpretable manner. Visualizations excellent method summarize information report analysis conclusions compelling format. course introduces theory applications data visualization. Students learn techniques methods developing rich, informative interactive, web-facing visualizations based principles graphic design perceptual psychology. Students practice techniques many types social science data, including multivariate, temporal, geospatial, text, hierarchical, network data. techniques developed using variety software implementations R, ggplot2, D3, Tableau.","code":""},{"path":"index.html","id":"prerequisites","chapter":"Syllabus","heading":"Prerequisites","text":"MACS 30500 equivalent programming course R. Prior experience ggplot2 expected.","code":""},{"path":"index.html","id":"course-schedule","chapter":"Syllabus","heading":"Course schedule","text":"Welcome courseGrammar graphicsLooking dataDeep dive: geomsDeep dive: stats + scales + guidesDeep dive: coordinate systems + faceting + themesOptimizing color spaces?Deep dive: axes annotationPresentation ready plotsVisualizing time series dataVisualizing geospatial data IVisualizing geospatial data IIVisualizing text network data?AnimationShiny IShiny IITablesAccessibility","code":""},{"path":"index.html","id":"what-do-i-need-for-this-course","chapter":"Syllabus","heading":"What do I need for this course?","text":"Class sessions mix lecture, demonstration, live coding. essential computer can follow along complete exercises. course starts, install following software computer:R - easiest approach select pre-compiled binary appropriate operating system.RStudio IDE - powerful user interface programming R. use base R, regret .Git - Git version control system used manage projects track changes computer files. installed, can integrated RStudio manage course assignments projects.Comprehensive instructions downloading setting software can found .readings (e.g., papers, book chapters) open source, either links citations provided.","code":""},{"path":"index.html","id":"how-will-i-be-evaluated","chapter":"Syllabus","heading":"How will I be evaluated?","text":"TBD","code":""},{"path":"index.html","id":"statement-on-disabilities","chapter":"Syllabus","heading":"Statement on Disabilities","text":"University Chicago committed diversity rigorous inquiry multiple perspectives. MAPSS, CIR, Computation programs share commitment seek foster productive learning environments based upon inclusion, open communication, mutual respect diverse range identities, experiences, positions.course open students meet academic requirements participation. student documented need accommodation contact Student Disability Services (773-702-6000 disabilities@uchicago.edu) provide us (Dr. Soltoff Dr. Waggoner) copy Accommodation Determination Letter soon possible.","code":""},{"path":"intro-data-viz.html","id":"intro-data-viz","chapter":"Day 1 Introduction to data visualization","heading":"Day 1 Introduction to data visualization","text":"","code":""},{"path":"intro-data-viz.html","id":"learning-objectives","chapter":"Day 1 Introduction to data visualization","heading":"Learning objectives","text":"","code":""},{"path":"intro-data-viz.html","id":"morning","chapter":"Day 1 Introduction to data visualization","heading":"1.0.1 Morning","text":"Introduce myselfIdentify major course objectivesReview purpose data visualizationsExamine perception cognition influence interpretation data visualizationsAssess several historic visualizations strengths weaknesses","code":""},{"path":"intro-data-viz.html","id":"afternoon","chapter":"Day 1 Introduction to data visualization","heading":"1.0.2 Afternoon","text":"Review grammar graphics ggplot2Generate clean, interpretable visualizations","code":""},{"path":"intro-data-viz.html","id":"assigned-readings","chapter":"Day 1 Introduction to data visualization","heading":"Assigned readings","text":"Chapters 1-3, Healy (2018) - accessible via book’s websiteChapter 2, Cairo (2016) - accessible via electronic course reserve","code":""},{"path":"intro-data-viz.html","id":"why-visualize-data","chapter":"Day 1 Introduction to data visualization","heading":"1.1 Why visualize data?","text":"Research methods classes graduate school generally teach important skills probability statistical theory, regression, analysis variance (ANOVA), maximum likelihood estimation (MLE), etc. important methods analyzing data assessing research questions, sometimes drawing picture (aka visualization) can precise conventional statistical computations.1","code":""},{"path":"intro-data-viz.html","id":"anscombes-quartet","chapter":"Day 1 Introduction to data visualization","heading":"1.1.1 Anscombe’s quartet","text":"","code":""},{"path":"intro-data-viz.html","id":"datasaurus-dozen","chapter":"Day 1 Introduction to data visualization","heading":"1.1.2 Datasaurus dozen","text":"Remarkably datasets summary statistics linear relationships, yet drastically different appearance! good picture tells reader much table text can provide.","code":""},{"path":"intro-data-viz.html","id":"outliers","chapter":"Day 1 Introduction to data visualization","heading":"1.1.3 Outliers","text":"","code":""},{"path":"intro-data-viz.html","id":"what-makes-visualizations-bad","chapter":"Day 1 Introduction to data visualization","heading":"1.2 What makes visualizations bad","text":"","code":""},{"path":"intro-data-viz.html","id":"lies","chapter":"Day 1 Introduction to data visualization","heading":"1.2.1 Lies","text":"","code":""},{"path":"intro-data-viz.html","id":"dual-axes","chapter":"Day 1 Introduction to data visualization","heading":"1.2.2 Dual axes","text":"","code":""},{"path":"intro-data-viz.html","id":"lacking-functionality","chapter":"Day 1 Introduction to data visualization","heading":"1.2.3 Lacking functionality","text":"","code":""},{"path":"intro-data-viz.html","id":"junky","chapter":"Day 1 Introduction to data visualization","heading":"1.2.4 Junky","text":"","code":""},{"path":"intro-data-viz.html","id":"purpose-of-visualizations","chapter":"Day 1 Introduction to data visualization","heading":"1.3 Purpose of visualizations","text":"visualization “kind visual representation information designed enable communication, analysis, discovery, exploration, etc.”2 However seek communicate can vary widely depending goals, therefore effects type visualization design.","code":""},{"path":"intro-data-viz.html","id":"statistical-graphics","chapter":"Day 1 Introduction to data visualization","heading":"1.3.1 Statistical graphics","text":"Statistical graphics seek visualize abstract data typically quantitative form. goal convey data accurately reveal underlying structure, generally explorative interactive may always yield aesthetically pleasing form.","code":""},{"path":"intro-data-viz.html","id":"examples","chapter":"Day 1 Introduction to data visualization","heading":"1.3.1.1 Examples","text":"","code":""},{"path":"intro-data-viz.html","id":"double-time-bar-charts","chapter":"Day 1 Introduction to data visualization","heading":"1.3.1.1.1 Double-time bar charts","text":"\nFigure 1.1: Double-time bar chart crime city San Francisco, 2009-10. Source: Visualizing Time Double-Time Bar Chart\nset 24 bars show data. top bars run midnight 11pm. bottom bars run noon 11am.Highlighted regions represent 6-5 (6am-5pm; 6pm-5am)Colors represent (roughly) day night (yellow day, blue night)Enables representing trends 24 hour period without breaking arbitrarily midnight\nFigure 1.2: Double-time bar chart crime city San Francisco, 2009-10. Source: Visualizing Time Double-Time Bar Chart\nCompare different categories crimes using small multiples (aka facets ggplot2 language)","code":""},{"path":"intro-data-viz.html","id":"information-dashboards","chapter":"Day 1 Introduction to data visualization","heading":"1.3.2 Information dashboards","text":"Information dashboards popular business industry. visualize abstract data, frequently (though always) time. goal convey large amounts information quickly identify outliers trends. downside can become extremely dense.","code":""},{"path":"intro-data-viz.html","id":"examples-1","chapter":"Day 1 Introduction to data visualization","heading":"1.3.2.1 Examples","text":"COVID-19 United States Cases CountyCalifornia COVID Assessment Tool - built Shiny!","code":""},{"path":"intro-data-viz.html","id":"infographics","chapter":"Day 1 Introduction to data visualization","heading":"1.3.3 Infographics","text":"Infographics depict abstract data effort eye-catching capture attention, convey information quickly. Unfortunately frequently accurate, use space efficiently, may encourage exploration data.","code":""},{"path":"intro-data-viz.html","id":"examples-2","chapter":"Day 1 Introduction to data visualization","heading":"1.3.3.1 Examples","text":"\nFigure 1.3: Extremely sexual sun stroking. Source: top 10 worst infographics ever created\n\nFigure 1.4: Source: 11 Useless Misleading Infographics Internet\n\nFigure 1.5: Source: WTF Visualizations\n","code":""},{"path":"intro-data-viz.html","id":"informative-art","chapter":"Day 1 Introduction to data visualization","heading":"1.3.4 Informative art","text":"Informative art visualizes abstract data effort make visualization ambient part everyday life. goal aesthetically please audience, informative.","code":""},{"path":"intro-data-viz.html","id":"examples-3","chapter":"Day 1 Introduction to data visualization","heading":"1.3.4.1 Examples","text":"Debussy, Clair de lune (piano music)","code":""},{"path":"intro-data-viz.html","id":"what-makes-a-good-visualization","chapter":"Day 1 Introduction to data visualization","heading":"1.4 What makes a good visualization","text":"","code":""},{"path":"intro-data-viz.html","id":"dr.-john-snow-and-cholera-outbreak-in-london","chapter":"Day 1 Introduction to data visualization","heading":"1.4.1 Dr. John Snow and cholera outbreak in London","text":"\nFigure 1.6: Original map made John Snow 1854. Cholera cases highlighted black. Source: Wikipedia.\npoint time theory bacteria widely accepted medical community public.3 mother washed baby’s diaper well 1854 London, sparking outbreak cholera, intestinal disease causes vomiting, diarrhea, eventually death. disease presented previously London cause still unknown. Dr. John Snow lived Soho, suburb London disease manifested 1854, wanted understand cholera spreads population (early day epidemiologist). Snow recorded location individuals contracted cholera, including places residence employment. used information draw map region, recording location individuals contracted disease. seemed clustered around well pump along Broad Street. Snow used map deduce source outbreak well, along way ruling causes noting individuals lived area contract cholera, identifying individuals drink well. Based information, government removed handle well pump public draw water . result, cholera epidemic ended.makes good visualization?One earliest examples statistical visualizations","code":""},{"path":"intro-data-viz.html","id":"minards-map-of-napoleons-march-on-russia","chapter":"Day 1 Introduction to data visualization","heading":"1.4.2 Minard’s map of Napoleon’s march on Russia","text":"\nFigure 1.7: Charles Minard’s 1869 chart showing number men Napoleon’s 1812 Russian campaign army, movements, well temperature encountered return path. Source: Wikipedia.\n\nFigure 1.8: English translation Minard’s map. Source: Wikipedia.\nillustration identifed Edward Tufte’s Visual Display Quantitative Information one “best statistical drawings ever created”.4 also demonstrates important rule warfare: never invade Russia winter. 1812, Napoleon ruled Europe. wanted seize control British islands, overcome UK defenses. decides impose embargo weaken nation preparation invasion, Russia refused participate. Angered decision, Napoleon launched invasion Russia 400,000 troops summer 1812. Russia unable defeat Napoleon battle, instead waged war attrition. Russian army near constant retreat, burning destroying anything value along way deny France usable resources. Napoleon’s army maintained military advantage, lack food emerging European winter decimated forces. left France army approximately 422,000 soldiers; returned France just 10,000.Charles Minard’s map stunning achievement era. incorporates data across six dimensions tell story Napoleon’s failure. graph depicts:Size armyLocation two-dimensions (latitude longitude)Direction army’s movementTemperature dates Napoleon’s retreatWhat makes effective visualization?5Forces visual comparisons (colored bands advancing retreating)Shows causality (temperature chart)Captures multivariate complexityIntegrates text graphic coherent whole (perhaps first infographic, done well!)Illustrates high quality content (based reliable data)Places comparisons adjacent (page, jumping back forth pages)Mimimalistic nature (avoids later term “chart junk”)Data maps one first data visualizations, though took thousands years first cartographic maps data maps came together.","code":""},{"path":"intro-data-viz.html","id":"perception-and-data-visualization","chapter":"Day 1 Introduction to data visualization","heading":"1.5 Perception and data visualization","text":"Driven scienceLots learn , don’t time week dive deep!Important remember human perception cognition process - design visualizations remembering factWork simplify perception story clear easy tell","code":""},{"path":"intro-data-viz.html","id":"visual-tasks-and-decoding-graphs","chapter":"Day 1 Introduction to data visualization","heading":"1.5.1 Visual tasks and decoding graphs","text":"graphical form involves elementary perceptual tasks lead accurate judgments another graphical form (quantitiative information) result better organization increase chances correct perception patterns behavior.\nFigure 1.9: Figure 1.22 Healy (2018)\n\nFigure 1.10: Figure 1.23 Healy (2018)\n","code":""},{"path":"intro-data-viz.html","id":"channels-and-decoding-information","chapter":"Day 1 Introduction to data visualization","heading":"1.5.2 Channels and decoding information","text":"\nFigure 1.11: Figure 1.24 Healy (2018)\n\nFigure 1.12: Figure 1.26 Healy (2018)\n","code":""},{"path":"intro-data-viz.html","id":"example-of-decoding-information","chapter":"Day 1 Introduction to data visualization","heading":"1.5.3 Example of decoding information","text":"","code":""},{"path":"intro-data-viz.html","id":"bar-chart-vs.-pie-chart","chapter":"Day 1 Introduction to data visualization","heading":"1.5.3.1 Bar chart vs. pie chart","text":"","code":""},{"path":"intro-data-viz.html","id":"choropleths","chapter":"Day 1 Introduction to data visualization","heading":"1.5.4 Choropleths","text":"","code":""},{"path":"intro-data-viz.html","id":"identifying-appropriate-graphical-forms","chapter":"Day 1 Introduction to data visualization","heading":"1.6 Identifying appropriate graphical forms","text":"learn elementary perceptual tasks channels better others, choosing appropriate graphical forms become complex carefully consider specific marks channels used communicate data. , identify high-level suggestions follow determining appropriate graphical form consider several basic types charts appropriate use cases.","code":""},{"path":"intro-data-viz.html","id":"cairos-truthful-art-suggested-approach","chapter":"Day 1 Introduction to data visualization","heading":"1.6.1 Cairo’s Truthful Art suggested approach","text":"Think task tasks want enableTry different graphic formsArrange components graphicTest outcomesThese suggestions bit vague, really like last one: test outcomes.6 Something appears intuitive may appear way different audience. Especially context statistical graphics presenting academic results, become steeped data much assume everyone else lots background knowledge dataset. However possess knowledge: ’s ’re reading visualization.","code":""},{"path":"intro-data-viz.html","id":"what-is-the-story","chapter":"Day 1 Introduction to data visualization","heading":"1.6.2 What is the story?","text":"Another Cairo’s suggestions really useful: story want tell?\nFigure 1.13: Source: Cairo (2016)\nConsider bottom two graphs: better graph? Well, depends. goal Piketty’s, want compare Europe rest continents. stacked area chart accomplishes goal just fine placing Europe bottom, sitting baseline. However goal compare continents one another, graph good job. Making comparisons Africa America difficult baselines dependent Europe’s GDP percentage. Instead, ’d rather continents start baseline enable easy comparisons, non-stacked grouped line chart accomplishes. Depending story, want choose graph/chart type best tells story.","code":""},{"path":"intro-data-viz.html","id":"grammar-of-graphics","chapter":"Day 1 Introduction to data visualization","heading":"1.7 Grammar of graphics","text":"Google defines grammar “whole system structure language languages general, usually taken consisting syntax morphology (including inflections) sometimes also phonology semantics”.7 Others consider grammar “fundamental principles rules art science”.8 Applied visualizations, grammar graphics grammar used describe create wide range statistical graphics.9The layered grammar graphics approach implemented ggplot2, widely used graphics library R. graphics library built using layered approach, building layers create final graphic.","code":""},{"path":"intro-data-viz.html","id":"components-of-the-layered-grammar-of-graphics","chapter":"Day 1 Introduction to data visualization","heading":"1.7.1 Components of the layered grammar of graphics","text":"Layer\nData\nMapping\nStatistical transformation (stat)\nGeometric object (geom)\nPosition adjustment (position)\nDataMappingStatistical transformation (stat)Geometric object (geom)Position adjustment (position)ScaleCoordinate system (coord)Faceting (facet)Defaults\nData\nMapping\nDataMapping","code":""},{"path":"intro-data-viz.html","id":"layer","chapter":"Day 1 Introduction to data visualization","heading":"1.7.2 Layer","text":"Layers used create objects plot. defined five basic parts:DataMappingStatistical transformation (stat)Geometric object (geom)Position adjustment (position)Layers typically related one another share many common features. instance, multiple layers can built using underlying data. example scatterplot overlayed smoothed regression line summarize relationship two variables:","code":""},{"path":"intro-data-viz.html","id":"data-and-mapping","chapter":"Day 1 Introduction to data visualization","heading":"1.7.3 Data and mapping","text":"Data defines source information visualized, independent elements. layered graphic can built utilizes different data sources keeping components .running example, let’s use county_data dataset socviz package.10Mapping defines variables applied plot. graphing information county_data, might map county’s median household income \\(x\\) position 2016 Democratic presidential vote percentage \\(y\\) position.","code":"\ncounty_data %>%\n  select(hh_income, per_dem_2016) %>%\n  rename(\n    x = hh_income,\n    y = per_dem_2016\n  )\n## # A tibble: 3,141 × 2\n##        x      y\n##    <int>  <dbl>\n##  1 53682 0.240 \n##  2 50221 0.196 \n##  3 32911 0.467 \n##  4 36447 0.214 \n##  5 44145 0.0847\n##  6 32033 0.751 \n##  7 29918 0.428 \n##  8 39962 0.279 \n##  9 32402 0.418 \n## 10 34907 0.145 \n## # … with 3,131 more rows"},{"path":"intro-data-viz.html","id":"statistical-transformation","chapter":"Day 1 Introduction to data visualization","heading":"1.7.4 Statistical transformation","text":"statistical transformation (stat) transforms data, generally summarizing information. instance, bar graph typically trying graph raw data doesn’t make inherent sense. Instead, might summarize data graphing total number observations within set categories. dataset many observations, might transform data smoothing line summarizes overall pattern relationship variables calculating mean \\(y\\) conditional \\(x\\).stat function takes dataset input returns dataset output; stat can add new variables original dataset, create entirely new dataset. instead graphing data raw form:transform :Sometimes don’t need make statistical transformation. example, scatterplot use raw values \\(x\\) \\(y\\) variables map onto graph. situations, statistical transformation identity transformation - stat simply passes original dataset exports exact dataset.","code":"\ncounty_data %>%\n  select(state)\n## # A tibble: 3,141 × 1\n##    state\n##    <fct>\n##  1 AL   \n##  2 AL   \n##  3 AL   \n##  4 AL   \n##  5 AL   \n##  6 AL   \n##  7 AL   \n##  8 AL   \n##  9 AL   \n## 10 AL   \n## # … with 3,131 more rows\ncounty_data %>%\n  count(state)\n## # A tibble: 51 × 2\n##    state     n\n##    <fct> <int>\n##  1 AK       29\n##  2 AL       67\n##  3 AR       75\n##  4 AZ       15\n##  5 CA       58\n##  6 CO       64\n##  7 CT        8\n##  8 DC        1\n##  9 DE        3\n## 10 FL       67\n## # … with 41 more rows"},{"path":"intro-data-viz.html","id":"geometric-objects","chapter":"Day 1 Introduction to data visualization","heading":"1.7.5 Geometric objects","text":"Geometric objects (geoms) control type plot create. Geoms classified dimensionality:0 dimensions - point, text1 dimension - path, line2 dimensions - polygon, intervalEach geom can display certain aesthetics visual attributes geom. example, point geom position, color, shape, size aesthetics.Position defines point drawn plotColor defines color point. color determined whether county flipped parties 2012 2016Whereas bar geom position, height, width, fill color.Position determines starting location (origin) barHeight determines tall draw bar. height based number observations dataset population density category.","code":"\nggplot(\n  data = county_data,\n  mapping = aes(\n    x = hh_income,\n    y = per_dem_2016,\n    color = flipped\n  )\n) +\n  geom_point() +\n  ggtitle(\"A point geom with position and color aesthetics\")\nggplot(data = county_data, mapping = aes(x = pop_dens)) +\n  geom_bar() +\n  ggtitle(\"A bar geom with position and height aesthetics\")"},{"path":"intro-data-viz.html","id":"position-adjustment","chapter":"Day 1 Introduction to data visualization","heading":"1.7.6 Position adjustment","text":"Sometimes dense data need adjust position elements plot, otherwise data points might obscure one another. Bar plots frequently stack dodge bars avoid overlap:Sometimes scatterplots unique \\(x\\) \\(y\\) values jittered (random noise added) reduce overplotting.","code":"\ncount(x = county_data, su_gun4, pop_dens) %>%\n  ggplot(mapping = aes(x = pop_dens, y = n, fill = su_gun4)) +\n  geom_bar(stat = \"identity\") +\n  ggtitle(label = \"A stacked bar chart\")\n\ncount(x = county_data, su_gun4, pop_dens) %>%\n  ggplot(mapping = aes(x = pop_dens, y = n, fill = su_gun4)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  ggtitle(label = \"A dodged bar chart\")\nggplot(data = county_data, mapping = aes(x = pop_dens, y = per_dem_2016)) +\n  geom_point() +\n  ggtitle(\"A point geom with obscured data points\")\n\nggplot(data = county_data, mapping = aes(x = pop_dens, y = per_dem_2016)) +\n  geom_jitter() +\n  ggtitle(\"A point geom with jittered data points\")"},{"path":"intro-data-viz.html","id":"scale","chapter":"Day 1 Introduction to data visualization","heading":"1.7.7 Scale","text":"scale controls data mapped aesthetic attributes, need one scale every aesthetic property employed layer. example, graph defines scale color:Note scale consistent - every point different population density category color. scale can changed use different color palette:Now using different palette, scale still consistent.","code":"\nggplot(\n  data = county_data,\n  mapping = aes(\n    x = hh_income,\n    y = per_dem_2016,\n    color = pop_dens\n  )\n) +\n  geom_point()\nggplot(\n  data = county_data,\n  mapping = aes(\n    x = hh_income,\n    y = per_dem_2016,\n    color = pop_dens\n  )\n) +\n  geom_point() +\n  scale_color_brewer(type = \"seq\")"},{"path":"intro-data-viz.html","id":"coordinate-system","chapter":"Day 1 Introduction to data visualization","heading":"1.7.8 Coordinate system","text":"coordinate system (coord) maps position objects onto plane plot, controls axes grid lines drawn. Plots typically use two coordinates (\\(x, y\\)), use number coordinates. plots drawn using Cartesian coordinate system:system requires fixed equal spacing values axes. , graph draws distance 1 2 5 6. graph drawn using semi-log coordinate system logarithmically compresses distance axis:even drawn using polar coordinates:","code":""},{"path":"intro-data-viz.html","id":"faceting","chapter":"Day 1 Introduction to data visualization","heading":"1.7.9 Faceting","text":"Faceting can used split data subsets entire dataset. powerful tool investigating whether patterns different across conditions, allows subsets visualized plot (known conditioned trellis plots). faceting specification describes variables used split data, arranged.","code":"\nggplot(\n  data = county_data,\n  mapping = aes(x = hh_income, y = per_dem_2016)\n) +\n  geom_point() +\n  facet_wrap(~pop_dens)"},{"path":"intro-data-viz.html","id":"defaults","chapter":"Day 1 Introduction to data visualization","heading":"1.7.10 Defaults","text":"Rather explicitly declaring component layered graphic (use code introduces opportunities errors), can establish intelligent defaults specific geoms scales. instance, whenever want use bar geom, can default using stat counts number observations group variable \\(x\\) position.Consider following scenario: wish generate scatterplot visualizing relationship household income 2016 presidential Democratic vote share. defaults, code generate graph :code:Creates new plot object (ggplot)Adds layer (layer)\nSpecifies data (county_data)\nMaps household income \\(x\\) position 2016 Democratic vote share \\(y\\) position (mapping)\nUses point geometric transformation (geom = \"point\")\nImplements identity transformation position (stat = \"identity\" position = \"identity\")\nSpecifies data (county_data)Maps household income \\(x\\) position 2016 Democratic vote share \\(y\\) position (mapping)Uses point geometric transformation (geom = \"point\")Implements identity transformation position (stat = \"identity\" position = \"identity\")Establishes two continuous position scales (scale_x_continuous scale_y_continuous)Declares cartesian coordinate system (coord_cartesian)can simplify using intelligent defaults?need specify one geom stat, since geom default stat.Cartesian coordinate systems commonly used, default.Default scales can added based aesthetic type variables.\nContinuous values transformed linear scaling.\nDiscrete values mapped integers.\nScales aesthetics color, fill, size can also intelligently defaulted.\nContinuous values transformed linear scaling.Discrete values mapped integers.Scales aesthetics color, fill, size can also intelligently defaulted.Using defaults, can rewrite code :generates exact plot, uses fewer lines code. multiple layers can use components (data, mapping, etc.), can also specify information ggplot() function rather layer() function:learn, function arguments R use specific ordering, can omit explicit call data mapping:specification, easy build graphic additional layers, without modifying original code:called aes(hh_income, per_dem_2016) within ggplot() function, automatically passed along geom_point() geom_smooth(). fail , get error:","code":"\nggplot() +\n  layer(\n    data = county_data, mapping = aes(x = hh_income, y = per_dem_2016),\n    geom = \"point\", stat = \"identity\", position = \"identity\"\n  ) +\n  scale_x_continuous() +\n  scale_y_continuous() +\n  coord_cartesian()\nggplot() +\n  geom_point(\n    data = county_data,\n    mapping = aes(x = hh_income, y = per_dem_2016)\n  )\nggplot(\n  data = county_data,\n  mapping = aes(x = hh_income, y = per_dem_2016)\n) +\n  geom_point()\nggplot(county_data, aes(hh_income, per_dem_2016)) +\n  geom_point()\nggplot(county_data, aes(hh_income, per_dem_2016)) +\n  geom_point() +\n  geom_smooth()\nggplot(county_data) +\n  geom_point(aes(hh_income, per_dem_2016)) +\n  geom_smooth()\n## Error in `check_required_aesthetics()`:\n## ! stat_smooth requires the following missing aesthetics: x and y"},{"path":"intro-data-viz.html","id":"building-minards-map-in-r","chapter":"Day 1 Introduction to data visualization","heading":"1.8 Building Minard’s map in R","text":"","code":"\n# get data on troop movements and city names\ntroops <- read_table(\"https://cfss.uchicago.edu/data/minard-troops.txt\")\ncities <- read_table(\"https://cfss.uchicago.edu/data/minard-cities.txt\")\ntroops\n## # A tibble: 51 × 5\n##     long   lat survivors direction group\n##    <dbl> <dbl>     <dbl> <chr>     <dbl>\n##  1  24    54.9    340000 A             1\n##  2  24.5  55      340000 A             1\n##  3  25.5  54.5    340000 A             1\n##  4  26    54.7    320000 A             1\n##  5  27    54.8    300000 A             1\n##  6  28    54.9    280000 A             1\n##  7  28.5  55      240000 A             1\n##  8  29    55.1    210000 A             1\n##  9  30    55.2    180000 A             1\n## 10  30.3  55.3    175000 A             1\n## # … with 41 more rows\ncities\n## # A tibble: 20 × 3\n##     long   lat city          \n##    <dbl> <dbl> <chr>         \n##  1  24    55   Kowno         \n##  2  25.3  54.7 Wilna         \n##  3  26.4  54.4 Smorgoni      \n##  4  26.8  54.3 Moiodexno     \n##  5  27.7  55.2 Gloubokoe     \n##  6  27.6  53.9 Minsk         \n##  7  28.5  54.3 Studienska    \n##  8  28.7  55.5 Polotzk       \n##  9  29.2  54.4 Bobr          \n## 10  30.2  55.3 Witebsk       \n## 11  30.4  54.5 Orscha        \n## 12  30.4  53.9 Mohilow       \n## 13  32    54.8 Smolensk      \n## 14  33.2  54.9 Dorogobouge   \n## 15  34.3  55.2 Wixma         \n## 16  34.4  55.5 Chjat         \n## 17  36    55.5 Mojaisk       \n## 18  37.6  55.8 Moscou        \n## 19  36.6  55.3 Tarantino     \n## 20  36.5  55   Malo-Jarosewii"},{"path":"intro-data-viz.html","id":"exercise-define-the-grammar-of-graphics-for-this-graph","chapter":"Day 1 Introduction to data visualization","heading":"1.8.1 Exercise: Define the grammar of graphics for this graph","text":"\nLayer\nData - troops\nMapping\n\\(x\\) \\(y\\) - troop position (lat long)\nSize - survivors\nColor - direction\n\nStatistical transformation (stat) - identity\nGeometric object (geom) - path\nPosition adjustment (position) - none\nLayerData - troopsMapping\n\\(x\\) \\(y\\) - troop position (lat long)\nSize - survivors\nColor - direction\n\\(x\\) \\(y\\) - troop position (lat long)Size - survivorsColor - directionStatistical transformation (stat) - identityGeometric object (geom) - pathPosition adjustment (position) - noneLayer\nData - cities\nMapping\n\\(x\\) \\(y\\) - city position (lat long)\nLabel - city\n\nStatistical transformation (stat) - identity\nGeometric object (geom) - text\nPosition adjustment (position) - none\nLayerData - citiesMapping\n\\(x\\) \\(y\\) - city position (lat long)\nLabel - city\n\\(x\\) \\(y\\) - city position (lat long)Label - cityStatistical transformation (stat) - identityGeometric object (geom) - textPosition adjustment (position) - noneScale\nSize - range widths troop path\nColor - colors indicate advancing retreating troops\nScaleSize - range widths troop pathColor - colors indicate advancing retreating troopsCoordinate system - map projection (Mercator something else)Coordinate system - map projection (Mercator something else)Faceting - none\n\nFaceting - none","code":""},{"path":"intro-data-viz.html","id":"write-the-r-code","chapter":"Day 1 Introduction to data visualization","heading":"1.8.2 Write the R code","text":"Download necessary data files using usethis::use_course(\"css-data-mining-viz/grammar--graphics\").First want build layer troop movement:Next let’s add cities layer:Now basic information , want clean graph polish visualization :Adjusting size scale aesthetics troop movement better highlight loss troops campaign.Change default colors mimic Minard’s original grey tan palette.Change coordinate system map-based system draws \\(x\\) \\(y\\) axes equal intervals.Give map title remove axis labels.Finally can change default ggplot theme remove background grid lines, well legend advance/retreat:","code":"\nplot_troops <- ggplot(data = troops, mapping = aes(x = long, y = lat)) +\n  geom_path(mapping = aes(\n    size = survivors,\n                color = direction,\n                group = group)\n    )\nplot_troops\nplot_both <- plot_troops + \n  geom_text(data = cities,\n            mapping = aes(label = city), size = 4)\nplot_both\nplot_polished <- plot_both +\n  scale_size(range = c(0, 12),\n             breaks = c(1e04, 5e04, 1e05, 3e05),\n             labels = scales::comma) + \n  scale_color_manual(values = c(\"tan\", \"grey50\")) +\n  coord_map() +\n  labs(title = \"Map of Napoleon's Russian campaign of 1812\",\n       x = NULL,\n       y = NULL)\nplot_polished\nplot_polished +\n  theme_void() +\n  scale_color_manual(values = c(\"tan\", \"grey50\"), guide = FALSE)"},{"path":"intro-data-viz.html","id":"session-info","chapter":"Day 1 Introduction to data visualization","heading":"Session info","text":"","code":"## ─ Session info ───────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.1.2 (2021-11-01)\n##  os       macOS Monterey 12.2.1\n##  system   aarch64, darwin20\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       America/Chicago\n##  date     2022-03-04\n##  pandoc   2.17.1.1 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/ (via rmarkdown)\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────\n##  package      * version    date (UTC) lib source\n##  assertthat     0.2.1      2019-03-21 [1] CRAN (R 4.1.0)\n##  backports      1.4.1      2021-12-13 [1] CRAN (R 4.1.1)\n##  bookdown       0.24       2021-09-02 [1] CRAN (R 4.1.1)\n##  brio           1.1.3      2021-11-30 [1] CRAN (R 4.1.1)\n##  broom        * 0.7.12     2022-01-28 [1] CRAN (R 4.1.1)\n##  bslib          0.3.1      2021-10-06 [1] CRAN (R 4.1.1)\n##  cachem         1.0.6      2021-08-19 [1] CRAN (R 4.1.1)\n##  callr          3.7.0      2021-04-20 [1] CRAN (R 4.1.0)\n##  cellranger     1.1.0      2016-07-27 [1] CRAN (R 4.1.0)\n##  class          7.3-20     2022-01-13 [1] CRAN (R 4.1.1)\n##  classInt       0.4-3      2020-04-07 [1] CRAN (R 4.1.0)\n##  cli            3.2.0      2022-02-14 [1] CRAN (R 4.1.1)\n##  codetools      0.2-18     2020-11-04 [1] CRAN (R 4.1.2)\n##  colorspace     2.0-3      2022-02-21 [1] CRAN (R 4.1.1)\n##  crayon         1.5.0      2022-02-14 [1] CRAN (R 4.1.1)\n##  crosstalk      1.2.0      2021-11-04 [1] CRAN (R 4.1.1)\n##  curl           4.3.2      2021-06-23 [1] CRAN (R 4.1.0)\n##  datasauRus   * 0.1.4      2018-09-20 [1] CRAN (R 4.1.1)\n##  DBI            1.1.2      2021-12-20 [1] CRAN (R 4.1.1)\n##  dbplyr         2.1.1      2021-04-06 [1] CRAN (R 4.1.0)\n##  desc           1.4.0      2021-09-28 [1] CRAN (R 4.1.1)\n##  devtools       2.4.3      2021-11-30 [1] CRAN (R 4.1.1)\n##  digest         0.6.29     2021-12-01 [1] CRAN (R 4.1.1)\n##  dplyr        * 1.0.8      2022-02-08 [1] CRAN (R 4.1.1)\n##  DT             0.21       2022-02-26 [1] CRAN (R 4.1.2)\n##  e1071          1.7-9      2021-09-16 [1] CRAN (R 4.1.1)\n##  ellipsis       0.3.2      2021-04-29 [1] CRAN (R 4.1.0)\n##  evaluate       0.15       2022-02-18 [1] CRAN (R 4.1.1)\n##  fansi          1.0.2      2022-01-14 [1] CRAN (R 4.1.1)\n##  farver         2.1.0      2021-02-28 [1] CRAN (R 4.1.0)\n##  fastmap        1.1.0      2021-01-25 [1] CRAN (R 4.1.0)\n##  forcats      * 0.5.1      2021-01-27 [1] CRAN (R 4.1.1)\n##  foreign        0.8-82     2022-01-13 [1] CRAN (R 4.1.1)\n##  fs             1.5.2      2021-12-08 [1] CRAN (R 4.1.1)\n##  generics       0.1.2      2022-01-31 [1] CRAN (R 4.1.1)\n##  gganimate    * 1.0.7      2020-10-15 [1] CRAN (R 4.1.1)\n##  ggplot2      * 3.3.5      2021-06-25 [1] CRAN (R 4.1.1)\n##  gifski         1.4.3-1    2021-05-02 [1] CRAN (R 4.1.0)\n##  glue           1.6.1      2022-01-22 [1] CRAN (R 4.1.1)\n##  gtable         0.3.0      2019-03-25 [1] CRAN (R 4.1.1)\n##  haven          2.4.3      2021-08-04 [1] CRAN (R 4.1.1)\n##  here         * 1.0.1      2020-12-13 [1] CRAN (R 4.1.0)\n##  highr          0.9        2021-04-16 [1] CRAN (R 4.1.0)\n##  hms            1.1.1      2021-09-26 [1] CRAN (R 4.1.1)\n##  htmltools      0.5.2      2021-08-25 [1] CRAN (R 4.1.1)\n##  htmlwidgets    1.5.4      2021-09-08 [1] CRAN (R 4.1.1)\n##  httr           1.4.2      2020-07-20 [1] CRAN (R 4.1.0)\n##  jquerylib      0.1.4      2021-04-26 [1] CRAN (R 4.1.0)\n##  jsonlite       1.8.0      2022-02-22 [1] CRAN (R 4.1.1)\n##  KernSmooth     2.23-20    2021-05-03 [1] CRAN (R 4.1.2)\n##  knitr        * 1.37       2021-12-16 [1] CRAN (R 4.1.1)\n##  labeling       0.4.2      2020-10-20 [1] CRAN (R 4.1.0)\n##  lattice        0.20-45    2021-09-22 [1] CRAN (R 4.1.2)\n##  lifecycle      1.0.1      2021-09-24 [1] CRAN (R 4.1.1)\n##  lubridate      1.8.0      2021-10-07 [1] CRAN (R 4.1.1)\n##  magrittr       2.0.2      2022-01-26 [1] CRAN (R 4.1.1)\n##  mapproj        1.2.8      2022-01-12 [1] CRAN (R 4.1.1)\n##  maps           3.4.0      2021-09-25 [1] CRAN (R 4.1.1)\n##  maptools       1.1-2      2021-09-07 [1] CRAN (R 4.1.1)\n##  Matrix         1.4-0      2021-12-08 [1] CRAN (R 4.1.1)\n##  memoise        2.0.1      2021-11-26 [1] CRAN (R 4.1.1)\n##  mgcv           1.8-38     2021-10-06 [1] CRAN (R 4.1.1)\n##  modelr         0.1.8      2020-05-19 [1] CRAN (R 4.1.0)\n##  munsell        0.5.0      2018-06-12 [1] CRAN (R 4.1.0)\n##  nlme           3.1-155    2022-01-13 [1] CRAN (R 4.1.1)\n##  patchwork    * 1.1.1      2020-12-17 [1] CRAN (R 4.1.1)\n##  pillar         1.7.0      2022-02-01 [1] CRAN (R 4.1.1)\n##  pkgbuild       1.3.1      2021-12-20 [1] CRAN (R 4.1.1)\n##  pkgconfig      2.0.3      2019-09-22 [1] CRAN (R 4.1.0)\n##  pkgload        1.2.4      2021-11-30 [1] CRAN (R 4.1.1)\n##  plyr           1.8.6      2020-03-03 [1] CRAN (R 4.1.0)\n##  prettyunits    1.1.1      2020-01-24 [1] CRAN (R 4.1.0)\n##  processx       3.5.2      2021-04-30 [1] CRAN (R 4.1.0)\n##  progress       1.2.2      2019-05-16 [1] CRAN (R 4.1.0)\n##  proxy          0.4-26     2021-06-07 [1] CRAN (R 4.1.0)\n##  ps             1.6.0      2021-02-28 [1] CRAN (R 4.1.0)\n##  purrr        * 0.3.4      2020-04-17 [1] CRAN (R 4.1.0)\n##  R6             2.5.1      2021-08-19 [1] CRAN (R 4.1.1)\n##  rappdirs       0.3.3      2021-01-31 [1] CRAN (R 4.1.0)\n##  rcfss        * 0.2.4      2022-02-17 [1] local\n##  RColorBrewer   1.1-2      2014-12-07 [1] CRAN (R 4.1.0)\n##  Rcpp           1.0.8      2022-01-13 [1] CRAN (R 4.1.1)\n##  readr        * 2.1.2      2022-01-30 [1] CRAN (R 4.1.1)\n##  readxl         1.3.1      2019-03-13 [1] CRAN (R 4.1.0)\n##  remotes        2.4.2      2021-11-30 [1] CRAN (R 4.1.1)\n##  reprex         2.0.1      2021-08-05 [1] CRAN (R 4.1.1)\n##  rgdal          1.5-28     2021-12-15 [1] CRAN (R 4.1.1)\n##  rlang          1.0.1      2022-02-03 [1] CRAN (R 4.1.1)\n##  rmarkdown      2.11       2021-09-14 [1] CRAN (R 4.1.1)\n##  rprojroot      2.0.2      2020-11-15 [1] CRAN (R 4.1.0)\n##  rstudioapi     0.13       2020-11-12 [1] CRAN (R 4.1.0)\n##  rvest          1.0.2      2021-10-16 [1] CRAN (R 4.1.1)\n##  sass           0.4.0      2021-05-12 [1] CRAN (R 4.1.0)\n##  scales         1.1.1      2020-05-11 [1] CRAN (R 4.1.0)\n##  sessioninfo    1.2.2      2021-12-06 [1] CRAN (R 4.1.1)\n##  sf             1.0-6      2022-02-04 [1] CRAN (R 4.1.1)\n##  socviz       * 1.2        2020-06-10 [1] CRAN (R 4.1.0)\n##  sp             1.4-6      2021-11-14 [1] CRAN (R 4.1.1)\n##  statebins    * 1.4.0      2020-07-08 [1] CRAN (R 4.1.0)\n##  stringi        1.7.6      2021-11-29 [1] CRAN (R 4.1.1)\n##  stringr      * 1.4.0      2019-02-10 [1] CRAN (R 4.1.1)\n##  testthat       3.1.2      2022-01-20 [1] CRAN (R 4.1.1)\n##  tibble       * 3.1.6      2021-11-07 [1] CRAN (R 4.1.1)\n##  tidycensus   * 1.1.0.9000 2022-01-25 [1] Github (walkerke/tidycensus@8b8e38a)\n##  tidyr        * 1.2.0      2022-02-01 [1] CRAN (R 4.1.1)\n##  tidyselect     1.1.2      2022-02-21 [1] CRAN (R 4.1.1)\n##  tidyverse    * 1.3.1      2021-04-15 [1] CRAN (R 4.1.0)\n##  tigris         1.6        2022-02-22 [1] CRAN (R 4.1.1)\n##  tweenr         1.0.2      2021-03-23 [1] CRAN (R 4.1.0)\n##  tzdb           0.2.0      2021-10-27 [1] CRAN (R 4.1.1)\n##  units          0.8-0      2022-02-05 [1] CRAN (R 4.1.1)\n##  usethis        2.1.5      2021-12-09 [1] CRAN (R 4.1.1)\n##  utf8           1.2.2      2021-07-24 [1] CRAN (R 4.1.0)\n##  uuid           1.0-3      2021-11-01 [1] CRAN (R 4.1.1)\n##  vctrs          0.3.8      2021-04-29 [1] CRAN (R 4.1.0)\n##  withr          2.4.3      2021-11-30 [1] CRAN (R 4.1.1)\n##  xfun           0.29       2021-12-14 [1] CRAN (R 4.1.1)\n##  xml2           1.3.3      2021-11-30 [1] CRAN (R 4.1.1)\n##  yaml           2.3.5      2022-02-21 [1] CRAN (R 4.1.1)\n## \n##  [1] /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library\n## \n## ──────────────────────────────────────────────────────────────────────────────"},{"path":"show-the-numbers.html","id":"show-the-numbers","chapter":"Day 2 Showing the right numbers","heading":"Day 2 Showing the right numbers","text":"","code":"\nlibrary(tidyverse)\nlibrary(gapminder)\nlibrary(socviz)\nlibrary(knitr)\nlibrary(broom)\nlibrary(forcats)\nlibrary(stringr)\nlibrary(ggrepel)\nlibrary(here)"},{"path":"show-the-numbers.html","id":"learning-objectives-1","chapter":"Day 2 Showing the right numbers","heading":"Learning objectives","text":"","code":""},{"path":"show-the-numbers.html","id":"morning-1","chapter":"Day 2 Showing the right numbers","heading":"2.0.1 Morning","text":"Expand different types geometric objects used ggplot2Demonstrate ability ggplot2 calculate statistical transformationsReview grammar graphics ggplot2 workflowCombine ggplot2 dplyr data transformation prior constructing graph","code":""},{"path":"show-the-numbers.html","id":"afternoon-1","chapter":"Day 2 Showing the right numbers","heading":"2.0.2 Afternoon","text":"Demonstrate techniques mapping data graphicsIntroduce alternative visualizations displaying amounts proportionsConsider advanced visualizations comparisons","code":""},{"path":"show-the-numbers.html","id":"assigned-readings-1","chapter":"Day 2 Showing the right numbers","heading":"Assigned readings","text":"Chapters 4-5, Healy (2018) - accessible via book’s website","code":""},{"path":"show-the-numbers.html","id":"grammar-of-graphics-review","chapter":"Day 2 Showing the right numbers","heading":"2.1 Grammar of graphics (review)","text":"grammar graphics set rules produce graphics data, taking pieces data mapping geometric objects (like points lines) aesthetic attributes (like position, color, size), together rules transforming data needed, adjusting scales, projecting results onto coordinate system.","code":""},{"path":"show-the-numbers.html","id":"grouped-data-and-the-group-aesthetic","chapter":"Day 2 Showing the right numbers","heading":"2.2 Grouped data and the group aesthetic","text":"doesn’t look right. trying draw single line observations. look structure gapminder:one-row-per-country-per-year. use group identify column tells us structure draw one line per country.facet geom. way arranging geoms. Facet’s use R’s formula syntax. Read ~ “” “”.labs() function lets name labels, title, subtitle, etc.","code":"\np <- ggplot(\n  data = gapminder,\n  mapping = aes(\n    x = year,\n    y = gdpPercap\n  )\n)\n\np + geom_line()\ngapminder\n## # A tibble: 1,704 × 6\n##    country     continent  year lifeExp      pop gdpPercap\n##    <fct>       <fct>     <int>   <dbl>    <int>     <dbl>\n##  1 Afghanistan Asia       1952    28.8  8425333      779.\n##  2 Afghanistan Asia       1957    30.3  9240934      821.\n##  3 Afghanistan Asia       1962    32.0 10267083      853.\n##  4 Afghanistan Asia       1967    34.0 11537966      836.\n##  5 Afghanistan Asia       1972    36.1 13079460      740.\n##  6 Afghanistan Asia       1977    38.4 14880372      786.\n##  7 Afghanistan Asia       1982    39.9 12881816      978.\n##  8 Afghanistan Asia       1987    40.8 13867957      852.\n##  9 Afghanistan Asia       1992    41.7 16317921      649.\n## 10 Afghanistan Asia       1997    41.8 22227415      635.\n## # … with 1,694 more rows\np <- ggplot(data = gapminder, mapping = aes(\n  x = year,\n  y = gdpPercap\n))\np + geom_line(mapping = aes(group = country))\np <- ggplot(\n  data = gapminder,\n  mapping = aes(\n    x = year,\n    y = gdpPercap\n  )\n)\np + geom_line(\n  mapping =\n    aes(group = country)\n) +\n  facet_wrap(~continent)\np + geom_line(\n  color = \"gray70\",\n  mapping = aes(group = country)\n) +\n  geom_smooth(\n    size = 1.1,\n    method = \"loess\",\n    se = FALSE\n  ) +\n  scale_y_log10(labels = scales::dollar) +\n  facet_wrap(~continent, ncol = 5) +\n  labs(\n    x = \"Year\",\n    y = \"GDP per capita\",\n    title = \"GDP per capita on Five Continents\"\n  )"},{"path":"show-the-numbers.html","id":"geoms-can-transform-data","chapter":"Day 2 Showing the right numbers","heading":"2.3 Geoms can transform data","text":"gss_sm contains subset General Social Survey questions 2016.y-axis variable count data. Instead, ggplot calculated us. using default stat_*() function associated geom_bar(), stat_count(). function can compute two new variables, count prop (short proportion). count statistic default one used.default stat(prop) calculated within bar. want calculate proportion rows data frame, add group = 1.","code":"\ngss_sm\n## # A tibble: 2,867 × 32\n##     year    id ballot       age childs sibs   degree race  sex   region income16\n##    <dbl> <dbl> <labelled> <dbl>  <dbl> <labe> <fct>  <fct> <fct> <fct>  <fct>   \n##  1  2016     1 1             47      3 2      Bache… White Male  New E… $170000…\n##  2  2016     2 2             61      0 3      High … White Male  New E… $50000 …\n##  3  2016     3 3             72      2 3      Bache… White Male  New E… $75000 …\n##  4  2016     4 1             43      4 3      High … White Fema… New E… $170000…\n##  5  2016     5 3             55      2 2      Gradu… White Fema… New E… $170000…\n##  6  2016     6 2             53      2 2      Junio… White Fema… New E… $60000 …\n##  7  2016     7 1             50      2 2      High … White Male  New E… $170000…\n##  8  2016     8 3             23      3 6      High … Other Fema… Middl… $30000 …\n##  9  2016     9 1             45      3 5      High … Black Male  Middl… $60000 …\n## 10  2016    10 3             71      4 1      Junio… White Male  Middl… $60000 …\n## # … with 2,857 more rows, and 21 more variables: relig <fct>, marital <fct>,\n## #   padeg <fct>, madeg <fct>, partyid <fct>, polviews <fct>, happy <fct>,\n## #   partners <fct>, grass <fct>, zodiac <fct>, pres12 <labelled>,\n## #   wtssall <dbl>, income_rc <fct>, agegrp <fct>, ageq <fct>, siblings <fct>,\n## #   kids <fct>, religion <fct>, bigregion <fct>, partners_rc <fct>, obama <dbl>\ncount(x = gss_sm, religion)\n## # A tibble: 6 × 2\n##   religion       n\n##   <fct>      <int>\n## 1 Protestant  1371\n## 2 Catholic     649\n## 3 Jewish        51\n## 4 None         619\n## 5 Other        159\n## 6 <NA>          18\np <- ggplot(\n  data = gss_sm,\n  mapping = aes(x = bigregion)\n)\np + geom_bar()\np <- ggplot(\n  data = gss_sm,\n  mapping = aes(x = bigregion)\n)\np + geom_bar(mapping = aes(y = stat(prop)))\np <- ggplot(\n  data = gss_sm,\n  mapping = aes(x = bigregion)\n)\np + geom_bar(mapping = aes(y = stat(prop), group = 1))"},{"path":"show-the-numbers.html","id":"geom_-functions-call-their-default-stat_-functions-behind-the-scenes","chapter":"Day 2 Showing the right numbers","heading":"2.4 geom_*() functions call their default stat_*() functions behind the scenes","text":"","code":"\np + geom_bar()\n\np + stat_count()"},{"path":"show-the-numbers.html","id":"color-in-a-bar-chart","chapter":"Day 2 Showing the right numbers","heading":"2.4.1 Color in a bar chart","text":"want use color aesthetic communicate additional information bar chart, pass using fill aesthetic. color defines border bar.","code":"\np <- ggplot(\n  data = gss_sm,\n  mapping = aes(x = religion)\n)\np + geom_bar()\np <- ggplot(\n  data = gss_sm,\n  mapping = aes(x = religion, color = religion)\n)\np + geom_bar()\np <- ggplot(\n  data = gss_sm,\n  mapping = aes(x = religion, fill = religion)\n)\np + geom_bar()\np <- ggplot(\n  data = gss_sm,\n  mapping = aes(x = religion, fill = religion)\n)\np + geom_bar() + guides(fill = FALSE)"},{"path":"show-the-numbers.html","id":"histograms-and-kernel-densities","chapter":"Day 2 Showing the right numbers","heading":"2.5 Histograms and kernel densities","text":"midwest contains county-level census data Midwestern states.default stat geom make choice, message letting us know might want override .","code":"\nmidwest\n## # A tibble: 437 × 28\n##      PID county  state  area poptotal popdensity popwhite popblack popamerindian\n##    <int> <chr>   <chr> <dbl>    <int>      <dbl>    <int>    <int>         <int>\n##  1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n##  2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n##  3   563 BOND    IL    0.022    14991       681.    14477      429            35\n##  4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n##  5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n##  6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n##  7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n##  8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n##  9   569 CASS    IL    0.024    13437       560.    13384       16             8\n## 10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n## # … with 427 more rows, and 19 more variables: popasian <int>, popother <int>,\n## #   percwhite <dbl>, percblack <dbl>, percamerindan <dbl>, percasian <dbl>,\n## #   percother <dbl>, popadults <int>, perchsd <dbl>, percollege <dbl>,\n## #   percprof <dbl>, poppovertyknown <int>, percpovertyknown <dbl>,\n## #   percbelowpoverty <dbl>, percchildbelowpovert <dbl>, percadultpoverty <dbl>,\n## #   percelderlypoverty <dbl>, inmetro <int>, category <chr>\np <- ggplot(\n  data = midwest,\n  mapping = aes(x = area)\n)\np + geom_histogram()\np <- ggplot(\n  data = midwest,\n  mapping = aes(x = area)\n)\np + geom_histogram(bins = 10)"},{"path":"show-the-numbers.html","id":"subsetting-data-on-the-fly","chapter":"Day 2 Showing the right numbers","heading":"2.5.1 Subsetting data on the fly","text":"can done, somewhat challenging read intuitively. must use alpha incorporate transparency otherwise hope interpreting lost.Alternatively, use continuous counterpart, geom_density().","code":"\noh_wi <- c(\"OH\", \"WI\")\n\np <- ggplot(\n  data = filter(midwest, state %in% oh_wi),\n  mapping = aes(x = percollege, fill = state)\n)\np + geom_histogram(\n  position = \"identity\",\n  alpha = 0.4, bins = 20\n)\np <- ggplot(\n  data = midwest,\n  mapping = aes(x = area)\n)\n\np + geom_density()\np <- ggplot(\n  data = midwest,\n  mapping = aes(\n    x = area,\n    fill = state,\n    color = state\n  )\n)\n\np + geom_density(alpha = 0.3)"},{"path":"show-the-numbers.html","id":"avoiding-transformations-when-necessary","chapter":"Day 2 Showing the right numbers","heading":"2.6 Avoiding transformations when necessary","text":"Sometimes transformation necessary. Consider titanic datasetHere data already summarized. want make bar chart?Even conveniently, use geom_col()","code":"\ntitanic\n##       fate    sex    n percent\n## 1 perished   male 1364    62.0\n## 2 perished female  126     5.7\n## 3 survived   male  367    16.7\n## 4 survived female  344    15.6\np <- ggplot(\n  data = titanic,\n  mapping = aes(\n    x = fate,\n    y = percent,\n    fill = sex\n  )\n)\np + geom_bar(\n  stat = \"identity\",\n  position = \"dodge\"\n) + theme(legend.position = \"top\")\np <- ggplot(data = titanic, mapping = aes(\n  x = fate,\n  y = percent,\n  fill = sex\n))\n\np + geom_col(position = \"dodge\") + theme(legend.position = \"top\")\noecd_sum\n## # A tibble: 57 × 5\n## # Groups:   year [57]\n##     year other   usa  diff hi_lo\n##    <int> <dbl> <dbl> <dbl> <chr>\n##  1  1960  68.6  69.9 1.30  Below\n##  2  1961  69.2  70.4 1.20  Below\n##  3  1962  68.9  70.2 1.30  Below\n##  4  1963  69.1  70   0.900 Below\n##  5  1964  69.5  70.3 0.800 Below\n##  6  1965  69.6  70.3 0.700 Below\n##  7  1966  69.9  70.3 0.400 Below\n##  8  1967  70.1  70.7 0.600 Below\n##  9  1968  70.1  70.4 0.300 Below\n## 10  1969  70.1  70.6 0.5   Below\n## # … with 47 more rows\n\np <- ggplot(\n  data = oecd_sum,\n  mapping = aes(x = year, y = diff, fill = hi_lo)\n)\np + geom_col() + guides(fill = FALSE) + labs(\n  x = NULL, y = \"Difference in Years\",\n  title = \"The US Life Expectancy Gap\", subtitle = \"Difference between US and OECD\naverage life expectancies, 1960-2015\",\n  caption = \"Data: OECD. After a chart by Christopher Ingraham,\nWashington Post, December 27th 2017.\"\n)"},{"path":"show-the-numbers.html","id":"cross-tabulation-the-awkward-way","chapter":"Day 2 Showing the right numbers","heading":"2.7 Cross-tabulation the awkward way","text":"commonly, add color bar graph cross-classify two categorical variables. graphical equivalent frequency table. can directly within ggplot(), however also convoluted.Consider examining religious preference census region.default get stacked bar chart. want make comparisons easier, convert proportional bar chart.Now bars height, lost ability see relative size region respect overall total. wanted show proportion religions within regions country, instead stacking bars want separate bars? first attempt may use position = \"dodge\".Good structure, ’re back counts. Let’s directly map stat(prop) variable y aesthetic well preserve proportion y-axis.Still correct. problem . individual bar sums 1. want overall proportions single variable, mapped group = 1. respect religion?Looks better, still problem. Bars within single region sum 1. Instead, bars particular religion sum 1.easiest approach use facet_wrap() force geom_bar() stat_count() work single step. Instead, can ask ggplot() give us proportional bar chart religious affiliation, facet region. proportions calculated within panel, breakdown wanted. added advantage producing many bars within category.","code":"\nggplot(\n  data = gss_sm,\n  mapping = aes(\n    x = bigregion,\n    fill = religion\n  )\n) +\n  geom_bar()\nggplot(\n  data = gss_sm,\n  mapping = aes(\n    x = bigregion,\n    fill = religion\n  )\n) +\n  geom_bar(position = \"fill\")\nggplot(\n  data = gss_sm,\n  mapping = aes(\n    x = bigregion,\n    fill = religion\n  )\n) +\n  geom_bar(position = \"dodge\")\nggplot(\n  data = gss_sm,\n  mapping = aes(\n    x = bigregion,\n    fill = religion\n  )\n) +\n  geom_bar(mapping = aes(y = stat(prop)), position = \"dodge\")\nggplot(\n  data = gss_sm,\n  mapping = aes(\n    x = bigregion,\n    fill = religion\n  )\n) +\n  geom_bar(mapping = aes(\n    y = stat(prop),\n    group = religion\n  ), position = \"dodge\")\nggplot(\n  data = gss_sm,\n  mapping = aes(x = religion)\n) +\n  geom_bar(mapping = aes(\n    y = stat(prop),\n    group = bigregion\n  ), position = \"dodge\") +\n  facet_wrap(~bigregion)"},{"path":"show-the-numbers.html","id":"calculate-manually","chapter":"Day 2 Showing the right numbers","heading":"2.7.1 Calculate manually","text":"Rather summarizing ggplot(), instead calculate frequencies proportions manually using dplyr functions first, use summarized data frame basis bar graph.Now easy pass ggplot() draw bar graph.Instead using geom_bar(), use geom_col() already summarized data - want stat_identity(), stat_count(). figure works, best can . generally crowded. Instead, let’s convert faceted plot:","code":"\nglimpse(gss_sm)\n## Rows: 2,867\n## Columns: 32\n## $ year        <dbl> 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016…\n## $ id          <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n## $ ballot      <labelled> 1, 2, 3, 1, 3, 2, 1, 3, 1, 3, 2, 1, 2, 3, 2, 3, 3, 2,…\n## $ age         <dbl> 47, 61, 72, 43, 55, 53, 50, 23, 45, 71, 33, 86, 32, 60, 76…\n## $ childs      <dbl> 3, 0, 2, 4, 2, 2, 2, 3, 3, 4, 5, 4, 3, 5, 7, 2, 6, 5, 0, 2…\n## $ sibs        <labelled> 2, 3, 3, 3, 2, 2, 2, 6, 5, 1, 4, 4, 3, 6, 0, 1, 3, 8,…\n## $ degree      <fct> Bachelor, High School, Bachelor, High School, Graduate, Ju…\n## $ race        <fct> White, White, White, White, White, White, White, Other, Bl…\n## $ sex         <fct> Male, Male, Male, Female, Female, Female, Male, Female, Ma…\n## $ region      <fct> New England, New England, New England, New England, New En…\n## $ income16    <fct> $170000 or over, $50000 to 59999, $75000 to $89999, $17000…\n## $ relig       <fct> None, None, Catholic, Catholic, None, None, None, Catholic…\n## $ marital     <fct> Married, Never Married, Married, Married, Married, Married…\n## $ padeg       <fct> Graduate, Lt High School, High School, NA, Bachelor, NA, H…\n## $ madeg       <fct> High School, High School, Lt High School, High School, Hig…\n## $ partyid     <fct> \"Independent\", \"Ind,near Dem\", \"Not Str Republican\", \"Not …\n## $ polviews    <fct> Moderate, Liberal, Conservative, Moderate, Slightly Libera…\n## $ happy       <fct> Pretty Happy, Pretty Happy, Very Happy, Pretty Happy, Very…\n## $ partners    <fct> NA, \"1 Partner\", \"1 Partner\", NA, \"1 Partner\", \"1 Partner\"…\n## $ grass       <fct> NA, Legal, Not Legal, NA, Legal, Legal, NA, Not Legal, NA,…\n## $ zodiac      <fct> Aquarius, Scorpio, Pisces, Cancer, Scorpio, Scorpio, Capri…\n## $ pres12      <labelled> 3, 1, 2, 2, 1, 1, NA, NA, NA, 2, NA, NA, 1, 1, 2, 1, …\n## $ wtssall     <dbl> 0.957, 0.478, 0.957, 1.914, 1.435, 0.957, 1.435, 0.957, 0.…\n## $ income_rc   <fct> Gt $170000, Gt $50000, Gt $75000, Gt $170000, Gt $170000, …\n## $ agegrp      <fct> Age 45-55, Age 55-65, Age 65+, Age 35-45, Age 45-55, Age 4…\n## $ ageq        <fct> Age 34-49, Age 49-62, Age 62+, Age 34-49, Age 49-62, Age 4…\n## $ siblings    <fct> 2, 3, 3, 3, 2, 2, 2, 6+, 5, 1, 4, 4, 3, 6+, 0, 1, 3, 6+, 2…\n## $ kids        <fct> 3, 0, 2, 4+, 2, 2, 2, 3, 3, 4+, 4+, 4+, 3, 4+, 4+, 2, 4+, …\n## $ religion    <fct> None, None, Catholic, Catholic, None, None, None, Catholic…\n## $ bigregion   <fct> Northeast, Northeast, Northeast, Northeast, Northeast, Nor…\n## $ partners_rc <fct> NA, 1, 1, NA, 1, 1, NA, 1, NA, 3, 1, NA, 1, NA, 0, 1, 0, N…\n## $ obama       <dbl> 0, 1, 0, 0, 1, 1, NA, NA, NA, 0, NA, NA, 1, 1, 0, 1, 0, 1,…\n\n(rel_by_region <- gss_sm %>%\n  count(bigregion, religion) %>%\n  mutate(\n    freq = n / sum(n),\n    pct = round((freq * 100), 0)\n  ) %>%\n  drop_na())\n## # A tibble: 20 × 5\n##    bigregion religion       n    freq   pct\n##    <fct>     <fct>      <int>   <dbl> <dbl>\n##  1 Northeast Protestant   158 0.0551      6\n##  2 Northeast Catholic     162 0.0565      6\n##  3 Northeast Jewish        27 0.00942     1\n##  4 Northeast None         112 0.0391      4\n##  5 Northeast Other         28 0.00977     1\n##  6 Midwest   Protestant   325 0.113      11\n##  7 Midwest   Catholic     172 0.0600      6\n##  8 Midwest   Jewish         3 0.00105     0\n##  9 Midwest   None         157 0.0548      5\n## 10 Midwest   Other         33 0.0115      1\n## 11 South     Protestant   650 0.227      23\n## 12 South     Catholic     160 0.0558      6\n## 13 South     Jewish        11 0.00384     0\n## 14 South     None         170 0.0593      6\n## 15 South     Other         50 0.0174      2\n## 16 West      Protestant   238 0.0830      8\n## 17 West      Catholic     155 0.0541      5\n## 18 West      Jewish        10 0.00349     0\n## 19 West      None         180 0.0628      6\n## 20 West      Other         48 0.0167      2\nggplot(\n  data = rel_by_region,\n  mapping = aes(\n    x = bigregion,\n    y = pct,\n    fill = religion\n  )\n) +\n  geom_col(position = \"dodge2\") +\n  labs(x = \"Region\", y = \"Percent\", fill = \"Religion\") +\n  theme(legend.position = \"top\")\nggplot(\n  data = rel_by_region,\n  mapping = aes(\n    x = religion,\n    y = pct,\n    fill = religion\n  )\n) +\n  geom_col(position = \"dodge2\") +\n  labs(x = \"Region\", y = \"Percent\", fill = \"Religion\") +\n  guides(fill = FALSE) +\n  coord_flip() +\n  facet_grid(~bigregion)"},{"path":"show-the-numbers.html","id":"continuous-variables-by-group-or-category","chapter":"Day 2 Showing the right numbers","heading":"2.8 Continuous variables by group or category","text":"","code":"\nglimpse(organdata)\n## Rows: 238\n## Columns: 21\n## $ country          <chr> \"Australia\", \"Australia\", \"Australia\", \"Australia\", \"…\n## $ year             <date> NA, 1991-01-01, 1992-01-01, 1993-01-01, 1994-01-01, …\n## $ donors           <dbl> NA, 12.09, 12.35, 12.51, 10.25, 10.18, 10.59, 10.26, …\n## $ pop              <int> 17065, 17284, 17495, 17667, 17855, 18072, 18311, 1851…\n## $ pop_dens         <dbl> 0.220, 0.223, 0.226, 0.228, 0.231, 0.233, 0.237, 0.23…\n## $ gdp              <int> 16774, 17171, 17914, 18883, 19849, 21079, 21923, 2296…\n## $ gdp_lag          <int> 16591, 16774, 17171, 17914, 18883, 19849, 21079, 2192…\n## $ health           <dbl> 1300, 1379, 1455, 1540, 1626, 1737, 1846, 1948, 2077,…\n## $ health_lag       <dbl> 1224, 1300, 1379, 1455, 1540, 1626, 1737, 1846, 1948,…\n## $ pubhealth        <dbl> 4.8, 5.4, 5.4, 5.4, 5.4, 5.5, 5.6, 5.7, 5.9, 6.1, 6.2…\n## $ roads            <dbl> 136.6, 122.3, 112.8, 110.5, 108.0, 111.6, 107.6, 95.4…\n## $ cerebvas         <int> 682, 647, 630, 611, 631, 592, 576, 525, 516, 493, 474…\n## $ assault          <int> 21, 19, 17, 18, 17, 16, 17, 17, 16, 15, 16, 15, 14, N…\n## $ external         <int> 444, 425, 406, 376, 387, 371, 395, 385, 410, 409, 393…\n## $ txp_pop          <dbl> 0.938, 0.926, 0.915, 0.906, 0.896, 0.885, 0.874, 0.86…\n## $ world            <chr> \"Liberal\", \"Liberal\", \"Liberal\", \"Liberal\", \"Liberal\"…\n## $ opt              <chr> \"In\", \"In\", \"In\", \"In\", \"In\", \"In\", \"In\", \"In\", \"In\",…\n## $ consent_law      <chr> \"Informed\", \"Informed\", \"Informed\", \"Informed\", \"Info…\n## $ consent_practice <chr> \"Informed\", \"Informed\", \"Informed\", \"Informed\", \"Info…\n## $ consistent       <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes…\n## $ ccode            <chr> \"Oz\", \"Oz\", \"Oz\", \"Oz\", \"Oz\", \"Oz\", \"Oz\", \"Oz\", \"Oz\",…"},{"path":"show-the-numbers.html","id":"boxplots","chapter":"Day 2 Showing the right numbers","heading":"2.8.1 Boxplots","text":"Awkward country labels x-axis. Switch y-axis.","code":"\nggplot(\n  data = organdata,\n  mapping = aes(x = country, y = donors)\n) +\n  geom_boxplot()"},{"path":"show-the-numbers.html","id":"coord_flip","chapter":"Day 2 Showing the right numbers","heading":"2.8.2 coord_flip()","text":"Explicit use coordinate transformation system.","code":"\nggplot(\n  data = organdata,\n  mapping = aes(x = country, y = donors)\n) +\n  geom_boxplot() +\n  coord_flip()"},{"path":"show-the-numbers.html","id":"reorder","chapter":"Day 2 Showing the right numbers","heading":"2.8.3 reorder()","text":"Place meaningful order.Add color aesthetic.","code":"\nggplot(\n  data = organdata,\n  mapping = aes(\n    x = reorder(country, donors, na.rm = TRUE),\n    y = donors\n  )\n) +\n  geom_boxplot() +\n  labs(x = NULL) +\n  coord_flip()\nggplot(\n  data = organdata,\n  mapping = aes(\n    x = reorder(country, donors, na.rm = TRUE),\n    y = donors, fill = world\n  )\n) +\n  geom_boxplot() +\n  labs(x = NULL) +\n  coord_flip() +\n  theme(legend.position = \"bottom\")"},{"path":"show-the-numbers.html","id":"strip-chart","chapter":"Day 2 Showing the right numbers","heading":"2.8.4 Strip chart","text":"Hard see points. Add jitter.","code":"\nggplot(\n  data = organdata,\n  mapping = aes(\n    x = reorder(country, donors, na.rm = TRUE),\n    y = donors, color = world\n  )\n) +\n  geom_point() +\n  labs(x = NULL) +\n  coord_flip() +\n  theme(legend.position = \"bottom\")\nggplot(\n  data = organdata,\n  mapping = aes(\n    x = reorder(country, donors, na.rm = TRUE),\n    y = donors, color = world\n  )\n) +\n  geom_jitter() +\n  labs(x = NULL) +\n  coord_flip() +\n  theme(legend.position = \"bottom\")"},{"path":"show-the-numbers.html","id":"cleveland-dotplot","chapter":"Day 2 Showing the right numbers","heading":"2.8.5 Cleveland dotplot","text":"","code":""},{"path":"show-the-numbers.html","id":"calculate-summary-statistics","chapter":"Day 2 Showing the right numbers","heading":"2.8.5.1 Calculate summary statistics","text":"Better approach using efficient code.","code":"\n(by_country <- organdata %>%\n  group_by(consent_law, country) %>%\n  summarize(\n    donors_mean = mean(donors, na.rm = TRUE),\n    donors_sd = sd(donors, na.rm = TRUE),\n    gdp_mean = mean(gdp, na.rm = TRUE),\n    health_mean = mean(health, na.rm = TRUE),\n    roads_mean = mean(roads, na.rm = TRUE),\n    cerebvas_mean = mean(cerebvas, na.rm = TRUE)\n  ))\n## # A tibble: 17 × 8\n## # Groups:   consent_law [2]\n##    consent_law country     donors_mean donors_sd gdp_mean health_mean roads_mean\n##    <chr>       <chr>             <dbl>     <dbl>    <dbl>       <dbl>      <dbl>\n##  1 Informed    Australia          10.6     1.14    22179.       1958.      105. \n##  2 Informed    Canada             14.0     0.751   23711.       2272.      109. \n##  3 Informed    Denmark            13.1     1.47    23722.       2054.      102. \n##  4 Informed    Germany            13.0     0.611   22163.       2349.      113. \n##  5 Informed    Ireland            19.8     2.48    20824.       1480.      118. \n##  6 Informed    Netherlands        13.7     1.55    23013.       1993.       76.1\n##  7 Informed    United Kin…        13.5     0.775   21359.       1561.       67.9\n##  8 Informed    United Sta…        20.0     1.33    29212.       3988.      155. \n##  9 Presumed    Austria            23.5     2.42    23876.       1875.      150. \n## 10 Presumed    Belgium            21.9     1.94    22500.       1958.      155. \n## 11 Presumed    Finland            18.4     1.53    21019.       1615.       93.6\n## 12 Presumed    France             16.8     1.60    22603.       2160.      156. \n## 13 Presumed    Italy              11.1     4.28    21554.       1757       122. \n## 14 Presumed    Norway             15.4     1.11    26448.       2217.       70.0\n## 15 Presumed    Spain              28.1     4.96    16933        1289.      161. \n## 16 Presumed    Sweden             13.1     1.75    22415.       1951.       72.3\n## 17 Presumed    Switzerland        14.2     1.71    27233        2776.       96.4\n## # … with 1 more variable: cerebvas_mean <dbl>\n(by_country <- organdata %>%\n  group_by(consent_law, country) %>%\n  summarize(across(where(is.numeric), list(mean = mean, sd = sd), na.rm = TRUE)) %>%\n  ungroup())\n## # A tibble: 17 × 28\n##    consent_law country       donors_mean donors_sd pop_mean pop_sd pop_dens_mean\n##    <chr>       <chr>               <dbl>     <dbl>    <dbl>  <dbl>         <dbl>\n##  1 Informed    Australia            10.6     1.14    18318. 8.31e2         0.237\n##  2 Informed    Canada               14.0     0.751   29608. 1.19e3         0.297\n##  3 Informed    Denmark              13.1     1.47     5257. 8.06e1        12.2  \n##  4 Informed    Germany              13.0     0.611   80255. 5.16e3        22.5  \n##  5 Informed    Ireland              19.8     2.48     3674. 1.32e2         5.23 \n##  6 Informed    Netherlands          13.7     1.55    15548. 3.73e2        37.4  \n##  7 Informed    United Kingd…        13.5     0.775   58187. 6.26e2        24.0  \n##  8 Informed    United States        20.0     1.33   269330. 1.25e4         2.80 \n##  9 Presumed    Austria              23.5     2.42     7927. 1.09e2         9.45 \n## 10 Presumed    Belgium              21.9     1.94    10153. 1.09e2        30.7  \n## 11 Presumed    Finland              18.4     1.53     5112. 6.86e1         1.51 \n## 12 Presumed    France               16.8     1.60    58056. 8.51e2        10.5  \n## 13 Presumed    Italy                11.1     4.28    57360. 4.25e2        19.0  \n## 14 Presumed    Norway               15.4     1.11     4386. 9.73e1         1.35 \n## 15 Presumed    Spain                28.1     4.96    39666. 9.51e2         7.84 \n## 16 Presumed    Sweden               13.1     1.75     8789. 1.14e2         1.95 \n## 17 Presumed    Switzerland          14.2     1.71     7037. 1.70e2        17.0  \n## # … with 21 more variables: pop_dens_sd <dbl>, gdp_mean <dbl>, gdp_sd <dbl>,\n## #   gdp_lag_mean <dbl>, gdp_lag_sd <dbl>, health_mean <dbl>, health_sd <dbl>,\n## #   health_lag_mean <dbl>, health_lag_sd <dbl>, pubhealth_mean <dbl>,\n## #   pubhealth_sd <dbl>, roads_mean <dbl>, roads_sd <dbl>, cerebvas_mean <dbl>,\n## #   cerebvas_sd <dbl>, assault_mean <dbl>, assault_sd <dbl>,\n## #   external_mean <dbl>, external_sd <dbl>, txp_pop_mean <dbl>,\n## #   txp_pop_sd <dbl>"},{"path":"show-the-numbers.html","id":"draw-the-plot","chapter":"Day 2 Showing the right numbers","heading":"2.8.5.2 Draw the plot","text":"","code":"\nggplot(\n  data = by_country,\n  mapping = aes(\n    x = donors_mean,\n    y = reorder(country, donors_mean),\n    color = consent_law\n  )\n) +\n  geom_point(size = 3) +\n  labs(\n    x = \"Donor Procurement Rate\",\n    y = \"\", color = \"Consent Law\"\n  ) +\n  theme(legend.position = \"top\")"},{"path":"show-the-numbers.html","id":"use-facet-instead-of-color","chapter":"Day 2 Showing the right numbers","heading":"2.8.5.3 Use facet instead of color","text":"Allow \\(y\\)-axis vary include matching countries.","code":"\nggplot(\n  data = by_country,\n  mapping = aes(\n    x = donors_mean,\n    y = reorder(country, donors_mean)\n  )\n) +\n  geom_point(size = 3) +\n  facet_wrap(~consent_law, ncol = 1) +\n  labs(\n    x = \"Donor Procurement Rate\",\n    y = \"\", color = \"Consent Law\"\n  )\nggplot(\n  data = by_country,\n  mapping = aes(\n    x = donors_mean,\n    y = reorder(country, donors_mean)\n  )\n) +\n  geom_point(size = 3) +\n  facet_wrap(~consent_law, scales = \"free_y\", ncol = 1) +\n  labs(\n    x = \"Donor Procurement Rate\",\n    y = \"\", color = \"Consent Law\"\n  )"},{"path":"show-the-numbers.html","id":"add-standard-deviation","chapter":"Day 2 Showing the right numbers","heading":"2.8.5.4 Add standard deviation","text":"","code":"\nggplot(\n  data = by_country,\n  mapping = aes(\n    x = reorder(country, donors_mean),\n    y = donors_mean\n  )\n) +\n  geom_pointrange(mapping = aes(\n    ymin = donors_mean - donors_sd,\n    ymax = donors_mean + donors_sd\n  )) +\n  labs(\n    x = \"\",\n    y = \"Donor Procurement Rate\"\n  ) +\n  coord_flip()"},{"path":"show-the-numbers.html","id":"plot-text-directly","chapter":"Day 2 Showing the right numbers","heading":"2.9 Plot text directly","text":"","code":""},{"path":"show-the-numbers.html","id":"geom_text","chapter":"Day 2 Showing the right numbers","heading":"2.9.1 geom_text()","text":"","code":"\nggplot(\n  data = by_country,\n  mapping = aes(\n    x = roads_mean,\n    y = donors_mean\n  )\n) +\n  geom_point() +\n  geom_text(mapping = aes(label = country))\nggplot(\n  data = by_country,\n  mapping = aes(\n    x = roads_mean,\n    y = donors_mean\n  )\n) +\n  geom_point() +\n  geom_text(mapping = aes(label = country), hjust = 0)"},{"path":"show-the-numbers.html","id":"ggrepelgeom_text_repel","chapter":"Day 2 Showing the right numbers","heading":"2.10 ggrepel::geom_text_repel()","text":"","code":"\nelections_historic %>%\n  select(2:7)\n## # A tibble: 49 × 6\n##     year winner                 win_party ec_pct popular_pct popular_margin\n##    <int> <chr>                  <chr>      <dbl>       <dbl>          <dbl>\n##  1  1824 John Quincy Adams      D.-R.      0.322       0.309        -0.104 \n##  2  1828 Andrew Jackson         Dem.       0.682       0.559         0.122 \n##  3  1832 Andrew Jackson         Dem.       0.766       0.547         0.178 \n##  4  1836 Martin Van Buren       Dem.       0.578       0.508         0.142 \n##  5  1840 William Henry Harrison Whig       0.796       0.529         0.0605\n##  6  1844 James Polk             Dem.       0.618       0.495         0.0145\n##  7  1848 Zachary Taylor         Whig       0.562       0.473         0.0479\n##  8  1852 Franklin Pierce        Dem.       0.858       0.508         0.0695\n##  9  1856 James Buchanan         Dem.       0.588       0.453         0.122 \n## 10  1860 Abraham Lincoln        Rep.       0.594       0.396         0.101 \n## # … with 39 more rows\np_title <- \"Presidential Elections: Popular & Electoral College Margins\"\np_subtitle <- \"1824-2016\"\np_caption <- \"Data for 2016 are provisional.\"\nx_label <- \"Winner's share of Popular Vote\"\ny_label <- \"Winner's share of Electoral College Votes\"\n\nlibrary(ggrepel)\n\nggplot(data = elections_historic, mapping = aes(\n  x = popular_pct,\n  y = ec_pct,\n  label = winner_label\n)) +\n  geom_hline(yintercept = 0.5, size = 1.4, color = \"gray80\") +\n  geom_vline(xintercept = 0.5, size = 1.4, color = \"gray80\") +\n  geom_point() +\n  geom_text_repel() +\n  scale_x_continuous(labels = scales::percent) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(\n    x = x_label, y = y_label, title = p_title, subtitle = p_subtitle,\n    caption = p_caption\n  )"},{"path":"show-the-numbers.html","id":"label-outliers-only","chapter":"Day 2 Showing the right numbers","heading":"2.10.1 Label outliers only","text":"","code":"\nggplot(\n  data = by_country,\n  mapping = aes(x = gdp_mean, y = health_mean)\n) +\n  geom_point() +\n  geom_text_repel(\n    data = filter(by_country, gdp_mean > 25000),\n    mapping = aes(label = country)\n  )\n\nggplot(\n  data = by_country,\n  mapping = aes(x = gdp_mean, y = health_mean)\n) +\n  geom_point() +\n  geom_text_repel(\n    data = filter(\n      by_country,\n      gdp_mean > 25000 | health_mean < 1500 |\n        country %in% \"Belgium\"\n    ),\n    mapping = aes(label = country)\n  )"},{"path":"show-the-numbers.html","id":"scales-guides-and-themes","chapter":"Day 2 Showing the right numbers","heading":"2.11 Scales, guides, and themes","text":"Scale functions control scale mappings geoms. Remember: just x y also color, fill, shape, size scales. visually represent quantities categories data – thus, scale associated \nrepresentation. means control things like color schemes data mappings scale functions.","code":"\np <- ggplot(\n  data = gapminder,\n  mapping =\n    aes(\n      x = gdpPercap,\n      y = lifeExp,\n      color = continent, fill = continent\n    )\n)\n\np + geom_point() +\n  geom_smooth(method = \"loess\") +\n  scale_x_log10()scale_<MAPPING>_<KIND>()\n\nscale_x_continuous()\nscale_y_continuous()\nscale_x_discrete()\nscale_y_discrete()\nscale_x_log10()\nscale_x_sqrt()"},{"path":"show-the-numbers.html","id":"labels-breaks-and-limits","chapter":"Day 2 Showing the right numbers","heading":"2.11.1 Labels, breaks, and limits","text":"","code":"\np <- ggplot(\n  data = organdata,\n  mapping = aes(\n    x = roads,\n    y = donors, color = world\n  )\n)\n\np + geom_point() +\n  scale_x_log10() + scale_y_continuous(\n    breaks = c(5, 15, 25),\n    labels = c(\"Five\", \"Fifteen\", \"Twenty Five\")\n  )\np <- ggplot(\n  data = organdata,\n  mapping = aes(\n    x = roads,\n    y = donors, color = world\n  )\n)\n\np + geom_point() + scale_color_discrete(\n  labels =\n    c(\n      \"Corporatist\", \"Liberal\",\n      \"Social Democratic\", \"Unclassified\"\n    )\n) +\n  labs(\n    x = \"Road Deaths\",\n    y = \"Donor Procurement\",\n    color = \"Welfare State\"\n  )\np <- ggplot(data = organdata, mapping = aes(\n  x = roads,\n  y = donors, color = world\n))\np + geom_point() +\n  labs(\n    x = \"Road Deaths\",\n    y = \"Donor Procurement\"\n  ) + guides(color = FALSE)"},{"path":"show-the-numbers.html","id":"mapping-data-to-graphics","chapter":"Day 2 Showing the right numbers","heading":"2.12 Mapping data to graphics","text":"Download necessary data files following coding exercises using usethis::use_course(\"css-data-mining-viz/show--numbers\").example, ’m going use real world data demonstrate typical process loading data, cleaning bit, mapping specific columns data onto parts graph using grammar graphics ggplot().data ’ll use comes BBC’s corporate charity, BBC Children Need, makes grants smaller UK nonprofit organizations work issues related childhood poverty. organization UK named 360Giving helps nonprofits foundations publish data grant giving activities open standardized way, (May 2020) list data 126 different charities, including BBC Children Need.want follow along example (highly recommended!), can download data directly website.","code":""},{"path":"show-the-numbers.html","id":"load-and-clean-data","chapter":"Day 2 Showing the right numbers","heading":"2.12.1 Load and clean data","text":"First, need load libraries: tidyverse (always), along readxl reading Excel files lubridate working dates:’ll load original Excel file. placed file folder named data RStudio Project folder example. ’s also good practice keep pristine, untouched copy data.may errors reading file – can ignore case.Next ’ll add couple columns clean data little.’ll extract year Award Date column, rename longer-named columns, make new column shows duration grants. ’ll also get rid 2015 since observations .Note strange use `s around column names like `Award Date`. R technically doesn’t allow special characters like spaces column names. spaces, wrap column names backticks. typing backticks time gets tedious, ’ll use rename() rename columns:","code":"\n# Load libraries\nlibrary(tidyverse)  # For ggplot, dplyr, and friends\nlibrary(readxl)     # For reading Excel files\nlibrary(lubridate)  # For working with dates\n# Load the original Excel file\nbbc_raw <- read_excel(\"data/360-giving-data.xlsx\")\nbbc <- bbc_raw %>% \n  # Extract the year from the award date\n  mutate(grant_year = year(`Award Date`)) %>% \n  # Rename some columns\n  rename(grant_amount = `Amount Awarded`,\n         grant_program = `Grant Programme:Title`,\n         grant_duration = `Planned Dates:Duration (months)`) %>% \n  # Make a new text-based version of the duration column, recoding months\n  # between 12-23, 23-35, and 36+. The case_when() function here lets us use\n  # multiple if/else conditions at the same time.\n  mutate(grant_duration_text = case_when(\n    grant_duration >= 12 & grant_duration < 24 ~ \"1 year\",\n    grant_duration >= 24 & grant_duration < 36 ~ \"2 years\",\n    grant_duration >= 36 ~ \"3 years\"\n  )) %>% \n  # Get rid of anything before 2016\n  filter(grant_year > 2015) %>% \n  # Make a categorical version of the year column\n  mutate(grant_year_category = factor(grant_year))"},{"path":"show-the-numbers.html","id":"histograms","chapter":"Day 2 Showing the right numbers","heading":"2.12.2 Histograms","text":"First let’s look distribution grant amounts histogram. Map grant_amount x-axis don’t map anything y-axis, since geom_histogram() calculate y-axis values us:Notice ggplot warns bin widths. default divide data 30 equally spaced bins, likely best data. always set bin width something appropriate. rules correct bin widths. Just don’t wide:small:£10,000 seems fit well. ’s often helpful add white border histogram bars, :can map variables onto plot, like mapping grant_year_category fill aesthetic:gets really hard interpret though, can facet year facet_wrap():Neat!","code":"\nggplot(data = bbc, mapping = aes(x = grant_amount)) +\n  geom_histogram()\nggplot(data = bbc, mapping = aes(x = grant_amount)) +\n  geom_histogram(binwidth = 100000)\nggplot(data = bbc, mapping = aes(x = grant_amount)) +\n  geom_histogram(binwidth = 500)\nggplot(data = bbc, mapping = aes(x = grant_amount)) +\n  geom_histogram(binwidth = 10000, color = \"white\")\nggplot(bbc, aes(x = grant_amount, fill = grant_year_category)) +\n  geom_histogram(binwidth = 10000, color = \"white\")\nggplot(bbc, aes(x = grant_amount, fill = grant_year_category)) +\n  geom_histogram(binwidth = 10000, color = \"white\") +\n  facet_wrap(vars(grant_year))"},{"path":"show-the-numbers.html","id":"points","chapter":"Day 2 Showing the right numbers","heading":"2.12.3 Points","text":"Next let’s look data using points, mapping year x-axis grant amount y-axis:serious overplotting , dots thick looks like lines. can fix couple different ways. First, can make points semi-transparent using alpha, ranges 0 (completely invisible) 1 (completely solid).can also randomly space points spread using position_jitter():One issue , though, points jittered along x-axis (fine, since ’re within year) y-axis (bad, since amounts actual numbers). can tell ggplot jitter one direction specifying height argument—don’t want --jittering:weird clusters around £30,000 . Let’s map grant_program color aesthetic, two categories—regular grants small grants—see helps explain :! appear two different distributions grants: small grants limit £30,000, regular grants much higher average amount.","code":"\nggplot(bbc, aes(x = grant_year_category, y = grant_amount)) +\n  geom_point()\nggplot(bbc, aes(x = grant_year_category, y = grant_amount)) +\n  geom_point(alpha = 0.1)\nggplot(bbc, aes(x = grant_year_category, y = grant_amount)) +\n  geom_point(position = position_jitter())\nggplot(bbc, aes(x = grant_year_category, y = grant_amount)) +\n  geom_point(position = position_jitter(height = 0))\nggplot(bbc, aes(x = grant_year_category, y = grant_amount, color = grant_program)) +\n  geom_point(position = position_jitter(height = 0))"},{"path":"show-the-numbers.html","id":"boxplots-1","chapter":"Day 2 Showing the right numbers","heading":"2.12.4 Boxplots","text":"can add summary information plot changing geom ’re using. Switch geom_point() geom_boxplot():","code":"\nggplot(bbc, aes(x = grant_year_category, y = grant_amount, color = grant_program)) +\n  geom_boxplot()"},{"path":"show-the-numbers.html","id":"summaries","chapter":"Day 2 Showing the right numbers","heading":"2.12.5 Summaries","text":"can also make smaller summarized datasets dplyr functions like group_by() summarize() plot . First let’s look grant totals, averages, counts time:used summarize(), R shrank data significantly. now row subgroups made: one year. can plot smaller data. ’ll use geom_col() now.Based charts, looks like 2016 saw largest average grant amount. years, grants averaged around £60,000, 2016 jumped £80,000. look total grants, though, can see far fewer grants awarded 2016—221! 2017 2018 much bigger years far money awarded.can also use multiple aesthetics reveal information data. First ’ll make new small summary dataset group year grant program. groups, ’ll calculate total, average, number.Next ’ll plot data, mapping grant_program column fill aesthetic:default, ggplot stack different fill colors within bar, makes little hard make comparisons. can see average small grant amount little bigger 2017 2019, ’s harder compare average main grant amount, since bottoms sections don’t align.fix , can use position_dodge() tell columns fit side--side:Instead dodging, can also facet grant_program separate bars:can put one column want:Finally, can include even variables! lot aesthetics can work (size, alpha, color, fill, linetype, etc.), well facets, let’s add one show duration awarded grant.First ’ll make another smaller summarized dataset, grouping year, program, duration summarizing total, average, number awards.Next, ’ll fill grant program facet duration show total number grants awardedThe vast majority BBC Children Need’s grants last 3 years. Super neat.","code":"\nbbc_by_year <- bbc %>% \n  group_by(grant_year) %>%  # Make invisible subgroups for each year\n  summarize(total = sum(grant_amount),  # Find the total awarded in each group\n            avg = mean(grant_amount),  # Find the average awarded in each group\n            number = n())  # n() is a special function that shows the number of rows in each group\n\n# Look at our summarized data\nbbc_by_year\n## # A tibble: 4 × 4\n##   grant_year    total    avg number\n##        <dbl>    <dbl>  <dbl>  <int>\n## 1       2016 17290488 78238.    221\n## 2       2017 62394278 59765.   1044\n## 3       2018 61349392 60205.   1019\n## 4       2019 41388816 61136.    677\n# Plot our summarized data\nggplot(bbc_by_year, aes(x = grant_year, y = avg)) +\n  geom_col()\n\nggplot(bbc_by_year, aes(x = grant_year, y = total)) +\n  geom_col()\n\nggplot(bbc_by_year, aes(x = grant_year, y = number)) +\n  geom_col()\nbbc_year_size <- bbc %>% \n  group_by(grant_year, grant_program) %>% \n  summarize(total = sum(grant_amount),\n            avg = mean(grant_amount),\n            number = n())\nbbc_year_size\n## # A tibble: 8 × 5\n## # Groups:   grant_year [4]\n##   grant_year grant_program    total    avg number\n##        <dbl> <chr>            <dbl>  <dbl>  <int>\n## 1       2016 Main Grants   16405586 86345.    190\n## 2       2016 Small Grants    884902 28545.     31\n## 3       2017 Main Grants   48502923 90154.    538\n## 4       2017 Small Grants  13891355 27453.    506\n## 5       2018 Main Grants   47347789 95652.    495\n## 6       2018 Small Grants  14001603 26721.    524\n## 7       2019 Main Grants   33019492 96267.    343\n## 8       2019 Small Grants   8369324 25058.    334\nggplot(bbc_year_size, aes(x = grant_year, y = total, fill = grant_program)) +\n  geom_col()\nggplot(bbc_year_size, aes(x = grant_year, y = total, fill = grant_program)) +\n  geom_col(position = position_dodge())\nggplot(bbc_year_size, aes(x = grant_year, y = total, fill = grant_program)) +\n  geom_col() +\n  facet_wrap(vars(grant_program))\nggplot(bbc_year_size, aes(x = grant_year, y = total, fill = grant_program)) +\n  geom_col() +\n  facet_wrap(vars(grant_program), ncol = 1)\nbbc_year_size_duration <- bbc %>% \n  group_by(grant_year, grant_program, grant_duration_text) %>% \n  summarize(total = sum(grant_amount),\n            avg = mean(grant_amount),\n            number = n())\nbbc_year_size_duration\n## # A tibble: 21 × 6\n## # Groups:   grant_year, grant_program [8]\n##    grant_year grant_program grant_duration_text    total    avg number\n##         <dbl> <chr>         <chr>                  <dbl>  <dbl>  <int>\n##  1       2016 Main Grants   2 years                97355 48678.      2\n##  2       2016 Main Grants   3 years             16308231 86746.    188\n##  3       2016 Small Grants  3 years               884902 28545.     31\n##  4       2017 Main Grants   1 year                 59586 29793       2\n##  5       2017 Main Grants   2 years               825732 82573.     10\n##  6       2017 Main Grants   3 years             47617605 90528.    526\n##  7       2017 Small Grants  1 year                 10000 10000       1\n##  8       2017 Small Grants  2 years               245227 18864.     13\n##  9       2017 Small Grants  3 years             13636128 27716.    492\n## 10       2018 Main Grants   1 year                118134 59067       2\n## # … with 11 more rows\nggplot(bbc_year_size_duration, aes(x = grant_year, y = number, fill = grant_program)) +\n  geom_col(position = position_dodge(preserve = \"single\")) +\n  facet_wrap(vars(grant_duration_text), ncol = 1)"},{"path":"show-the-numbers.html","id":"amounts-and-proportions","chapter":"Day 2 Showing the right numbers","heading":"2.13 Amounts and proportions","text":"example, ’re going use real world data demonstrate different ways visualize amounts proportions. ’ll use data CDC Social Security Administration number daily births United States 1994–2014. FiveThirtyEight reported story using data 2016 posted relatively CSV files GitHub, can download use .want follow along example, can download data directly GitHub using links (’ll likely need right click choose “Save Link …”):US_births_1994-2003_CDC_NCHS.csvUS_births_2000-2014_SSA.csv","code":""},{"path":"show-the-numbers.html","id":"load-data","chapter":"Day 2 Showing the right numbers","heading":"2.13.1 Load data","text":"two CSV files:US_births_1994-2003_CDC_NCHS.csv contains U.S. births data years 1994 2003, provided Centers Disease Control Prevention’s National Center Health Statistics.US_births_2000-2014_SSA.csv contains U.S. births data years 2000 2014, provided Social Security Administration.Since two datasets overlap 2000–2003, use Social Security Administration data years.downloaded data GitHub placed CSV files folder named data. ’ll load read_csv() combine one data frame.","code":"\nlibrary(tidyverse)\nlibrary(scales)   # For nice labels in charts\nbirths_1994_1999 <- read_csv(\"data/US_births_1994-2003_CDC_NCHS.csv\") %>% \n  # Ignore anything after 2000\n  filter(year < 2000)\nbirths_2000_2014 <- read_csv(\"data/US_births_2000-2014_SSA.csv\")\nbirths_combined <- bind_rows(births_1994_1999, births_2000_2014)"},{"path":"show-the-numbers.html","id":"wrangle-data","chapter":"Day 2 Showing the right numbers","heading":"2.13.2 Wrangle data","text":"Let’s look first rows data see ’re working :columns year births seem straightforward ready use. columns month day week improved changed text (.e. January instead 1; Tuesday instead 3). fix , can convert columns categorical variables, factors R. can also specify categories (factors) ordered, meaning Feburary comes January, etc. Without ordering, R plot alphabetically, isn’t helpful.’ll make new dataset named births ’s based combined births data, new columns added:look data now, can see columns changed different types. year date_of_month still numbers, month, day_of_week ordered factors (ord) date_of_month_categorical regular factor (fct). Technically ’s also ordered, ’s already alphabetical (.e. 2 naturally comes 1), don’t need force right order.births data now clean ready go!","code":"\nbirths_combined\n## # A tibble: 7,670 × 5\n##     year month date_of_month day_of_week births\n##    <dbl> <dbl>         <dbl>       <dbl>  <dbl>\n##  1  1994     1             1           6   8096\n##  2  1994     1             2           7   7772\n##  3  1994     1             3           1  10142\n##  4  1994     1             4           2  11248\n##  5  1994     1             5           3  11053\n##  6  1994     1             6           4  11406\n##  7  1994     1             7           5  11251\n##  8  1994     1             8           6   8653\n##  9  1994     1             9           7   7910\n## 10  1994     1            10           1  10498\n## # … with 7,660 more rows\n# The c() function lets us make a list of values\nmonth_names <- c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\",\n                 \"August\", \"September\", \"October\", \"November\", \"December\")\n\nday_names <- c(\"Monday\", \"Tuesday\", \"Wednesday\", \n               \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")\n\nbirths <- births_combined %>% \n  # Make month an ordered factor, using the month_name list as labels\n  mutate(month = factor(month, labels = month_names, ordered = TRUE)) %>% \n  mutate(day_of_week = factor(day_of_week, labels = day_names, ordered = TRUE),\n         date_of_month_categorical = factor(date_of_month)) %>% \n  # Add a column indicating if the day is on a weekend\n  mutate(weekend = ifelse(day_of_week %in% c(\"Saturday\", \"Sunday\"), TRUE, FALSE))\n\nhead(births)\n## # A tibble: 6 × 7\n##    year month   date_of_month day_of_week births date_of_month_categori… weekend\n##   <dbl> <ord>           <dbl> <ord>        <dbl> <fct>                   <lgl>  \n## 1  1994 January             1 Saturday      8096 1                       TRUE   \n## 2  1994 January             2 Sunday        7772 2                       TRUE   \n## 3  1994 January             3 Monday       10142 3                       FALSE  \n## 4  1994 January             4 Tuesday      11248 4                       FALSE  \n## 5  1994 January             5 Wednesday    11053 5                       FALSE  \n## 6  1994 January             6 Thursday     11406 6                       FALSE"},{"path":"show-the-numbers.html","id":"bar-plot","chapter":"Day 2 Showing the right numbers","heading":"2.13.3 Bar plot","text":"First can look bar chart showing total number births day. need make smaller summarized dataset ’ll plot :fill day week, get 7 different colors, fine (guess), doesn’t really help tell story. main story far fewer births weekends. create new column flags row Saturday Sunday, can fill column instead:Neat! default colors kinda ugly, though, let’s use principles preattentive processing contrast highlight weekend bars:","code":"\ntotal_births_weekday <- births %>% \n  group_by(day_of_week) %>% \n  summarize(total = sum(births))\n\nggplot(data = total_births_weekday,\n       mapping = aes(x = day_of_week, y = total, fill = day_of_week)) +\n  geom_col() +\n  # Turn off the fill legend because it's redundant\n  guides(fill = FALSE)\ntotal_births_weekday <- births %>% \n  group_by(day_of_week) %>% \n  summarize(total = sum(births)) %>% \n  mutate(weekend = day_of_week %in% c(\"Saturday\", \"Sunday\"))\n\nggplot(data = total_births_weekday,\n       mapping = aes(x = day_of_week, y = total, fill = weekend)) +\n  geom_col()\nggplot(data = total_births_weekday,\n       mapping = aes(x = day_of_week, y = total, fill = weekend)) +\n  geom_col() +\n  # Use grey and orange\n  scale_fill_manual(values = c(\"grey70\", \"#f2ad22\")) +\n  # Use commas instead of scientific notation\n  scale_y_continuous(labels = comma) +\n  # Turn off the legend since the title shows what the orange is\n  guides(fill = FALSE) +\n  labs(title = \"Weekends are unpopular times for giving birth\",\n       x = NULL, y = \"Total births\")"},{"path":"show-the-numbers.html","id":"lollipop-chart","chapter":"Day 2 Showing the right numbers","heading":"2.13.4 Lollipop chart","text":"Since ends bars often important part graph, can use lollipop chart emphasize . ’ll keep code bar chart make changes:Color weekend instead fill weekend, since points lines colored ggplot, filledSwitch scale_fill_manual() scale_color_manual() turn color legend guides() layerSwitch geom_col() geom_pointrange(). geom_pointrange() layer requires two additional aesthetics: ymin ymax ends lines come point. ’ll set ymin 0 starts x-axis, ’ll set ymax total ends point.","code":"\nggplot(data = total_births_weekday,\n       mapping = aes(x = day_of_week, y = total, color = weekend)) +\n  geom_pointrange(aes(ymin = 0, ymax = total),\n                  # Make the lines a little thicker and the dots a little bigger\n                  fatten = 5, size = 1.5) +\n  # Use grey and orange\n  scale_color_manual(values = c(\"grey70\", \"#f2ad22\")) +\n  # Use commas instead of scientific notation\n  scale_y_continuous(labels = comma) +\n  # Turn off the legend since the title shows what the orange is\n  guides(color = FALSE) +\n  labs(title = \"Weekends are unpopular times for giving birth\",\n       x = NULL, y = \"Total births\")"},{"path":"show-the-numbers.html","id":"strip-plot","chapter":"Day 2 Showing the right numbers","heading":"2.13.5 Strip plot","text":"Let’s show data points. ’ll use full dataset now, map x weekday, y births, change geom_col() geom_point(). ’ll tell geom_point() jitter points randomly.interesting points low ends, likely holidays like Labor Day Memorial Day (Mondays) Thanksgiving (Thursday). column indicated whether day holiday, color probably explain low numbers. Unfortunately don’t column, ’d hard make. holidays constant (Halloween always October 31), aren’t (Thanksgiving fourth Thursday November, ’d need find November 20-somethingth year fourth Thursday, good luck scale).","code":"\nggplot(data = births,\n       mapping = aes(x = day_of_week, y = births, color = weekend)) +\n  scale_color_manual(values = c(\"grey70\", \"#f2ad22\")) +\n  geom_point(size = 0.5, position = position_jitter(height = 0)) +\n  guides(color = FALSE)"},{"path":"show-the-numbers.html","id":"beeswarm-plot","chapter":"Day 2 Showing the right numbers","heading":"2.13.6 Beeswarm plot","text":"can add structure points use ggbeeswarm package, either geom_beeswarm() geom_quasirandom(). geom_quasirandom() actually works better since many points – geom_beeswarm() makes clusters points way wide.","code":"\nlibrary(ggbeeswarm)\nggplot(data = births,\n       mapping = aes(x = day_of_week, y = births, color = weekend)) +\n  scale_color_manual(values = c(\"grey70\", \"#f2ad22\")) +\n  # Make these points suuuper tiny\n  geom_quasirandom(size = 0.0001) +\n  guides(color = FALSE)"},{"path":"show-the-numbers.html","id":"heatmap","chapter":"Day 2 Showing the right numbers","heading":"2.13.7 Heatmap","text":"Finally, let’s use something non-traditional show average births day somewhat proportional way. can calculate average number births every day make heatmap fills square average, thus showing relative differences births per day., need make summarized data frame group_by() %>% summarize() calculate average number births month day month (.e. average January 1, January 2, etc.).’ll make sort calendar date month x axis, month y axis, heat map squares filled daily average. ’ll use geom_tile() add squares day, add extra scale, coordinates, theme layers clean plot:Neat! really interesting trends . obvious, probably, people born New Year’s Day, July 4th, Halloween, Thanksgiving, Christmas.days highest average mid-September, likely ’s 9 months first week January. July 7th #7 odd idea might popular.funniest trend visible dark column 13th every month. People really don’t want give birth 13th.","code":"\navg_births_month_day <- births %>% \n  group_by(month, date_of_month_categorical) %>% \n  summarize(avg_births = mean(births))\n\nggplot(data = avg_births_month_day,\n       # By default, the y-axis will have December at the top, so use fct_rev() to reverse it\n       mapping = aes(x = date_of_month_categorical, y = fct_rev(month), fill = avg_births)) +\n  geom_tile() +\n  # Add viridis colors\n  scale_fill_viridis_c(option = \"inferno\", labels = comma) + \n  # Add nice labels\n  labs(x = \"Day of the month\", y = NULL,\n       title = \"Average births per day\",\n       subtitle = \"1994-2014\",\n       fill = \"Average births\") +\n  # Force all the tiles to have equal widths and heights\n  coord_equal() +\n  # Use a cleaner theme\n  theme_minimal()\navg_births_month_day %>% \n  arrange(avg_births)\n## # A tibble: 366 × 3\n## # Groups:   month [12]\n##    month    date_of_month_categorical avg_births\n##    <ord>    <fct>                          <dbl>\n##  1 December 25                             6601.\n##  2 January  1                              7827.\n##  3 December 24                             8103.\n##  4 July     4                              8825.\n##  5 January  2                              9356.\n##  6 December 26                             9599.\n##  7 November 27                             9770.\n##  8 November 23                             9919.\n##  9 November 25                            10001 \n## 10 October  31                            10030.\n## # … with 356 more rows\navg_births_month_day %>% \n  arrange(desc(avg_births))\n## # A tibble: 366 × 3\n## # Groups:   month [12]\n##    month     date_of_month_categorical avg_births\n##    <ord>     <fct>                          <dbl>\n##  1 September 9                             12344.\n##  2 September 19                            12285.\n##  3 September 12                            12282.\n##  4 September 17                            12201.\n##  5 September 10                            12190.\n##  6 September 20                            12162.\n##  7 July      7                             12147.\n##  8 September 15                            12126.\n##  9 September 16                            12114.\n## 10 September 18                            12112.\n## # … with 356 more rows"},{"path":"show-the-numbers.html","id":"comparisons","chapter":"Day 2 Showing the right numbers","heading":"2.14 Comparisons","text":"example, ’re going use cross-national data, instead using typical gapminder dataset, ’re going collect data directly World Bank’s Open Data portalIf want skip data downloading, can download data (’ll likely need right click choose “Save Link …”):wdi_raw.csv","code":""},{"path":"show-the-numbers.html","id":"load-and-clean-data-1","chapter":"Day 2 Showing the right numbers","heading":"2.14.1 Load and clean data","text":"First, load libraries ’ll using:World Bank ton country-level data data.worldbank.org. can use package named WDI (world development indicators) access servers download data directly R., need find special World Bank codes specific variables want get. codes come URLs World Bank’s website. instance, search “access electricity” World Bank’s website, ’ll find page. look end URL, ’ll see cryptic code: EG.ELC.ACCS.ZS. ’s World Bank’s ID code “Access electricity (% population)” indicator.can feed list ID codes WDI() function download data specific indicators. want data 1995-2015, set start end years accordingly. extra=TRUE argument means ’ll also include helpful details like region, aid status, etc. Without , download indicators listed.Downloading data World Bank every time knit get tedious take long time (plus servers temporarily , won’t able get data). ’s good practice save raw data CSV file work .clean data little, filtering rows aren’t actually countries renaming ugly World Bank code columns actual words:","code":"\nlibrary(tidyverse)  # For ggplot, dplyr, and friends\nlibrary(WDI)        # For getting data from the World Bank\nlibrary(geofacet)   # For map-shaped facets\nlibrary(scales)     # For helpful scale functions like dollar()\nlibrary(ggrepel)    # For non-overlapping labels\nindicators <- c(\"SP.DYN.LE00.IN\",  # Life expectancy\n                \"EG.ELC.ACCS.ZS\",  # Access to electricity\n                \"EN.ATM.CO2E.PC\",  # CO2 emissions\n                \"NY.GDP.PCAP.KD\")  # GDP per capita\n\nwdi_raw <- WDI(country = \"all\", indicators, extra = TRUE, \n               start = 1995, end = 2015)\n\nhead(wdi_raw)\nwrite_csv(wdi_raw, \"data/wdi_raw.csv\")\nwdi_clean <- wdi_raw %>% \n  filter(region != \"Aggregates\") %>% \n  select(iso2c, country, year, \n         life_expectancy = SP.DYN.LE00.IN, \n         access_to_electricity = EG.ELC.ACCS.ZS, \n         co2_emissions = EN.ATM.CO2E.PC, \n         gdp_per_cap = NY.GDP.PCAP.KD, \n         region, income)\n\nhead(wdi_clean)\n## # A tibble: 6 × 9\n##   iso2c country  year life_expectancy access_to_elect… co2_emissions gdp_per_cap\n##   <chr> <chr>   <dbl>           <dbl>            <dbl>         <dbl>       <dbl>\n## 1 AD    Andorra  2015              NA              100         NA         41768.\n## 2 AD    Andorra  2004              NA              100          7.36      47033.\n## 3 AD    Andorra  2001              NA              100          7.79      41421.\n## 4 AD    Andorra  2002              NA              100          7.59      42396.\n## 5 AD    Andorra  2014              NA              100          5.83      40790.\n## 6 AD    Andorra  1995              NA              100          6.66      32918.\n## # … with 2 more variables: region <chr>, income <chr>"},{"path":"show-the-numbers.html","id":"small-multiples","chapter":"Day 2 Showing the right numbers","heading":"2.14.2 Small multiples","text":"First can make small multiples plots show life expectancy time handful countries. ’ll make list countries chosen random scrolled data, filter data include rows. plot life expectancy, faceting country.Small multiples! ’s need .can fancier things, though. can make plot hyper minimalist:can whole part continent (poor Iraq Syria)can use geofacet package arrange facets geography:Neat!","code":"\nlife_expectancy_small <- wdi_clean %>%\n  filter(country %in% c(\"Afghanistan\", \"Belarus\", \"India\",\n                        \"Mexico\", \"New Zealand\", \"Spain\"))\n\nggplot(data = life_expectancy_small, \n       mapping = aes(x = year, y = life_expectancy)) +\n  geom_line(size = 1) +\n  facet_wrap(vars(country))\nggplot(data = life_expectancy_small, \n       mapping = aes(x = year, y = life_expectancy)) +\n  geom_line(size = 1) +\n  facet_wrap(vars(country), scales = \"free_y\") +\n  theme_void() +\n  theme(strip.text = element_text(face = \"bold\"))\nlife_expectancy_mena <- wdi_clean %>% \n  filter(region == \"Middle East & North Africa\")\n\nggplot(data = life_expectancy_mena, \n       mapping = aes(x = year, y = life_expectancy)) +\n  geom_line(size = 1) +\n  facet_wrap(vars(country), scales = \"free_y\", nrow = 3) +\n  theme_void() +\n  theme(strip.text = element_text(face = \"bold\"))\nlife_expectancy_eu <- wdi_clean %>% \n  filter(region == \"Europe & Central Asia\")\n\nggplot(life_expectancy_eu, aes(x = year, y = life_expectancy)) +\n  geom_line(size = 1) +\n  facet_geo(vars(country), grid = \"eu_grid1\", scales = \"free_y\") +\n  labs(x = NULL, y = NULL, title = \"Life expectancy from 1995–2015\",\n       caption = \"Source: The World Bank (SP.DYN.LE00.IN)\") +\n  theme_minimal() +\n  theme(strip.text = element_text(face = \"bold\"),\n        plot.title = element_text(face = \"bold\"),\n        axis.text.x = element_text(angle = 45, hjust = 1))"},{"path":"show-the-numbers.html","id":"sparklines","chapter":"Day 2 Showing the right numbers","heading":"2.14.3 Sparklines","text":"Sparklines just line charts (bar charts) really really small.can use saved tiny plots text.India  China  seen increased CO2 emissions past 20 years.","code":"\nindia_co2 <- wdi_clean %>% \n  filter(country == \"India\")\n\nplot_india <- ggplot(india_co2, aes(x = year, y = co2_emissions)) +\n  geom_line() +\n  theme_void()\nplot_india\nggsave(\"india_co2.pdf\", plot_india, width = 1, height = 0.15, units = \"in\")\nggsave(\"india_co2.png\", plot_india, width = 1, height = 0.15, units = \"in\")\nchina_co2 <- wdi_clean %>% \n  filter(country == \"China\")\n\nplot_china <- ggplot(china_co2, aes(x = year, y = co2_emissions)) +\n  geom_line() +\n  theme_void()\nplot_china\nggsave(\"china_co2.pdf\", plot_china, width = 1, height = 0.15, units = \"in\")\nggsave(\"china_co2.png\", plot_china, width = 1, height = 0.15, units = \"in\")"},{"path":"show-the-numbers.html","id":"slopegraphs","chapter":"Day 2 Showing the right numbers","heading":"2.14.4 Slopegraphs","text":"can make slopegraph show changes GDP per capita two time periods. need first filter WDI include start end years (1995 2015). , make sure ’re using complete data, ’ll get rid country missing data either 1995 2015. group_by(...) %>% filter(...) %>% ungroup() pipeline , !(.na(gdp_per_cap)) test keeping rows gdp_per_cap values missing whole country.add couple special columns labels. paste0() function concatenates strings variables together, paste0(\"2 + 2 = \", 2 + 2) show “2 + 2 = 4”. make labels say either “Country name: $GDP” “$GDP” depending year.data filtered like , can plot mapping year x-axis, GDP per capita y-axis, coloring country. make lines go across two categorical labels x-axis (since made year factor/category), need also specify group aesthetic.Cool! ’re getting closer. can definitely see different slopes, 7 different colors, ’s hard see exactly country . Instead, can directly label lines geom_text():gets us little closer, country labels hard see, include information, like actual values. Remember label_first label_last columns made? Let’s use instead:Now dollar amounts country names, labels still overlapping really hard read. fix , can make labels repel away randomly position way makes overlap. ggrepel package lets us geom_text_repel()Now none labels top , labels still top lines. Also, labels moved inward outward along x-axis, don’t need —just need shift . can force labels move setting direction = \"y\" argument, can move labels left right nudge_x argument. seed argument makes sure random label placement every time run . can whatever number want—just number.’s ! Let’s take theme completely, change colors little, perfect.","code":"\ngdp_south_asia <- wdi_clean %>% \n  filter(region == \"South Asia\") %>% \n  filter(year %in% c(1995, 2015)) %>% \n  # Look at each country individually\n  group_by(country) %>%\n  # Remove the country if any of its gdp_per_cap values are missing\n  filter(!any(is.na(gdp_per_cap))) %>%\n  ungroup() %>%\n  # Make year a factor\n  mutate(year = factor(year)) %>% \n  # Make some nice label columns\n  # If the year is 1995, format it like \"Country name: $GDP\". If the year is\n  # 2015, format it like \"$GDP\"\n  mutate(label_first = ifelse(year == 1995, str_c(country, \": \", dollar(round(gdp_per_cap))), NA),\n         label_last = ifelse(year == 2015, dollar(round(gdp_per_cap, 0)), NA))\nggplot(gdp_south_asia, aes(x = year, y = gdp_per_cap, group = country, color = country)) +\n  geom_line(size = 1.5)\nggplot(gdp_south_asia, aes(x = year, y = gdp_per_cap, group = country, color = country)) +\n  geom_line(size = 1.5) +\n  geom_text(aes(label = country)) +\n  guides(color = FALSE)\nggplot(gdp_south_asia, aes(x = year, y = gdp_per_cap, group = country, color = country)) +\n  geom_line(size = 1.5) +\n  geom_text(aes(label = label_first)) +\n  geom_text(aes(label = label_last)) +\n  guides(color = FALSE)\nggplot(gdp_south_asia, aes(x = year, y = gdp_per_cap, group = country, color = country)) +\n  geom_line(size = 1.5) +\n  geom_text_repel(aes(label = label_first)) +\n  geom_text_repel(aes(label = label_last)) +\n  guides(color = FALSE)\nggplot(gdp_south_asia, aes(x = year, y = gdp_per_cap, group = country, color = country)) +\n  geom_line(size = 1.5) +\n  geom_text_repel(aes(label = label_first), direction = \"y\", nudge_x = -1, seed = 1234) +\n  geom_text_repel(aes(label = label_last), direction = \"y\", nudge_x = 1, seed = 1234) +\n  guides(color = FALSE)\nggplot(gdp_south_asia, aes(x = year, y = gdp_per_cap, group = country, color = country)) +\n  geom_line(size = 1.5) +\n  geom_text_repel(aes(label = label_first), direction = \"y\", nudge_x = -1, seed = 1234) +\n  geom_text_repel(aes(label = label_last), direction = \"y\", nudge_x = 1, seed = 1234) +\n  guides(color = FALSE) +\n  scale_color_viridis_d(option = \"magma\", end = 0.9) +\n  theme_void()"},{"path":"show-the-numbers.html","id":"bump-charts","chapter":"Day 2 Showing the right numbers","heading":"2.14.5 Bump charts","text":"Finally, can make bump chart shows changes rankings time. ’ll look CO2 emissions South Asia. First need calculate new variable shows rank country within year. can group year use rank() function rank countries co2_emissions column.plot points lines, reversing y-axis 1 top:Afghanistan Nepal switched around number 1 spot, India dropped 4 6, switching places Pakistan.slopegraph, 8 different colors legend ’s hard line different lines, can plot text directly instead. ’ll use geom_text() . don’t need repel anything, since text fit row just fine. need change data argument geom_text() though filter data include one year, otherwise ’ll get labels every point, excessive. can also adjust theme colors make cleaner.want super fancy, can use flags instead country codes, ’s little complicated (need install ggflags package. See example.","code":"\nsa_co2 <- wdi_clean %>% \n  filter(region == \"South Asia\") %>% \n  filter(year >= 2004, year < 2015) %>% \n  group_by(year) %>% \n  mutate(rank = rank(co2_emissions))\nggplot(sa_co2, aes(x = year, y = rank, color = country)) +\n  geom_line() +\n  geom_point() +\n  scale_y_reverse(breaks = 1:8)\nggplot(sa_co2, aes(x = year, y = rank, color = country)) +\n  geom_line(size = 2) +\n  geom_point(size = 4) +\n  geom_text(data = filter(sa_co2, year == 2004),\n            aes(label = iso2c, x = 2003.25),\n            fontface = \"bold\") +\n  geom_text(data = filter(sa_co2, year == 2014),\n            aes(label = iso2c, x = 2014.75),\n            fontface = \"bold\") +\n  guides(color = FALSE) +\n  scale_y_reverse(breaks = 1:8) +\n  scale_x_continuous(breaks = 2004:2014) +\n  scale_color_viridis_d(option = \"magma\", begin = 0.2, end = 0.9) +\n  labs(x = NULL, y = \"Rank\") +\n  theme_minimal() +\n  theme(panel.grid.major.y = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.minor.x = element_blank())"},{"path":"show-the-numbers.html","id":"acknowledgments","chapter":"Day 2 Showing the right numbers","heading":"Acknowledgments","text":"Coding examples Andrew Heiss","code":""},{"path":"show-the-numbers.html","id":"session-info-1","chapter":"Day 2 Showing the right numbers","heading":"Session info","text":"","code":"\ndevtools::session_info()\n## ─ Session info ───────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.1.2 (2021-11-01)\n##  os       macOS Monterey 12.2.1\n##  system   aarch64, darwin20\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       America/Chicago\n##  date     2022-03-04\n##  pandoc   2.17.1.1 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/ (via rmarkdown)\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────\n##  package       * version date (UTC) lib source\n##  assertthat      0.2.1   2019-03-21 [1] CRAN (R 4.1.0)\n##  backports       1.4.1   2021-12-13 [1] CRAN (R 4.1.1)\n##  beeswarm        0.4.0   2021-06-01 [1] CRAN (R 4.1.0)\n##  bit             4.0.4   2020-08-04 [1] CRAN (R 4.1.1)\n##  bit64           4.0.5   2020-08-30 [1] CRAN (R 4.1.0)\n##  bookdown        0.24    2021-09-02 [1] CRAN (R 4.1.1)\n##  brio            1.1.3   2021-11-30 [1] CRAN (R 4.1.1)\n##  broom         * 0.7.12  2022-01-28 [1] CRAN (R 4.1.1)\n##  bslib           0.3.1   2021-10-06 [1] CRAN (R 4.1.1)\n##  cachem          1.0.6   2021-08-19 [1] CRAN (R 4.1.1)\n##  callr           3.7.0   2021-04-20 [1] CRAN (R 4.1.0)\n##  cellranger      1.1.0   2016-07-27 [1] CRAN (R 4.1.0)\n##  class           7.3-20  2022-01-13 [1] CRAN (R 4.1.1)\n##  classInt        0.4-3   2020-04-07 [1] CRAN (R 4.1.0)\n##  cli             3.2.0   2022-02-14 [1] CRAN (R 4.1.1)\n##  codetools       0.2-18  2020-11-04 [1] CRAN (R 4.1.2)\n##  colorspace      2.0-3   2022-02-21 [1] CRAN (R 4.1.1)\n##  crayon          1.5.0   2022-02-14 [1] CRAN (R 4.1.1)\n##  DBI             1.1.2   2021-12-20 [1] CRAN (R 4.1.1)\n##  dbplyr          2.1.1   2021-04-06 [1] CRAN (R 4.1.0)\n##  desc            1.4.0   2021-09-28 [1] CRAN (R 4.1.1)\n##  devtools        2.4.3   2021-11-30 [1] CRAN (R 4.1.1)\n##  digest          0.6.29  2021-12-01 [1] CRAN (R 4.1.1)\n##  dplyr         * 1.0.8   2022-02-08 [1] CRAN (R 4.1.1)\n##  e1071           1.7-9   2021-09-16 [1] CRAN (R 4.1.1)\n##  ellipsis        0.3.2   2021-04-29 [1] CRAN (R 4.1.0)\n##  evaluate        0.15    2022-02-18 [1] CRAN (R 4.1.1)\n##  fansi           1.0.2   2022-01-14 [1] CRAN (R 4.1.1)\n##  farver          2.1.0   2021-02-28 [1] CRAN (R 4.1.0)\n##  fastmap         1.1.0   2021-01-25 [1] CRAN (R 4.1.0)\n##  forcats       * 0.5.1   2021-01-27 [1] CRAN (R 4.1.1)\n##  fs              1.5.2   2021-12-08 [1] CRAN (R 4.1.1)\n##  gapminder     * 0.3.0   2017-10-31 [1] CRAN (R 4.1.0)\n##  generics        0.1.2   2022-01-31 [1] CRAN (R 4.1.1)\n##  geofacet      * 0.2.0   2020-05-26 [1] CRAN (R 4.1.1)\n##  geogrid         0.1.1   2018-12-11 [1] CRAN (R 4.1.0)\n##  ggbeeswarm    * 0.6.0   2017-08-07 [1] CRAN (R 4.1.0)\n##  ggplot2       * 3.3.5   2021-06-25 [1] CRAN (R 4.1.1)\n##  ggrepel       * 0.9.1   2021-01-15 [1] CRAN (R 4.1.1)\n##  glue            1.6.1   2022-01-22 [1] CRAN (R 4.1.1)\n##  gridExtra       2.3     2017-09-09 [1] CRAN (R 4.1.1)\n##  gtable          0.3.0   2019-03-25 [1] CRAN (R 4.1.1)\n##  haven           2.4.3   2021-08-04 [1] CRAN (R 4.1.1)\n##  here          * 1.0.1   2020-12-13 [1] CRAN (R 4.1.0)\n##  highr           0.9     2021-04-16 [1] CRAN (R 4.1.0)\n##  hms             1.1.1   2021-09-26 [1] CRAN (R 4.1.1)\n##  htmltools       0.5.2   2021-08-25 [1] CRAN (R 4.1.1)\n##  httr            1.4.2   2020-07-20 [1] CRAN (R 4.1.0)\n##  imguR           1.0.3   2016-03-29 [1] CRAN (R 4.1.0)\n##  jpeg            0.1-9   2021-07-24 [1] CRAN (R 4.1.0)\n##  jquerylib       0.1.4   2021-04-26 [1] CRAN (R 4.1.0)\n##  jsonlite        1.8.0   2022-02-22 [1] CRAN (R 4.1.1)\n##  KernSmooth      2.23-20 2021-05-03 [1] CRAN (R 4.1.2)\n##  knitr         * 1.37    2021-12-16 [1] CRAN (R 4.1.1)\n##  labeling        0.4.2   2020-10-20 [1] CRAN (R 4.1.0)\n##  lattice         0.20-45 2021-09-22 [1] CRAN (R 4.1.2)\n##  lifecycle       1.0.1   2021-09-24 [1] CRAN (R 4.1.1)\n##  lubridate     * 1.8.0   2021-10-07 [1] CRAN (R 4.1.1)\n##  magrittr        2.0.2   2022-01-26 [1] CRAN (R 4.1.1)\n##  Matrix          1.4-0   2021-12-08 [1] CRAN (R 4.1.1)\n##  memoise         2.0.1   2021-11-26 [1] CRAN (R 4.1.1)\n##  mgcv            1.8-38  2021-10-06 [1] CRAN (R 4.1.1)\n##  modelr          0.1.8   2020-05-19 [1] CRAN (R 4.1.0)\n##  munsell         0.5.0   2018-06-12 [1] CRAN (R 4.1.0)\n##  nlme            3.1-155 2022-01-13 [1] CRAN (R 4.1.1)\n##  pillar          1.7.0   2022-02-01 [1] CRAN (R 4.1.1)\n##  pkgbuild        1.3.1   2021-12-20 [1] CRAN (R 4.1.1)\n##  pkgconfig       2.0.3   2019-09-22 [1] CRAN (R 4.1.0)\n##  pkgload         1.2.4   2021-11-30 [1] CRAN (R 4.1.1)\n##  png             0.1-7   2013-12-03 [1] CRAN (R 4.1.0)\n##  prettyunits     1.1.1   2020-01-24 [1] CRAN (R 4.1.0)\n##  processx        3.5.2   2021-04-30 [1] CRAN (R 4.1.0)\n##  proxy           0.4-26  2021-06-07 [1] CRAN (R 4.1.0)\n##  ps              1.6.0   2021-02-28 [1] CRAN (R 4.1.0)\n##  purrr         * 0.3.4   2020-04-17 [1] CRAN (R 4.1.0)\n##  R6              2.5.1   2021-08-19 [1] CRAN (R 4.1.1)\n##  Rcpp            1.0.8   2022-01-13 [1] CRAN (R 4.1.1)\n##  readr         * 2.1.2   2022-01-30 [1] CRAN (R 4.1.1)\n##  readxl        * 1.3.1   2019-03-13 [1] CRAN (R 4.1.0)\n##  remotes         2.4.2   2021-11-30 [1] CRAN (R 4.1.1)\n##  reprex          2.0.1   2021-08-05 [1] CRAN (R 4.1.1)\n##  rgdal           1.5-28  2021-12-15 [1] CRAN (R 4.1.1)\n##  rgeos           0.5-9   2021-12-15 [1] CRAN (R 4.1.1)\n##  RJSONIO         1.3-1.6 2021-09-16 [1] CRAN (R 4.1.1)\n##  rlang           1.0.1   2022-02-03 [1] CRAN (R 4.1.1)\n##  rmarkdown       2.11    2021-09-14 [1] CRAN (R 4.1.1)\n##  rnaturalearth   0.1.0   2017-03-21 [1] CRAN (R 4.1.0)\n##  rprojroot       2.0.2   2020-11-15 [1] CRAN (R 4.1.0)\n##  rstudioapi      0.13    2020-11-12 [1] CRAN (R 4.1.0)\n##  rvest           1.0.2   2021-10-16 [1] CRAN (R 4.1.1)\n##  sass            0.4.0   2021-05-12 [1] CRAN (R 4.1.0)\n##  scales        * 1.1.1   2020-05-11 [1] CRAN (R 4.1.0)\n##  sessioninfo     1.2.2   2021-12-06 [1] CRAN (R 4.1.1)\n##  sf              1.0-6   2022-02-04 [1] CRAN (R 4.1.1)\n##  socviz        * 1.2     2020-06-10 [1] CRAN (R 4.1.0)\n##  sp              1.4-6   2021-11-14 [1] CRAN (R 4.1.1)\n##  stringi         1.7.6   2021-11-29 [1] CRAN (R 4.1.1)\n##  stringr       * 1.4.0   2019-02-10 [1] CRAN (R 4.1.1)\n##  testthat        3.1.2   2022-01-20 [1] CRAN (R 4.1.1)\n##  tibble        * 3.1.6   2021-11-07 [1] CRAN (R 4.1.1)\n##  tidyr         * 1.2.0   2022-02-01 [1] CRAN (R 4.1.1)\n##  tidyselect      1.1.2   2022-02-21 [1] CRAN (R 4.1.1)\n##  tidyverse     * 1.3.1   2021-04-15 [1] CRAN (R 4.1.0)\n##  tzdb            0.2.0   2021-10-27 [1] CRAN (R 4.1.1)\n##  units           0.8-0   2022-02-05 [1] CRAN (R 4.1.1)\n##  usethis         2.1.5   2021-12-09 [1] CRAN (R 4.1.1)\n##  utf8            1.2.2   2021-07-24 [1] CRAN (R 4.1.0)\n##  vctrs           0.3.8   2021-04-29 [1] CRAN (R 4.1.0)\n##  vipor           0.4.5   2017-03-22 [1] CRAN (R 4.1.0)\n##  viridisLite     0.4.0   2021-04-13 [1] CRAN (R 4.1.0)\n##  vroom           1.5.7   2021-11-30 [1] CRAN (R 4.1.1)\n##  WDI           * 2.7.6   2022-02-25 [1] CRAN (R 4.1.1)\n##  withr           2.4.3   2021-11-30 [1] CRAN (R 4.1.1)\n##  xfun            0.29    2021-12-14 [1] CRAN (R 4.1.1)\n##  xml2            1.3.3   2021-11-30 [1] CRAN (R 4.1.1)\n##  yaml            2.3.5   2022-02-21 [1] CRAN (R 4.1.1)\n## \n##  [1] /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library\n## \n## ──────────────────────────────────────────────────────────────────────────────"},{"path":"science-polish.html","id":"science-polish","chapter":"Day 3 Making plots pretty and clean","heading":"Day 3 Making plots pretty and clean","text":"","code":"\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(knitr)\nlibrary(broom)\nlibrary(stringr)\nlibrary(socviz)\nlibrary(patchwork)\nlibrary(RColorBrewer)\nlibrary(colorspace)\nlibrary(dichromat)\nlibrary(ggrepel)\nlibrary(ggthemes)\nlibrary(scales)\nlibrary(gapminder)\nlibrary(here)"},{"path":"science-polish.html","id":"learning-objectives-2","chapter":"Day 3 Making plots pretty and clean","heading":"Learning objectives","text":"","code":""},{"path":"science-polish.html","id":"morning-2","chapter":"Day 3 Making plots pretty and clean","heading":"3.0.1 Morning","text":"Define Tufte’s theory data graphics, data-ink ratio, chartjunkPresent compare examples minimalistic graphics original formAssess visualizations engineer/designers philosophy","code":""},{"path":"science-polish.html","id":"afternoon-2","chapter":"Day 3 Making plots pretty and clean","heading":"3.0.2 Afternoon","text":"Demonstrate methods visualizing uncertaintyGenerate layered plots highlight specific attributes dataAdjust themes","code":""},{"path":"science-polish.html","id":"assigned-readings-2","chapter":"Day 3 Making plots pretty and clean","heading":"Assigned readings","text":"Chapter 8, Healy (2018) - accessible via book’s website","code":""},{"path":"science-polish.html","id":"tuftes-world","chapter":"Day 3 Making plots pretty and clean","heading":"3.1 Tufte’s world","text":"Core purpose visualization communicate quantitative information\nArt secondary\n“else show data”\nCore purpose visualization communicate quantitative informationArt secondary“else show data”Goal maximize data-ink ratio\n\\[\\text{Data-ink ratio} = \\frac{\\text{data-ink}}{\\text{total ink used print graphic}}\\]Goal maximize data-ink ratio\\[\\text{Data-ink ratio} = \\frac{\\text{data-ink}}{\\text{total ink used print graphic}}\\]Data-ink - non-erasable core graphic\nTufte says care \nMinimize extraneous fluff\nData-ink - non-erasable core graphicThis Tufte says care aboutMinimize extraneous fluffWhat consider part “data-ink”?\nliterally just data? Don’t need gridlines axes? else can considered integral graph?\nconsider part “data-ink”?literally just data? Don’t need gridlines axes? else can considered integral graph?never offers proof hypothesis less betterHe never offers proof hypothesis less better","code":""},{"path":"science-polish.html","id":"what-is-integral","chapter":"Day 3 Making plots pretty and clean","heading":"3.1.1 What is integral?","text":"Data pointsAxis ticksAxis tick labelsAxis labelsBackgroundGrid linesWhat happens strip away everything except data?Hmm, actually need keep? consider “integral”? remove background color?Remove panel boxRemove minor grid linesRemove grid linesRemove tick marksUse serif fontWhat lost? easier interpret? Harder?","code":""},{"path":"science-polish.html","id":"chart-junk","chapter":"Day 3 Making plots pretty and clean","heading":"3.2 Chart junk","text":"Vibrating moire effects\nHard produce ggplot2 - support \nEye junk\nMakes graph harder decode/interpret\nVibrating moire effectsHard produce ggplot2 - support themEye junkMakes graph harder decode/interpretThe grid\nMinimize/reduce thickness grid lines ease interpretation\nLess visual clutter weed \nAdd compare/contrast ggplot\ngridMinimize/reduce thickness grid lines ease interpretationLess visual clutter weed throughAdd compare/contrast ggplotThe duckThe duckTufte concludes forgoing chartjunk enables functionality insight (Cairo describe ). agree?Tufte concludes forgoing chartjunk enables functionality insight (Cairo describe ). agree?","code":""},{"path":"science-polish.html","id":"compare-tufte-minimal-graphs-to-traditional-graphs-using-ggplot2","chapter":"Day 3 Making plots pretty and clean","heading":"3.3 Compare Tufte minimal graphs to traditional graphs using ggplot2","text":"ggthemesCompare themes basic plot11The goal Tufte’s minimalism maximize data-ink ratio, want modify traditional default graphs R ggplot2 minimize use extraneous ink.","code":""},{"path":"science-polish.html","id":"minimal-line-plot","chapter":"Day 3 Making plots pretty and clean","heading":"3.3.1 Minimal line plot","text":"use geom_point() draw data points geom_line() connect pointsWhat extraneous ink graph?\nBackground\nTitle graph y-axis labels - redundant\nx-axis label - year obvious/self-explanatory\nBackgroundTitle graph y-axis labels - redundantx-axis label - year obvious/self-explanatoryMissing context - expansion meaningful time?Remove axis graph titlesAdds text annotation within graphHighlights 5% increase per capital expanduresChanges font aesthetically pleasing, blockish","code":""},{"path":"science-polish.html","id":"minimal-boxplot","chapter":"Day 3 Making plots pretty and clean","heading":"3.3.2 Minimal boxplot","text":"Key features boxplot\nLines indicate:\nMaximum IQR\n3rd quartile\nMedian\n1st quartile\nMinimum IQR\n\nDots outliers\nLines indicate:\nMaximum IQR\n3rd quartile\nMedian\n1st quartile\nMinimum IQR\nMaximum IQR3rd quartileMedian1st quartileMinimum IQRDots outliersHow many different line strokes use?\n8 graph\n\\(8 \\times 22 = 176\\)\n8 graph\\(8 \\times 22 = 176\\)extraneous inkNow use 22 verticals show data. easily drawn hand single vertical category x-axisDoesn’t show outlier info, really necessary?Also removes background color gridlinesHere use offsetting lines indicate middle half data rather using gapIs prettier? Easier interpret?","code":""},{"path":"science-polish.html","id":"minimal-barchart","chapter":"Day 3 Making plots pretty and clean","heading":"3.3.3 Minimal barchart","text":", background main culpritErases box/grid backgroundRemoves vertical axisUse white grid show coordinate lines absence ink, rather adding ink\nAllows us remove tick marks well\nAllows us remove tick marks well","code":""},{"path":"science-polish.html","id":"range-frame-scatterplot","chapter":"Day 3 Making plots pretty and clean","heading":"3.3.4 Range-frame scatterplot","text":"standard bivariate scatterplotUse frame/axis lines graph communicate important information\nExtends minimum/maximum values data, rather arbitrary points\nExplicitly identifies minimum maximum values\nExtends minimum/maximum values data, rather arbitrary pointsExplicitly identifies minimum maximum values","code":""},{"path":"science-polish.html","id":"with-a-quartile-plot","chapter":"Day 3 Making plots pretty and clean","heading":"3.3.4.1 With a quartile plot","text":"Combine info quartiles data show case info wellThicker bar indicates inner two quartilesMedian explicitly labeled","code":""},{"path":"science-polish.html","id":"reconsidering-tufte","chapter":"Day 3 Making plots pretty and clean","heading":"3.4 Reconsidering Tufte","text":"","code":""},{"path":"science-polish.html","id":"when-is-redundancy-better","chapter":"Day 3 Making plots pretty and clean","heading":"3.4.1 When is redundancy better?","text":"\nFigure 1.1: Double-time bar chart crime city San Francisco, 2009-10. Source: Visualizing Time Double-Time Bar Chart\nset 24 bars show data. top bars run midnight 11pm. bottom bars run noon 11am.Highlighted regions represent 6-5 (6am-5pm; 6pm-5am)Colors represent (roughly) day night (yellow day, blue night)Enables representing trends 24 hour period without breaking arbitrarily midnight\nFigure 1.2: Double-time bar chart crime city San Francisco, 2009-10. Source: Visualizing Time Double-Time Bar Chart\nsecond graph incredibly redundant, easier interpret?\npass Tufte’s test?\nmean “integral”?\npass Tufte’s test?mean “integral”?","code":""},{"path":"science-polish.html","id":"does-minimalism-really-help-here","chapter":"Day 3 Making plots pretty and clean","heading":"3.4.2 Does minimalism really help here?","text":"Accompanying article declaring student progress NAEP tests come virtual standstill\nFigure 3.1: Chart Harvard magazine. Source: Involuntary head-shaking probably intended consequence data visualization\ncomparison make?much color?Meets Tufte’s minimalist standards, probably decent data-ink ratioNote Grade 4 math scores whites 2009-2015 - mean progress unknown scores?\nFigure 3.2: Redesigned chart Harvard magazine. Source: Involuntary head-shaking probably intended consequence data visualization\nversion much clearer - specifically tells us compare scoresRemoves color channel, using linetype instead\nsituation, better worse?\nsituation, better worse?Title graph makes clear point trying made","code":""},{"path":"science-polish.html","id":"experimental-tests-of-tuftes-claims","chapter":"Day 3 Making plots pretty and clean","heading":"3.4.3 Experimental tests of Tufte’s claims","text":"know Tufte’s claims true? can test experiments!\nFigure 3.3: Source: Figure 2 Bateman, Scott, et al. “Useful junk?: effects visual embellishment comprehension memorability charts.” Proceedings SIGCHI Conference Human Factors Computing Systems. ACM, 2010.\n","code":""},{"path":"science-polish.html","id":"protocol","chapter":"Day 3 Making plots pretty and clean","heading":"3.4.3.1 Protocol","text":"Compared chartjunk versions graphs standard/minimalist versions graphsTested individuals chart description recall20 subjects split short long-term recall groups\nQuite small sample convenience (university population)\nQuite small sample convenience (university population)Collected measures\nResponse scores - individual correctly read/interpret chart?\nPreferences - type chart individual prefer? Standard embellished?\nGaze data - subject look experiment? data regions embellishment regions?\nResponse scores - individual correctly read/interpret chart?Preferences - type chart individual prefer? Standard embellished?Gaze data - subject look experiment? data regions embellishment regions?","code":""},{"path":"science-polish.html","id":"results","chapter":"Day 3 Making plots pretty and clean","heading":"3.4.3.2 Results","text":"\nFigure 3.4: Source: Figures 4-6 Bateman, Scott, et al. “Useful junk?: effects visual embellishment comprehension memorability charts.” Proceedings SIGCHI Conference Human Factors Computing Systems. ACM, 2010.\ndifference descriptionNo difference immediate recallEmbellished images slightly better long-term recall (12-22 days treatment)","code":""},{"path":"science-polish.html","id":"discussing-the-results","chapter":"Day 3 Making plots pretty and clean","heading":"3.4.4 Discussing the results","text":"chartjunk lead worse description recall?\nChartjunk related topic chart\n“Gets point quicker”\nChartjunk related topic chart“Gets point quicker”embellished images produce better long-term recall?\nvivid image\nValue message - individual believes author trying communicate set values\nEmbellished images produced value messages\nvivid imageValue message - individual believes author trying communicate set valuesEmbellished images produced value messagesShould visualizations “objective”?\nTufte seems think : minimalism leads data speaking - buy ?\nTufte seems think : minimalism leads data speaking - buy ?","code":""},{"path":"science-polish.html","id":"rethinking-tuftes-definition-of-visual-excellence","chapter":"Day 3 Making plots pretty and clean","heading":"3.4.5 Rethinking Tufte’s definition of visual excellence","text":"many Tufte’s claims based nothing - evidence support minimalistic approach graphical designThink hockey stick chart vs. xkcd Earth’s temperature\nAccording Tufte, probably lot chartjunk (xkcd )\nasked remember importance story graph weeks later, one think average reader recall better?\nAccording Tufte, probably lot chartjunk (xkcd )asked remember importance story graph weeks later, one think average reader recall better?","code":""},{"path":"science-polish.html","id":"testing-this-theory","chapter":"Day 3 Making plots pretty and clean","heading":"3.4.6 Testing this theory","text":"Design experiment test impact/effectiveness chartjunk vs. minimalismWhat protocols/features use? deploy experiment?\ndeployed platform Amazon MTurk, benefits drawbacks?\ndeployed platform Amazon MTurk, benefits drawbacks?","code":""},{"path":"science-polish.html","id":"visualizing-uncertainty","chapter":"Day 3 Making plots pretty and clean","heading":"3.5 Visualizing uncertainty","text":"Download necessary data files following coding exercises using usethis::use_course(\"css-data-mining-viz/science-polish\").example, ’re going use historical weather data Dark Sky wind speed temperature trends downtown Atlanta (specifically 33.754557, -84.390009) 2019. downloaded data using Dark Sky’s (---retired----bought--Apple) API using darksky package.atl-weather-2019.csv","code":""},{"path":"science-polish.html","id":"load-and-clean-data-2","chapter":"Day 3 Making plots pretty and clean","heading":"3.5.1 Load and clean data","text":"First, load libraries ’ll using:load data read_csv(). assume CSV file lives subfolder project named data:’ll add couple columns can use faceting filling using month() wday() functions lubridate extracting parts date:Now ’re ready go!","code":"\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggridges)\nlibrary(gghalves)\nweather_atl_raw <- read_csv(\"data/atl-weather-2019.csv\")\nweather_atl <- weather_atl_raw %>% \n  mutate(Month = month(time, label = TRUE, abbr = FALSE),\n         Day = wday(time, label = TRUE, abbr = FALSE))"},{"path":"science-polish.html","id":"histograms-1","chapter":"Day 3 Making plots pretty and clean","heading":"3.5.2 Histograms","text":"can first make histogram wind speed. ’ll use bin width 1 color edges bars white:fine enough, can improve forcing buckets/bins start whole numbers instead containing ranges like 2.5–3.5. ’ll use boundary argument . also add scale_x_continuous() add x-axis breaks instead things like 2.5, 5, 7.5:can show distribution wind speed month map Month column made onto fill aesthetic:colorful, ’s impossible actually interpret. Instead filling, ’ll also facet month see separate graphs month. can turn fill legend ’s now redundant.Neat! January, March, April appear variation windy days, wind-less days -windy days, August wind-less.","code":"\nggplot(weather_atl, aes(x = windSpeed)) +\n  geom_histogram(binwidth = 1, color = \"white\")\nggplot(weather_atl, aes(x = windSpeed)) +\n  geom_histogram(binwidth = 1, color = \"white\", boundary = 1) +\n  scale_x_continuous(breaks = seq(0, 12, by = 1))\nggplot(weather_atl, aes(x = windSpeed, fill = Month)) +\n  geom_histogram(binwidth = 1, color = \"white\", boundary = 1) +\n  scale_x_continuous(breaks = seq(0, 12, by = 1))\nggplot(weather_atl, aes(x = windSpeed, fill = Month)) +\n  geom_histogram(binwidth = 1, color = \"white\", boundary = 1) +\n  scale_x_continuous(breaks = seq(0, 12, by = 1)) + \n  guides(fill = FALSE) +\n  facet_wrap(vars(Month))"},{"path":"science-polish.html","id":"density-plots","chapter":"Day 3 Making plots pretty and clean","heading":"3.5.3 Density plots","text":"code create density plot nearly identical used histogram—thing change geom layer:want, can mess calculus options like kernel bandwidth:can also fill month. ’ll make different layers 50% transparent can kind see whole stack:Even transparency, really hard interpret. can fix faceting, like histograms:can stack density plots behind ggridges. work, also need map Month y-axis. can reverse y-axis January top use fct_rev() function:can add extra information geom_density_ridges() arguments like quantile_lines. can use quantiles argument tell plow many parts cut . Since just want show median, ’ll set 2 density plot divided half:Now good working code, can easily substitute variables changing x mapping:can get extra fancy fill temperature instead filling month. get work, need use geom_density_ridges_gradient(), need change fill mapping strange looking ..x.., weird ggplot trick tells use variable mapped x-axis. whatever reason, fill = temperatureHigh doesn’t work 🤷:finally, can get extra fancy show distributions high low temperatures month. make work, need manipulate data little. Right now two columns high low temperature: temperatureLow temperatureHigh. able map temperature x-axis high vs. low another aesthetic (like linetype), need column temperature column indicator variable whether high low. data needs tidied (since right now variable (high/low) encoded column name). can tidy data using pivot_longer() tidyr, already loaded library(tidyverse). RStudio primers, thing gather()—pivot_longer() newer version gather():Now column temperature (temp) column indicating high low (temp_type). dataset also twice long (730 rows) day two rows (high low). Let’s plot map high/low linetype aesthetic show high/low border plots:Super neat! can see much wider temperature disparities summer, large gaps high low, relatively equal high/low temperatures winter.","code":"\nggplot(weather_atl, aes(x = windSpeed)) +\n  geom_density(color = \"grey20\", fill = \"grey50\")\nggplot(weather_atl, aes(x = windSpeed)) +\n  geom_density(color = \"grey20\", fill = \"grey50\",\n               bw = 0.1, kernel = \"epanechnikov\")\nggplot(weather_atl, aes(x = windSpeed, fill = Month)) +\n  geom_density(alpha = 0.5)\nggplot(weather_atl, aes(x = windSpeed, fill = Month)) +\n  geom_density(alpha = 0.5) +\n  guides(fill = FALSE) +\n  facet_wrap(vars(Month))\nggplot(weather_atl, aes(x = windSpeed, y = fct_rev(Month), fill = Month)) +\n  geom_density_ridges() +\n  guides(fill = FALSE)\nggplot(weather_atl, aes(x = windSpeed, y = fct_rev(Month), fill = Month)) +\n  geom_density_ridges(quantile_lines = TRUE, quantiles = 2) +\n  guides(fill = FALSE)\nggplot(weather_atl, aes(x = temperatureHigh, y = fct_rev(Month), fill = Month)) +\n  geom_density_ridges(quantile_lines = TRUE, quantiles = 2) +\n  guides(fill = FALSE)\nggplot(weather_atl, aes(x = temperatureHigh, y = fct_rev(Month), fill = ..x..)) +\n  geom_density_ridges_gradient(quantile_lines = TRUE, quantiles = 2) +\n  scale_fill_viridis_c(option = \"plasma\") +\n  labs(x = \"High temperature\", y = NULL, color = \"Temp\")\nweather_atl_long <- weather_atl %>% \n  pivot_longer(cols = c(temperatureLow, temperatureHigh),\n               names_to = \"temp_type\",\n               values_to = \"temp\") %>% \n  # Clean up the new temp_type column so that \"temperatureHigh\" becomes \"High\", etc.\n  mutate(temp_type = recode(temp_type, \n                            temperatureHigh = \"High\",\n                            temperatureLow = \"Low\")) %>% \n  # This is optional—just select a handful of columns\n  select(time, temp_type, temp, Month) \n\n# Show the first few rows\nhead(weather_atl_long)\n## # A tibble: 6 × 4\n##   time                temp_type  temp Month  \n##   <dttm>              <chr>     <dbl> <ord>  \n## 1 2019-01-01 05:00:00 Low        50.6 January\n## 2 2019-01-01 05:00:00 High       63.9 January\n## 3 2019-01-02 05:00:00 Low        49.0 January\n## 4 2019-01-02 05:00:00 High       57.4 January\n## 5 2019-01-03 05:00:00 Low        53.1 January\n## 6 2019-01-03 05:00:00 High       55.3 January\nggplot(weather_atl_long, aes(x = temp, y = fct_rev(Month), \n                             fill = ..x.., linetype = temp_type)) +\n  geom_density_ridges_gradient(quantile_lines = TRUE, quantiles = 2) +\n  scale_fill_viridis_c(option = \"plasma\") +\n  labs(x = \"High temperature\", y = NULL, color = \"Temp\")"},{"path":"science-polish.html","id":"box-violin-and-rain-cloud-plots","chapter":"Day 3 Making plots pretty and clean","heading":"3.5.4 Box, violin, and rain cloud plots","text":"Finally, can look distribution variables box plots, violin plots, similar graphs. First, ’ll make box plot windspeed, filled Day variable made indicating weekday:can switch violin plot just changing geom layer mapping Day x-axis:violin plots ’s typically good overlay geoms. can add jittered points strip plot:can also add larger points daily averages. ’ll use special layer : stat_summary(). slightly different syntax, since ’re actually mapping column dataset. Instead, ’re feeding column dataset function (\"mean\") plotting result:can also show mean confidence interval time changing summary function:Overlaying points directly top violins shows extra information, ’s also really crowded hard read. use gghalves package, can use special halved versions geoms like :Note side argument specifying half column geom goes. can also use geom_half_violin():flip plot, can make rain cloud plot:Neat!","code":"\nggplot(weather_atl,\n       aes(y = windSpeed, fill = Day)) +\n  geom_boxplot()\nggplot(weather_atl,\n       aes(y = windSpeed, x = Day, fill = Day)) +\n  geom_violin()\nggplot(weather_atl,\n       aes(y = windSpeed, x = Day, fill = Day)) +\n  geom_violin() +\n  geom_point(size = 0.5, position = position_jitter(width = 0.1)) +\n  guides(fill = FALSE)\nggplot(weather_atl,\n       aes(y = windSpeed, x = Day, fill = Day)) +\n  geom_violin() +\n  stat_summary(geom = \"point\", fun = \"mean\", size = 5, color = \"white\") +\n  geom_point(size = 0.5, position = position_jitter(width = 0.1)) +\n  guides(fill = FALSE)\nggplot(weather_atl,\n       aes(y = windSpeed, x = Day, fill = Day)) +\n  geom_violin() +\n  stat_summary(geom = \"pointrange\", fun.data = \"mean_se\", size = 1, color = \"white\") +\n  geom_point(size = 0.5, position = position_jitter(width = 0.1)) +\n  guides(fill = FALSE)\nggplot(weather_atl,\n       aes(x = fct_rev(Day), y = temperatureHigh)) +\n  geom_half_point(aes(color = Day), side = \"l\", size = 0.5) +\n  geom_half_boxplot(aes(fill = Day), side = \"r\") +\n  guides(color = FALSE, fill = FALSE)\nggplot(weather_atl,\n       aes(x = fct_rev(Day), y = temperatureHigh)) +\n  geom_half_point(aes(color = Day), side = \"l\", size = 0.5) +\n  geom_half_violin(aes(fill = Day), side = \"r\") +\n  guides(color = FALSE, fill = FALSE)\nggplot(weather_atl,\n       aes(x = fct_rev(Day), y = temperatureHigh)) +\n  geom_half_boxplot(aes(fill = Day), side = \"l\", width = 0.5, nudge = 0.1) +\n  geom_half_point(aes(color = Day), side = \"l\", size = 0.5) +\n  geom_half_violin(aes(fill = Day), side = \"r\") +\n  guides(color = FALSE, fill = FALSE) + \n  coord_flip()"},{"path":"science-polish.html","id":"building-a-theme","chapter":"Day 3 Making plots pretty and clean","heading":"3.6 Building a theme()","text":"Consider example using gapminder:Now base_plot work . ’s looks like theme_minimal() applied :gets rid grey background good start, can make lots improvements. First let’s deal gridlines. many. can get rid minor gridlines setting element_blank():Next let’s add typographic contrast. ’ll use Roboto Condensed Regular base font. trying , make sure following:macOS:Run capabilities() console verify TRUE shows cairoIf , download install XQuartzOn Windows:Run windowsFonts() console ’ll see list fonts can use R. ’s big list.\n#> $serif\n#> [1] \"TT Times New Roman\"\n#>\n#> $sans\n#> [1] \"TT Arial\"\n#> \n#> $mono\n#> [1] \"TT Courier New\"\ncan add Roboto Condensed current R session running console:\n\nwindowsFonts(`Roboto Condensed` = windowsFont(\"Roboto Condensed\"))\nNow run windowsFonts(), ’ll see list:\n#> $serif\n#> [1] \"TT Times New Roman\"\n#>\n#> $sans\n#> [1] \"TT Arial\"\n#> \n#> $mono\n#> [1] \"TT Courier New\"\n#>\n#> $`Roboto Condensed`\n#> [1] \"Roboto Condensed\"\ntakes effect current R session, knitting document ever plan closing RStudio, ’ll need incorporate font creation code script.Run windowsFonts() console ’ll see list fonts can use R. ’s big list.can add Roboto Condensed current R session running console:Now run windowsFonts(), ’ll see list:takes effect current R session, knitting document ever plan closing RStudio, ’ll need incorporate font creation code script.’ll use font base_family argument. Note make bold face change size rel(). Instead manually setting arbitrary size, use rel() resize text relation base_size argument. Using rel(1.7) means 1.7 × base_size, 20.4 rescale according whatever base_size —shrink base_size = 8, title scale accordingly.Whoa. gets us way ! good contrast typography, strong bold lighter regular font (contrast). Everything aligned left (alignment repetition). moving axis titles little bit away labels, ’ve enhanced proximity, since close together (proximity). repeat grey caption subtitle (repetition).thing don’t like 2002 isn’t quite aligned title subtitle. facet labels boxes along top plot, themes (like theme_grey() theme_bw()) facet labels grey backgrounds. can turn margin boxes, can add background, perfectly aligned title subtitle.looks great!save time future, can store whole thing object can reuse plots:Now can use plot.Super neat!","code":"\ngapminder_filtered <- gapminder %>%\n  filter(year > 2000)\n\nbase_plot <- ggplot(\n  data = gapminder_filtered,\n  mapping = aes(\n    x = gdpPercap, y = lifeExp,\n    color = continent, size = pop\n  )\n) +\n  geom_point() +\n  # Use dollars, and get rid of the cents part (i.e. $300 instead of $300.00)\n  scale_x_log10(labels = dollar_format(accuracy = 1)) +\n  # Format with commas\n  scale_size_continuous(labels = comma) +\n  # Use viridis\n  scale_color_viridis_d(option = \"plasma\", end = 0.9) +\n  labs(\n    x = \"GDP per capita\", y = \"Life expectancy\",\n    color = \"Continent\", size = \"Population\",\n    title = \"Here's a cool title\",\n    subtitle = \"And here's a neat subtitle\",\n    caption = \"Source: The Gapminder Project\"\n  ) +\n  facet_wrap(vars(year))\n\nbase_plot\nbase_plot +\n  theme_minimal()\nbase_plot +\n  theme_minimal() +\n  theme(panel.grid.minor = element_blank())#> $serif\n#> [1] \"TT Times New Roman\"\n#>\n#> $sans\n#> [1] \"TT Arial\"\n#> \n#> $mono\n#> [1] \"TT Courier New\"\nwindowsFonts(`Roboto Condensed` = windowsFont(\"Roboto Condensed\"))#> $serif\n#> [1] \"TT Times New Roman\"\n#>\n#> $sans\n#> [1] \"TT Arial\"\n#> \n#> $mono\n#> [1] \"TT Courier New\"\n#>\n#> $`Roboto Condensed`\n#> [1] \"Roboto Condensed\"\nplot_with_good_typography <- base_plot +\n  theme_minimal(base_family = \"Roboto Condensed\", base_size = 12) +\n  theme(\n    panel.grid.minor = element_blank(),\n    # Bold, bigger title\n    plot.title = element_text(face = \"bold\", size = rel(1.7)),\n    # Plain, slightly bigger subtitle that is grey\n    plot.subtitle = element_text(face = \"plain\", size = rel(1.3), color = \"grey70\"),\n    # Italic, smaller, grey caption that is left-aligned\n    plot.caption = element_text(\n      face = \"italic\", size = rel(0.7),\n      color = \"grey70\", hjust = 0\n    ),\n    # Bold legend titles\n    legend.title = element_text(face = \"bold\"),\n    # Bold, slightly larger facet titles that are left-aligned for the sake of repetition\n    strip.text = element_text(face = \"bold\", size = rel(1.1), hjust = 0),\n    # Bold axis titles\n    axis.title = element_text(face = \"bold\"),\n    # Add some space above the x-axis title and make it left-aligned\n    axis.title.x = element_text(margin = margin(t = 10), hjust = 0),\n    # Add some space to the right of the y-axis title and make it top-aligned\n    axis.title.y = element_text(margin = margin(r = 10), hjust = 1)\n  )\nplot_with_good_typography\nplot_with_good_typography +\n  # Add a light grey background to the facet titles, with no borders\n  theme(\n    strip.background = element_rect(fill = \"grey90\", color = NA),\n    # Add a thin grey border around all the plots to tie in the facet titles\n    panel.border = element_rect(color = \"grey90\", fill = NA)\n  )\nmy_pretty_theme <- theme_minimal(base_family = \"Roboto Condensed\", base_size = 12) +\n  theme(\n    panel.grid.minor = element_blank(),\n    # Bold, bigger title\n    plot.title = element_text(face = \"bold\", size = rel(1.7)),\n    # Plain, slightly bigger subtitle that is grey\n    plot.subtitle = element_text(face = \"plain\", size = rel(1.3), color = \"grey70\"),\n    # Italic, smaller, grey caption that is left-aligned\n    plot.caption = element_text(\n      face = \"italic\", size = rel(0.7),\n      color = \"grey70\", hjust = 0\n    ),\n    # Bold legend titles\n    legend.title = element_text(face = \"bold\"),\n    # Bold, slightly larger facet titles that are left-aligned for the sake of repetition\n    strip.text = element_text(face = \"bold\", size = rel(1.1), hjust = 0),\n    # Bold axis titles\n    axis.title = element_text(face = \"bold\"),\n    # Add some space above the x-axis title and make it left-aligned\n    axis.title.x = element_text(margin = margin(t = 10), hjust = 0),\n    # Add some space to the right of the y-axis title and make it top-aligned\n    axis.title.y = element_text(margin = margin(r = 10), hjust = 1),\n    # Add a light grey background to the facet titles, with no borders\n    strip.background = element_rect(fill = \"grey90\", color = NA),\n    # Add a thin grey border around all the plots to tie in the facet titles\n    panel.border = element_rect(color = \"grey90\", fill = NA)\n  )\nmpg_example <- ggplot(\n  data = mpg,\n  mapping = aes(x = displ, y = hwy, color = class)\n) +\n  geom_point(size = 3) +\n  scale_color_viridis_d() +\n  facet_wrap(vars(drv)) +\n  labs(\n    x = \"Displacement\", y = \"Highway MPG\", color = \"Car class\",\n    title = \"Heavier cars get worse mileage\",\n    subtitle = \"Except two-seaters?\",\n    caption = \"Here's a caption\"\n  ) +\n  my_pretty_theme\nmpg_example"},{"path":"science-polish.html","id":"annotations","chapter":"Day 3 Making plots pretty and clean","heading":"3.7 Annotations","text":"example, ’re going use cross-national data World Bank’s Open Data portal. ’ll download data WDI package.wdi_co2.csv","code":""},{"path":"science-polish.html","id":"load-data-1","chapter":"Day 3 Making plots pretty and clean","heading":"3.7.1 Load data","text":"First, load libraries ’ll using:clean data removing non-country countries renaming columns.","code":"\nlibrary(tidyverse)  # For ggplot, dplyr, and friends\nlibrary(WDI)        # Get data from the World Bank\nlibrary(ggrepel)    # For non-overlapping labels\n\n# You need to install ggtext from GitHub. Follow the instructions at \n# https://github.com/wilkelab/ggtext\nlibrary(ggtext)     # For fancier text handling\nindicators <- c(\"SP.POP.TOTL\",     # Population\n                \"EN.ATM.CO2E.PC\",  # CO2 emissions\n                \"NY.GDP.PCAP.KD\")  # GDP per capita\n\nwdi_co2_raw <- WDI(country = \"all\", indicators, extra = TRUE, \n                   start = 1995, end = 2015)\nwdi_co2_raw <- read_csv(here::here(\"data\", \"wdi_co2.csv\"))\nwdi_clean <- wdi_co2_raw %>% \n  filter(region != \"Aggregates\") %>% \n  select(iso2c, iso3c, country, year, \n         population = SP.POP.TOTL,\n         co2_emissions = EN.ATM.CO2E.PC, \n         gdp_per_cap = NY.GDP.PCAP.KD, \n         region, income)"},{"path":"science-polish.html","id":"clean-and-reshape-data","chapter":"Day 3 Making plots pretty and clean","heading":"3.7.2 Clean and reshape data","text":"Next ’ll substantial filtering reshaping can end rankings CO2 emissions 1995 2014. annotate much possible can see ’s happening step.’s reshaped data looked like :’s looks like now:","code":"\nco2_rankings <- wdi_clean %>% \n  # Get rid of smaller countries\n  filter(population > 200000) %>% \n  # Only look at two years\n  filter(year %in% c(1995, 2014)) %>% \n  # Get rid of all the rows that have missing values in co2_emissions\n  drop_na(co2_emissions) %>% \n  # Look at each year individually and rank countries based on their emissions that year\n  group_by(year) %>% \n  mutate(ranking = rank(co2_emissions)) %>% \n  ungroup() %>% \n  # Only select a handful of columns, mostly just the newly created \"ranking\"\n  # column and some country identifiers\n  select(iso3c, country, year, region, income, ranking) %>% \n  # Right now the data is tidy and long, but we want to widen it and create\n  # separate columns for emissions in 1995 and in 2014. pivot_wider() will make\n  # new columns based on the existing \"year\" column (that's what `names_from`\n  # does), and it will add \"rank_\" as the prefix, so that the new columns will\n  # be \"rank_1995\" and \"rank_2014\". The values that go in those new columns will\n  # come from the existing \"ranking\" column\n  pivot_wider(names_from = year, names_prefix = \"rank_\", values_from = ranking) %>% \n  # Find the difference in ranking between 2014 and 1995\n  mutate(rank_diff = rank_2014 - rank_1995) %>% \n  # Remove all rows where there's a missing value in the rank_diff column\n  drop_na(rank_diff) %>% \n  # Make an indicator variable that is true of the absolute value of the\n  # difference in rankings is greater than 25. 25 is arbitrary here—that just\n  # felt like a big change in rankings\n  mutate(big_change = ifelse(abs(rank_diff) >= 25, TRUE, FALSE)) %>% \n  # Make another indicator variable that indicates if the rank improved by a\n  # lot, worsened by a lot, or didn't change much. We use the case_when()\n  # function, which is like a fancy version of ifelse() that takes multiple\n  # conditions. This is how it generally works:\n  #\n  # case_when(\n  #  some_test ~ value_if_true,\n  #  some_other_test ~ value_if_true,\n  #  TRUE ~ value_otherwise\n  #)\n  mutate(better_big_change = case_when(\n    rank_diff <= -25 ~ \"Rank improved\",\n    rank_diff >= 25 ~ \"Rank worsened\",\n    TRUE ~ \"Rank changed a little\"\n  ))\nhead(wdi_clean)\n## # A tibble: 6 × 9\n##   iso2c iso3c country  year population co2_emissions gdp_per_cap region   income\n##   <chr> <chr> <chr>   <dbl>      <dbl>         <dbl>       <dbl> <chr>    <chr> \n## 1 AD    AND   Andorra  1995      63850          6.66      32577. Europe … High …\n## 2 AD    AND   Andorra  1996      64360          7.07      33822. Europe … High …\n## 3 AD    AND   Andorra  1997      64327          7.24      36907. Europe … High …\n## 4 AD    AND   Andorra  1999      64370          7.98      39621. Europe … High …\n## 5 AD    AND   Andorra  2000      65390          8.02      40379. Europe … High …\n## 6 AD    AND   Andorra  2001      67341          7.79      42393. Europe … High …\nhead(co2_rankings)\n## # A tibble: 6 × 9\n##   iso3c country           region income rank_1995 rank_2014 rank_diff big_change\n##   <chr> <chr>             <chr>  <chr>      <dbl>     <dbl>     <dbl> <lgl>     \n## 1 ARE   United Arab Emir… Middl… High …       170       176         6 FALSE     \n## 2 AFG   Afghanistan       South… Low i…         9        21        12 FALSE     \n## 3 ALB   Albania           Europ… Upper…        54        79        25 TRUE      \n## 4 ARM   Armenia           Europ… Upper…        71        77         6 FALSE     \n## 5 AGO   Angola            Sub-S… Lower…        59        69        10 FALSE     \n## 6 ARG   Argentina         Latin… Upper…       104       121        17 FALSE     \n## # … with 1 more variable: better_big_change <chr>"},{"path":"science-polish.html","id":"plot-the-data-and-annotate","chapter":"Day 3 Making plots pretty and clean","heading":"3.7.3 Plot the data and annotate","text":"use IBM Plex Sans plot. can download Google Fonts.","code":"\n# These three functions make it so all geoms that use text, label, and\n# label_repel will use IBM Plex Sans as the font. Those layers are *not*\n# influenced by whatever you include in the base_family argument in something\n# like theme_bw(), so ordinarily you'd need to specify the font in each\n# individual annotate(geom = \"text\") layer or geom_label() layer, and that's\n# tedious! This removes that tediousness.\nupdate_geom_defaults(\"text\", list(family = \"IBM Plex Sans\"))\nupdate_geom_defaults(\"label\", list(family = \"IBM Plex Sans\"))\nupdate_geom_defaults(\"label_repel\", list(family = \"IBM Plex Sans\"))\n\nggplot(co2_rankings,\n       aes(x = rank_1995, y = rank_2014)) +\n  # Add a reference line that goes from the bottom corner to the top corner\n  annotate(geom = \"segment\", x = 0, xend = 172, y = 0, yend = 178) +\n  # Add points and color them by the type of change in rankings\n  geom_point(aes(color = better_big_change)) +\n  # Add repelled labels. Only use data where big_change is TRUE. Fill them by\n  # the type of change (so they match the color in geom_point() above) and use\n  # white text\n  geom_label_repel(data = filter(co2_rankings, big_change == TRUE),\n                   aes(label = country, fill = better_big_change),\n                   color = \"white\") +\n  # Add notes about what the outliers mean in the bottom left and top right\n  # corners. These are italicized and light grey. The text in the bottom corner\n  # is justified to the right with hjust = 1, and the text in the top corner is\n  # justified to the left with hjust = 0\n  annotate(geom = \"text\", x = 170, y = 6, label = \"Outliers improving\", \n           fontface = \"italic\", hjust = 1, color = \"grey50\") +\n  annotate(geom = \"text\", x = 2, y = 170, label = \"Outliers worsening\", \n           fontface = \"italic\", hjust = 0, color = \"grey50\") +\n  # Add mostly transparent rectangles in the bottom right and top left corners\n  annotate(geom = \"rect\", xmin = 0, xmax = 25, ymin = 0, ymax = 25, \n           fill = \"#2ECC40\", alpha = 0.25) +\n  annotate(geom = \"rect\", xmin = 150, xmax = 178, ymin = 150, ymax = 178, \n           fill = \"#FF851B\", alpha = 0.25) +\n  # Add text to define what the rectangles abovee actually mean. The \\n in\n  # \"highest\\nemitters\" will put a line break in the label\n  annotate(geom = \"text\", x = 40, y = 6, label = \"Lowest emitters\", \n           hjust = 0, color = \"#2ECC40\") +\n  annotate(geom = \"text\", x = 162.5, y = 135, label = \"Highest\\nemitters\", \n           hjust = 0.5, vjust = 1, lineheight = 1, color = \"#FF851B\") +\n  # Add arrows between the text and the rectangles. These use the segment geom,\n  # and the arrows are added with the arrow() function, which lets us define the\n  # angle of the arrowhead and the length of the arrowhead pieces. Here we use\n  # 0.5 lines, which is a unit of measurement that ggplot uses internally (think\n  # of how many lines of text fit in the plot). We could also use unit(1, \"cm\")\n  # or unit(0.25, \"in\") or anything else\n  annotate(geom = \"segment\", x = 38, xend = 20, y = 6, yend = 6, color = \"#2ECC40\", \n           arrow = arrow(angle = 15, length = unit(0.5, \"lines\"))) +\n  annotate(geom = \"segment\", x = 162.5, xend = 162.5, y = 140, yend = 155, color = \"#FF851B\", \n           arrow = arrow(angle = 15, length = unit(0.5, \"lines\"))) +\n  # Use three different colors for the points\n  scale_color_manual(values = c(\"grey50\", \"#0074D9\", \"#FF4136\")) +\n  # Use two different colors for the filled labels. There are no grey labels, so\n  # we don't have to specify that color\n  scale_fill_manual(values = c(\"#0074D9\", \"#FF4136\")) +\n  # Make the x and y axes expand all the way to the edges of the plot area and\n  # add breaks every 25 units from 0 to 175\n  scale_x_continuous(expand = c(0, 0), breaks = seq(0, 175, 25)) +\n  scale_y_continuous(expand = c(0, 0), breaks = seq(0, 175, 25)) +\n  # Add labels! There are a couple fancy things here.\n  # 1. In the title we wrap the 2 of CO2 in the HTML <sub><\/sub> tag so that the\n  #    number gets subscripted. The only way this will actually get parsed as \n  #    HTML is if we tell the plot.title to use element_markdown() in the \n  #    theme() function, and element_markdown() comes from the ggtext package.\n  # 2. In the subtitle we bold the two words **improved** and **worsened** using\n  #    Markdown asterisks. We also wrap these words with HTML span tags with \n  #    inline CSS to specify the color of the text. Like the title, this will \n  #    only be processed and parsed as HTML and Markdown if we tell the p\n  #    lot.subtitle to use element_markdown() in the theme() function.\n  labs(x = \"Rank in 1995\", y = \"Rank in 2014\",\n       title = \"Changes in CO<sub>2<\/sub> emission rankings between 1995 and 2014\",\n       subtitle = \"Countries that <span style='color: #0074D9'>**improved**<\/span> or <span style='color: #FF4136'>**worsened**<\/span> more than 25 positions in the rankings highlighted\",\n       caption = \"Source: The World Bank.\\nCountries with populations of less than 200,000 excluded.\") +\n  # Turn off the legends for color and fill, since the subtitle includes that\n  guides(color = FALSE, fill = FALSE) +\n  # Use theme_bw() with IBM Plex Sans\n  theme_bw(base_family = \"IBM Plex Sans\") +\n  # Tell the title and subtitle to be treated as Markdown/HTML, make the title\n  # 1.6x the size of the base font, and make the subtitle 1.3x the size of the\n  # base font. Also add a little larger margin on the right of the plot so that\n  # the 175 doesn't get cut off.\n  theme(plot.title = element_markdown(face = \"bold\", size = rel(1.6)),\n        plot.subtitle = element_markdown(size = rel(1.3)),\n        plot.margin = unit(c(0.5, 1, 0.5, 0.5), units = \"lines\"))"},{"path":"science-polish.html","id":"acknowledgments-1","chapter":"Day 3 Making plots pretty and clean","heading":"Acknowledgments","text":"Coding examples Andrew Heiss","code":""},{"path":"science-polish.html","id":"session-info-2","chapter":"Day 3 Making plots pretty and clean","heading":"Session info","text":"","code":"\ndevtools::session_info()\n## ─ Session info ───────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.1.2 (2021-11-01)\n##  os       macOS Monterey 12.2.1\n##  system   aarch64, darwin20\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       America/Chicago\n##  date     2022-03-04\n##  pandoc   2.17.1.1 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/ (via rmarkdown)\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────\n##  package      * version    date (UTC) lib source\n##  assertthat     0.2.1      2019-03-21 [1] CRAN (R 4.1.0)\n##  backports      1.4.1      2021-12-13 [1] CRAN (R 4.1.1)\n##  bit            4.0.4      2020-08-04 [1] CRAN (R 4.1.1)\n##  bit64          4.0.5      2020-08-30 [1] CRAN (R 4.1.0)\n##  bookdown       0.24       2021-09-02 [1] CRAN (R 4.1.1)\n##  brio           1.1.3      2021-11-30 [1] CRAN (R 4.1.1)\n##  broom        * 0.7.12     2022-01-28 [1] CRAN (R 4.1.1)\n##  bslib          0.3.1      2021-10-06 [1] CRAN (R 4.1.1)\n##  cachem         1.0.6      2021-08-19 [1] CRAN (R 4.1.1)\n##  callr          3.7.0      2021-04-20 [1] CRAN (R 4.1.0)\n##  cellranger     1.1.0      2016-07-27 [1] CRAN (R 4.1.0)\n##  cli            3.2.0      2022-02-14 [1] CRAN (R 4.1.1)\n##  codetools      0.2-18     2020-11-04 [1] CRAN (R 4.1.2)\n##  colorspace   * 2.0-3      2022-02-21 [1] CRAN (R 4.1.1)\n##  crayon         1.5.0      2022-02-14 [1] CRAN (R 4.1.1)\n##  curl           4.3.2      2021-06-23 [1] CRAN (R 4.1.0)\n##  DBI            1.1.2      2021-12-20 [1] CRAN (R 4.1.1)\n##  dbplyr         2.1.1      2021-04-06 [1] CRAN (R 4.1.0)\n##  desc           1.4.0      2021-09-28 [1] CRAN (R 4.1.1)\n##  devtools     * 2.4.3      2021-11-30 [1] CRAN (R 4.1.1)\n##  dichromat    * 2.0-0      2013-01-24 [1] CRAN (R 4.1.0)\n##  digest         0.6.29     2021-12-01 [1] CRAN (R 4.1.1)\n##  dplyr        * 1.0.8      2022-02-08 [1] CRAN (R 4.1.1)\n##  ellipsis       0.3.2      2021-04-29 [1] CRAN (R 4.1.0)\n##  emo            0.0.0.9000 2022-01-06 [1] Github (hadley/emo@3f03b11)\n##  evaluate       0.15       2022-02-18 [1] CRAN (R 4.1.1)\n##  fansi          1.0.2      2022-01-14 [1] CRAN (R 4.1.1)\n##  farver         2.1.0      2021-02-28 [1] CRAN (R 4.1.0)\n##  fastmap        1.1.0      2021-01-25 [1] CRAN (R 4.1.0)\n##  forcats      * 0.5.1      2021-01-27 [1] CRAN (R 4.1.1)\n##  fs             1.5.2      2021-12-08 [1] CRAN (R 4.1.1)\n##  gapminder    * 0.3.0      2017-10-31 [1] CRAN (R 4.1.0)\n##  generics       0.1.2      2022-01-31 [1] CRAN (R 4.1.1)\n##  gghalves     * 0.1.1      2020-11-08 [1] CRAN (R 4.1.1)\n##  ggplot2      * 3.3.5      2021-06-25 [1] CRAN (R 4.1.1)\n##  ggrepel      * 0.9.1      2021-01-15 [1] CRAN (R 4.1.1)\n##  ggridges     * 0.5.3      2021-01-08 [1] CRAN (R 4.1.1)\n##  ggtext       * 0.1.1      2020-12-17 [1] CRAN (R 4.1.1)\n##  ggthemes     * 4.2.4      2021-01-20 [1] CRAN (R 4.1.0)\n##  glue           1.6.1      2022-01-22 [1] CRAN (R 4.1.1)\n##  gridtext       0.1.4      2020-12-10 [1] CRAN (R 4.1.0)\n##  gtable         0.3.0      2019-03-25 [1] CRAN (R 4.1.1)\n##  haven          2.4.3      2021-08-04 [1] CRAN (R 4.1.1)\n##  here         * 1.0.1      2020-12-13 [1] CRAN (R 4.1.0)\n##  highr          0.9        2021-04-16 [1] CRAN (R 4.1.0)\n##  hms            1.1.1      2021-09-26 [1] CRAN (R 4.1.1)\n##  htmltools      0.5.2      2021-08-25 [1] CRAN (R 4.1.1)\n##  httr           1.4.2      2020-07-20 [1] CRAN (R 4.1.0)\n##  jquerylib      0.1.4      2021-04-26 [1] CRAN (R 4.1.0)\n##  jsonlite       1.8.0      2022-02-22 [1] CRAN (R 4.1.1)\n##  knitr        * 1.37       2021-12-16 [1] CRAN (R 4.1.1)\n##  labeling       0.4.2      2020-10-20 [1] CRAN (R 4.1.0)\n##  lifecycle      1.0.1      2021-09-24 [1] CRAN (R 4.1.1)\n##  lubridate    * 1.8.0      2021-10-07 [1] CRAN (R 4.1.1)\n##  magrittr       2.0.2      2022-01-26 [1] CRAN (R 4.1.1)\n##  markdown       1.1        2019-08-07 [1] CRAN (R 4.1.0)\n##  memoise        2.0.1      2021-11-26 [1] CRAN (R 4.1.1)\n##  modelr         0.1.8      2020-05-19 [1] CRAN (R 4.1.0)\n##  munsell        0.5.0      2018-06-12 [1] CRAN (R 4.1.0)\n##  patchwork    * 1.1.1      2020-12-17 [1] CRAN (R 4.1.1)\n##  pillar         1.7.0      2022-02-01 [1] CRAN (R 4.1.1)\n##  pkgbuild       1.3.1      2021-12-20 [1] CRAN (R 4.1.1)\n##  pkgconfig      2.0.3      2019-09-22 [1] CRAN (R 4.1.0)\n##  pkgload        1.2.4      2021-11-30 [1] CRAN (R 4.1.1)\n##  plyr           1.8.6      2020-03-03 [1] CRAN (R 4.1.0)\n##  prettyunits    1.1.1      2020-01-24 [1] CRAN (R 4.1.0)\n##  processx       3.5.2      2021-04-30 [1] CRAN (R 4.1.0)\n##  ps             1.6.0      2021-02-28 [1] CRAN (R 4.1.0)\n##  purrr        * 0.3.4      2020-04-17 [1] CRAN (R 4.1.0)\n##  R6             2.5.1      2021-08-19 [1] CRAN (R 4.1.1)\n##  RColorBrewer * 1.1-2      2014-12-07 [1] CRAN (R 4.1.0)\n##  Rcpp           1.0.8      2022-01-13 [1] CRAN (R 4.1.1)\n##  readr        * 2.1.2      2022-01-30 [1] CRAN (R 4.1.1)\n##  readxl         1.3.1      2019-03-13 [1] CRAN (R 4.1.0)\n##  remotes        2.4.2      2021-11-30 [1] CRAN (R 4.1.1)\n##  reprex         2.0.1      2021-08-05 [1] CRAN (R 4.1.1)\n##  RJSONIO        1.3-1.6    2021-09-16 [1] CRAN (R 4.1.1)\n##  rlang          1.0.1      2022-02-03 [1] CRAN (R 4.1.1)\n##  rmarkdown      2.11       2021-09-14 [1] CRAN (R 4.1.1)\n##  rprojroot      2.0.2      2020-11-15 [1] CRAN (R 4.1.0)\n##  rstudioapi     0.13       2020-11-12 [1] CRAN (R 4.1.0)\n##  rvest          1.0.2      2021-10-16 [1] CRAN (R 4.1.1)\n##  sass           0.4.0      2021-05-12 [1] CRAN (R 4.1.0)\n##  scales       * 1.1.1      2020-05-11 [1] CRAN (R 4.1.0)\n##  sessioninfo    1.2.2      2021-12-06 [1] CRAN (R 4.1.1)\n##  socviz       * 1.2        2020-06-10 [1] CRAN (R 4.1.0)\n##  stringi        1.7.6      2021-11-29 [1] CRAN (R 4.1.1)\n##  stringr      * 1.4.0      2019-02-10 [1] CRAN (R 4.1.1)\n##  testthat       3.1.2      2022-01-20 [1] CRAN (R 4.1.1)\n##  tibble       * 3.1.6      2021-11-07 [1] CRAN (R 4.1.1)\n##  tidyr        * 1.2.0      2022-02-01 [1] CRAN (R 4.1.1)\n##  tidyselect     1.1.2      2022-02-21 [1] CRAN (R 4.1.1)\n##  tidyverse    * 1.3.1      2021-04-15 [1] CRAN (R 4.1.0)\n##  tzdb           0.2.0      2021-10-27 [1] CRAN (R 4.1.1)\n##  usethis      * 2.1.5      2021-12-09 [1] CRAN (R 4.1.1)\n##  utf8           1.2.2      2021-07-24 [1] CRAN (R 4.1.0)\n##  vctrs          0.3.8      2021-04-29 [1] CRAN (R 4.1.0)\n##  viridisLite    0.4.0      2021-04-13 [1] CRAN (R 4.1.0)\n##  vroom          1.5.7      2021-11-30 [1] CRAN (R 4.1.1)\n##  WDI          * 2.7.6      2022-02-25 [1] CRAN (R 4.1.1)\n##  withr          2.4.3      2021-11-30 [1] CRAN (R 4.1.1)\n##  xfun           0.29       2021-12-14 [1] CRAN (R 4.1.1)\n##  xml2           1.3.3      2021-11-30 [1] CRAN (R 4.1.1)\n##  yaml           2.3.5      2022-02-21 [1] CRAN (R 4.1.1)\n## \n##  [1] /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library\n## \n## ──────────────────────────────────────────────────────────────────────────────"},{"path":"geoviz.html","id":"geoviz","chapter":"Day 4 Geospatial visualizations","heading":"Day 4 Geospatial visualizations","text":"","code":"\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(ggmap)\nlibrary(rnaturalearth)\nlibrary(RColorBrewer)\nlibrary(patchwork)\nlibrary(tidycensus)\nlibrary(viridis)\nlibrary(here)\n\n# useful on MacOS to speed up rendering of geom_sf() objects\nif (!identical(getOption(\"bitmapType\"), \"cairo\") && isTRUE(capabilities()[[\"cairo\"]])) {\n  options(bitmapType = \"cairo\")\n}"},{"path":"geoviz.html","id":"learning-objectives-3","chapter":"Day 4 Geospatial visualizations","heading":"Learning objectives","text":"","code":""},{"path":"geoviz.html","id":"morning-3","chapter":"Day 4 Geospatial visualizations","heading":"4.0.1 Morning","text":"Introduce major components geospatial visualizationIdentify draw raster maps using ggmaps get_map()Practice generating raster maps","code":""},{"path":"geoviz.html","id":"afternoon-3","chapter":"Day 4 Geospatial visualizations","heading":"4.0.2 Afternoon","text":"Define shapefiles import spatial data using sf packageDraw maps using ggplot2 geom_sf()Change coordinate systemsGenerate appropriate color palettes visualize additional dimensions data","code":""},{"path":"geoviz.html","id":"assigned-readings-3","chapter":"Day 4 Geospatial visualizations","heading":"Assigned readings","text":"Chapter 7, Healy (2018) - accessible via book’s website","code":""},{"path":"geoviz.html","id":"introduction-to-geospatial-visualization","chapter":"Day 4 Geospatial visualizations","heading":"4.1 Introduction to geospatial visualization","text":"Geospatial visualizations one earliest forms information visualizations. used historically navigation essential tools modern technological era humanity. Data maps first popularized seventeenth century grown complexity detail since . Consider Google Maps, sheer volume data depicted, analytical pathways available users. course geospatial data visualizations require computational skills generate.","code":""},{"path":"geoviz.html","id":"john-snow-and-the-broad-street-water-pump","chapter":"Day 4 Geospatial visualizations","heading":"4.1.1 John Snow and the Broad Street water pump","text":"\nFigure 1.6: Original map made John Snow 1854. Cholera cases highlighted black. Source: Wikipedia.\nnineteenth century theory bacteria widely accepted medical community public.12 mother washed baby’s diaper well 1854 London, sparking outbreak cholera, intestinal disease causes vomiting, diarrhea, eventually death. disease presented previously London cause still unknown.Dr. John Snow lived Soho, suburb London disease manifested 1854, wanted understand cholera spreads population (early day epidemiologist). Snow recorded location individuals contracted cholera, including places residence employment. used information draw map region, recording location individuals contracted disease. seemed clustered around well pump along Broad Street. Snow used map deduce source outbreak well, observing almost infected individuals lived near, drank , well. Based information, government removed handle well pump public draw water . result, cholera epidemic ended.","code":""},{"path":"geoviz.html","id":"carte-figurative-des-pertes-successives-en-hommes-de-larmée-française-dans-la-campagne-de-russie-1812-1813","chapter":"Day 4 Geospatial visualizations","heading":"4.1.2 Carte figurative des pertes successives en hommes de l’Armée Française dans la campagne de Russie 1812-1813)","text":"\nFigure 1.7: Charles Minard’s 1869 chart showing number men Napoleon’s 1812 Russian campaign army, movements, well temperature encountered return path. Source: Wikipedia.\n\nFigure 1.8: English translation Minard’s map. Source: Wikipedia.\nillustration identifed Edward Tufte’s Visual Display Quantitative Information one “best statistical drawings ever created”. also demonstrates important rule warfare: never invade Russia winter.1812, Napoleon ruled Europe. wanted seize control British islands, overcome UK defenses. decided impose embargo weaken nation preparation invasion, Russia refused participate. Angered decision, Napoleon launched invasion Russia 400,000 troops summer 1812. Russia unable defeat Napoleon battle, instead waged war attrition. Russian army near constant retreat, burning destroying anything value along way deny France usable resources. Napoleon’s army maintained military advantage, lack food emerging European winter decimated forces. left France army approximately 422,000 soldiers; returned France just 10,000.Charles Minard’s map stunning achievement era. incorporates data across six dimensions tell story Napoleon’s failure. graph depicts:Size armyLocation two physical dimensions (latitude longitude)Direction army’s movementTemperature dates Napoleon’s retreatWhat makes effective visualization?13Forces visual comparisons (colored bands advancing retreating)Shows causality (temperature chart)Captures multivariate complexityIntegrates text graphic coherent whole (perhaps first infographic, done well!)Illustrates high quality content (based reliable data)Places comparisons adjacent (page, jumping back forth pages)Mimimalistic nature (avoids later term “chart junk”)","code":""},{"path":"geoviz.html","id":"designing-modern-maps","chapter":"Day 4 Geospatial visualizations","heading":"4.1.3 Designing modern maps","text":"Geometric visualizations used depict spatial features, incorporation data reveal additional attributes information. main features map defined scale (proportion distances sizes map), projection (three-dimensional Earth represented two-dimensional surface), symbols (data depicted visualized map).","code":""},{"path":"geoviz.html","id":"scale-1","chapter":"Day 4 Geospatial visualizations","heading":"4.1.3.1 Scale","text":"Scale defines proportion distances sizes map actual distances sizes Earth. Depending total geographic area data visualize, create small-scale map large-scale map. instance, map United States considered large-scale:Whereas map Hyde Park small-scale:smaller scale, easier include additional details map.","code":""},{"path":"geoviz.html","id":"projection","chapter":"Day 4 Geospatial visualizations","heading":"4.1.3.2 Projection","text":"Projection process taking globe (.e. three-dimensional object)14 visualizing two-dimensional picture. 100% perfect method , projection method distort features map achieve two-dimensional representation. five properties consider defining projection method:ShapeAreaAnglesDistanceDirectionProjection methods typically maximize accuracy one two properties, . instance, conformal projections mercator projection preserves shape local angles useful sea navigation, distorts area landmasses.farther away equator one travels, distorted size region.Another family projections called equal-area projections preserves area ratios, relative size areas map proportional areas Earth.downside equal-area projections tend distory shapes heavily, shapes areas can become distorted. method can conformal equal-area simultaneously, methods Mollweide projection achieve trade-sets characteristics.","code":""},{"path":"geoviz.html","id":"symbols","chapter":"Day 4 Geospatial visualizations","heading":"4.1.3.3 Symbols","text":"Different types symbols used denote different types information spatial visualization. instance, consider following map Hyde Park:Line used indicate roadwaysFill used indicate type land (grassland, water, urban, etc.)Symbols/shapes used locate buildingsText labels used indicate geographic locationsData maps just encode geographic features visualization. also plot quantitative qualitative data mapping surface . Minard’s drawing just geographic coordinates features - also visualizes quantitative data troop deaths temperature. Different symbols used depending type data seek visualize.","code":""},{"path":"geoviz.html","id":"drawing-raster-maps-with-ggmap","chapter":"Day 4 Geospatial visualizations","heading":"4.2 Drawing raster maps with ggmap","text":"ggmap package R retrieves raster map tiles online mapping services like Google Maps plots using ggplot2 framework. map tiles raster static image files generated previously mapping service. need data files containing information things like scale, projection, boundaries, etc. information already created map tile. severely limits ability redraw change appearance geographic map, however tradeoff means can immediately focus incorporating additional data map.Google changed API requirements, ggmap users now required provide API key enable billing. recommend trying use Google Maps obtain map images. code work , Google now charges time obtain map image. Stick providers Stamen Maps.","code":""},{"path":"geoviz.html","id":"obtain-map-images","chapter":"Day 4 Geospatial visualizations","heading":"4.2.1 Obtain map images","text":"ggmap supports open-source map providers OpenStreetMap Stamen Maps, well proprietary Google Maps. Obtaining map tiles requires use get_map() function. two formats specifying mapping region wish obtain:Bounding boxCenter/zoom","code":""},{"path":"geoviz.html","id":"specifying-map-regions","chapter":"Day 4 Geospatial visualizations","heading":"4.2.2 Specifying map regions","text":"","code":""},{"path":"geoviz.html","id":"bounding-box","chapter":"Day 4 Geospatial visualizations","heading":"4.2.2.1 Bounding box","text":"Bounding box requires user specify four corners box defining map region. instance, obtain map Chicago using Stamen Maps:view map, use ggmap():zoom argument get_stamenmap() controls level detail map. larger number, greater detail.smaller number, lesser detail.Trial error help decide appropriate level detail depending data need visualize map.Use bboxfinder.com determine exact longitude/latitude coordinates bounding box wish obtain.","code":"\n# store bounding box coordinates\nchi_bb <- c(left = -87.936287,\n            bottom = 41.679835,\n            right = -87.447052,\n            top = 42.000835)\n\nchicago_stamen <- get_stamenmap(bbox = chi_bb,\n                                zoom = 11)\nchicago_stamen\n## 627x712 terrain map image from Stamen Maps. \n## See ?ggmap to plot it.\nggmap(chicago_stamen)\nget_stamenmap(bbox = chi_bb,\n              zoom = 12) %>%\n  ggmap()\nget_stamenmap(bbox = chi_bb,\n              zoom = 10) %>%\n  ggmap()"},{"path":"geoviz.html","id":"centerzoom","chapter":"Day 4 Geospatial visualizations","heading":"4.2.2.2 Center/zoom","text":"Stamen Maps OpenStreetMap require bounding box format obtaining map tiles allow increase decrease level detail within single bounding box, Google Maps requires specifying center coordinate map (single longitude/latitude location) level zoom detail. zoom integer value 3 (continent) 21 (building). means level detail hardcoded size mapping region. default zoom level 10.Use Find Latitude Longitude get exact GPS coordinates center location.","code":"\n# store center coordinate\nchi_center <- c(lon = -87.65, lat = 41.855)\n\nchicago_google <- get_googlemap(center = chi_center)\nggmap(chicago_google)\n\nget_googlemap(center = chi_center,\n              zoom = 12) %>%\n  ggmap()\n\nget_googlemap(center = chi_center,\n              zoom = 8) %>%\n  ggmap()"},{"path":"geoviz.html","id":"types-of-map-tiles","chapter":"Day 4 Geospatial visualizations","heading":"4.2.3 Types of map tiles","text":"map tile provider offers range different types maps depending background want map. Stamen Maps offers several different types:Google Maps bit limited, still offers major types:See documentation get_*map() function exact code necessary get type map.get_map() wrapper automatically queries Google Maps, OpenStreetMap, Stamen Maps depending function arguments inputs. useful, also combines different arguments get_googlemap(), get_stamenmap(), getopenstreetmap() can become bit jumbled. Use risk.","code":""},{"path":"geoviz.html","id":"import-crime-data","chapter":"Day 4 Geospatial visualizations","heading":"4.2.4 Import crime data","text":"Now can obtain map tiles draw using ggmap(), let’s explore add data map. city Chicago excellent data portal publishing large volume public records. ’ll look crime data 2017.15 previously downloaded .csv file containing records, import using read_csv():copying--pasting code demonstration, change line code crimes <- read_csv(\"https://cfss.uchicago.edu/data/Crimes_-_2017.csv\") download file course website.row data frame single reported incident crime. Geographic location encoded several ways, though importantly us exact longitude latitude incident encoded Longitude Latitude columns respectively.","code":"\ncrimes <- here(\"data\", \"Crimes_-_2017.csv\") %>%\n  read_csv()\nglimpse(crimes)\n## Rows: 267,345\n## Columns: 22\n## $ ID                     <dbl> 11094370, 11118031, 11134189, 11156462, 1116487…\n## $ `Case Number`          <chr> \"JA440032\", \"JA470589\", \"JA491697\", \"JA521389\",…\n## $ Date                   <chr> \"09/21/2017 12:15:00 AM\", \"10/12/2017 07:14:00 …\n## $ Block                  <chr> \"072XX N CALIFORNIA AVE\", \"055XX W GRAND AVE\", …\n## $ IUCR                   <chr> \"1122\", \"1345\", \"4651\", \"1110\", \"0265\", \"143A\",…\n## $ `Primary Type`         <chr> \"DECEPTIVE PRACTICE\", \"CRIMINAL DAMAGE\", \"OTHER…\n## $ Description            <chr> \"COUNTERFEIT CHECK\", \"TO CITY OF CHICAGO PROPER…\n## $ `Location Description` <chr> \"CURRENCY EXCHANGE\", \"JAIL / LOCK-UP FACILITY\",…\n## $ Arrest                 <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,…\n## $ Domestic               <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n## $ Beat                   <chr> \"2411\", \"2515\", \"0922\", \"2514\", \"1221\", \"0232\",…\n## $ District               <chr> \"024\", \"025\", \"009\", \"025\", \"012\", \"002\", \"005\"…\n## $ Ward                   <dbl> 50, 29, 12, 30, 32, 20, 9, 12, 12, 27, 32, 17, …\n## $ `Community Area`       <dbl> 2, 19, 58, 19, 24, 40, 49, 30, 30, 23, 24, 44, …\n## $ `FBI Code`             <chr> \"10\", \"14\", \"26\", \"11\", \"02\", \"15\", \"03\", \"06\",…\n## $ `X Coordinate`         <dbl> 1156443, 1138788, 1159425, 1138653, 1161264, 11…\n## $ `Y Coordinate`         <dbl> 1947707, 1913480, 1875711, 1920720, 1905292, 18…\n## $ Year                   <dbl> 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,…\n## $ `Updated On`           <chr> \"03/01/2018 03:52:35 PM\", \"03/01/2018 03:52:35 …\n## $ Latitude               <dbl> 42.0, 41.9, 41.8, 41.9, 41.9, 41.8, 41.7, 41.8,…\n## $ Longitude              <dbl> -87.7, -87.8, -87.7, -87.8, -87.7, -87.6, -87.6…\n## $ Location               <chr> \"(42.012293397, -87.699714109)\", \"(41.918711651…"},{"path":"geoviz.html","id":"plot-high-level-map-of-crime","chapter":"Day 4 Geospatial visualizations","heading":"4.2.5 Plot high-level map of crime","text":"Let’s start simple high-level overview reported crime Chicago. First need map entire city.","code":"\nchicago <- chicago_stamen\nggmap(chicago)"},{"path":"geoviz.html","id":"using-geom_point","chapter":"Day 4 Geospatial visualizations","heading":"4.2.6 Using geom_point()","text":"Since row single reported incident crime, use geom_point() map location every crime dataset. ggmap() uses map tiles (, defined chicago) basic input, specify data mapping inside geom_point(), rather inside ggplot():went wrong? get sea black.Oh yeah. 267345 reported incidents crime city. incident represented dot map. can make map usable? One option decrease size increase transparancy data point dense clusters crime become apparent:Better, still quite useful .","code":"\nggmap(chicago) +\n  geom_point(data = crimes,\n             mapping = aes(x = Longitude,\n                           y = Latitude))\nnrow(crimes)\n## [1] 267345\nggmap(chicago) +\n  geom_point(data = crimes,\n             aes(x = Longitude,\n                 y = Latitude),\n             size = .25,\n             alpha = .01)"},{"path":"geoviz.html","id":"using-stat_density_2d","chapter":"Day 4 Geospatial visualizations","heading":"4.2.7 Using stat_density_2d()","text":"Instead relying geom_point() plotting raw data, better approach create heatmap. precisely, two-dimensional kernel density estimation (KDE). context, KDE take raw data (.e. reported incidents crime) convert smoothed plot showing geographic concentrations crime. core function ggplot2 generate kind plot geom_density_2d():default, geom_density_2d() draws contour plot lines constant value. , line represents approximately frequency crime along specific line. Contour plots frequently used maps (known topographic maps) denote elevation.\nFigure 4.1: Cadillac Mountains. Source: US Geological Survey.\nRather drawing lines, instead can fill graph use fill aesthetic draw bands crime density. , use related function stat_density_2d():Note two new arguments:geom = \"polygon\" - change geometric object drawn density_2d geom polygon geomfill = stat(level) - value fill aesthetic level calculated within stat_density_2d(), access using stat() notation.improvement, can adjust additional settings make graph visually useful. Specifically,Increase number bins, unique bands color allowed graphMake heatmap semi-transparent using alpha can still view underlying mapChange color palette better distinguish high low crime areas. use brewer.pal() RColorBrewer package create custom color palette using reds yellows.map, couple trends noticeable:downtown region highest crime incidence rate. surprising given population density workday.clusters crime south west sides. Also surprising know anything city Chicago.","code":"\nggmap(chicago) +\n  geom_density_2d(data = crimes,\n                  aes(x = Longitude,\n                      y = Latitude))\nggmap(chicago) +\n  stat_density_2d(data = crimes,\n                  aes(x = Longitude,\n                      y = Latitude,\n                      fill = stat(level)),\n                  geom = \"polygon\")\nggmap(chicago) +\n  stat_density_2d(data = crimes,\n                  aes(x = Longitude,\n                      y = Latitude,\n                      fill = stat(level)),\n                  alpha = .2,\n                  bins = 25,\n                  geom = \"polygon\") +\n  scale_fill_gradientn(colors = brewer.pal(7, \"YlOrRd\"))"},{"path":"geoviz.html","id":"looking-for-variation","chapter":"Day 4 Geospatial visualizations","heading":"4.2.8 Looking for variation","text":"ggmap built ggplot2, can use core features ggplot2 modify graph. One major feature faceting. Let’s focus analysis four types crimes similar frequency reported incidents16 facet type crime:large difference geographic density narcotics crimes relative catgories. burglaries, motor vehicle thefts, robberies reasonably prevalent across city, vast majority narcotics crimes occur west south sides city.","code":"\nggmap(chicago) +\n  stat_density_2d(data = crimes %>%\n                    filter(`Primary Type` %in% c(\"BURGLARY\", \"MOTOR VEHICLE THEFT\",\n                                                 \"NARCOTICS\", \"ROBBERY\")),\n                  aes(x = Longitude,\n                      y = Latitude,\n                      fill = stat(level)),\n                  alpha = .4,\n                  bins = 10,\n                  geom = \"polygon\") +\n  scale_fill_gradientn(colors = brewer.pal(7, \"YlOrRd\")) +\n  facet_wrap(~ `Primary Type`)"},{"path":"geoviz.html","id":"locations-of-murders","chapter":"Day 4 Geospatial visualizations","heading":"4.2.9 Locations of murders","text":"geom_point() appropriate graphing large number observations dense geographic location, work rather well less dense areas. Now let’s limit analysis strictly reported incidents homicide 2017.can draw map city homicides indicated map using geom_point():Compared previous overviews, homicides reported downtown. can also narrow geographic location map specific neighborhoods Chicago. First obtain map tiles specific regions. ’ll examine North Lawndale Kenwood.plot homicides specifically neighborhoods, change ggmap(chicago) appropriate map tile:North Lawndale reported homicides 2017, whereas Kenwood handful. even though homicides contained data homicides across entire city, ggmap() automatically cropped graph keep just homicides occurred within bounding box.aesthetic customizations geom_point() work ggmap. expand neighborhood maps include violent crime categories17 distinguish type color:","code":"\n(homicides <- crimes %>%\n  filter(`Primary Type` == \"HOMICIDE\"))\n## # A tibble: 671 × 22\n##          ID `Case Number` Date            Block IUCR  `Primary Type` Description\n##       <dbl> <chr>         <chr>           <chr> <chr> <chr>          <chr>      \n##  1    23128 JA149608      02/11/2017 07:… 001X… 0110  HOMICIDE       FIRST DEGR…\n##  2    23851 JA530946      11/30/2017 11:… 088X… 0110  HOMICIDE       FIRST DEGR…\n##  3    23355 JA302423      06/11/2017 06:… 047X… 0110  HOMICIDE       FIRST DEGR…\n##  4    23379 JA312425      06/18/2017 04:… 006X… 0110  HOMICIDE       FIRST DEGR…\n##  5    23673 JA490016      10/28/2017 10:… 048X… 0110  HOMICIDE       FIRST DEGR…\n##  6    23224 JA210752      04/03/2017 12:… 013X… 0110  HOMICIDE       FIRST DEGR…\n##  7    23627 JA461918      10/07/2017 11:… 018X… 0110  HOMICIDE       FIRST DEGR…\n##  8    23628 JA461918      10/07/2017 11:… 018X… 0110  HOMICIDE       FIRST DEGR…\n##  9 10836558 JA138326      02/01/2017 06:… 013X… 0142  HOMICIDE       RECKLESS H…\n## 10    23477 JA364517      07/26/2017 05:… 047X… 0110  HOMICIDE       FIRST DEGR…\n## # … with 661 more rows, and 15 more variables: `Location Description` <chr>,\n## #   Arrest <lgl>, Domestic <lgl>, Beat <chr>, District <chr>, Ward <dbl>,\n## #   `Community Area` <dbl>, `FBI Code` <chr>, `X Coordinate` <dbl>,\n## #   `Y Coordinate` <dbl>, Year <dbl>, `Updated On` <chr>, Latitude <dbl>,\n## #   Longitude <dbl>, Location <chr>\nggmap(chicago) +\n  geom_point(data = homicides,\n             mapping = aes(x = Longitude,\n                           y = Latitude),\n             size = 1)\n# North Lawndale is the highest homicides in 2017\n# Compare to Kenwood\nnorth_lawndale_bb <- c(\n  left = -87.749047,\n  bottom = 41.840185,\n  right = -87.687893,\n  top = 41.879850\n)\nnorth_lawndale <- get_stamenmap(bbox = north_lawndale_bb,\n                                zoom = 14)\n\nkenwood_bb <- c(\n  left = -87.613113,\n  bottom = 41.799215,\n  right = -87.582536,\n  top = 41.819064\n)\nkenwood <- get_stamenmap(bbox = kenwood_bb,\n                                zoom = 15)\n\nggmap(north_lawndale)\nggmap(kenwood)\nggmap(north_lawndale) +\n  geom_point(data = homicides,\n             aes(x = Longitude, y = Latitude))\n\nggmap(kenwood) +\n  geom_point(data = homicides,\n             aes(x = Longitude, y = Latitude))\n(violent <- crimes %>%\n  filter(`Primary Type` %in% c(\"HOMICIDE\",\n                               \"CRIM SEXUAL ASSAULT\",\n                               \"ROBBERY\")))\n## # A tibble: 14,146 × 22\n##          ID `Case Number` Date            Block IUCR  `Primary Type` Description\n##       <dbl> <chr>         <chr>           <chr> <chr> <chr>          <chr>      \n##  1 11164874 JA531910      12/01/2017 06:… 022X… 0265  CRIM SEXUAL A… AGGRAVATED…\n##  2 10995008 JA322389      06/25/2017 07:… 003X… 031A  ROBBERY        ARMED: HAN…\n##  3 11175304 JA545986      12/11/2017 07:… 007X… 031A  ROBBERY        ARMED: HAN…\n##  4 11175934 JA546734      12/12/2017 06:… 007X… 031A  ROBBERY        ARMED: HAN…\n##  5 11227287 JB147188      10/08/2017 03:… 092X… 0281  CRIM SEXUAL A… NON-AGGRAV…\n##  6 11227634 JB147599      08/26/2017 10:… 001X… 0281  CRIM SEXUAL A… NON-AGGRAV…\n##  7    23128 JA149608      02/11/2017 07:… 001X… 0110  HOMICIDE       FIRST DEGR…\n##  8 11043709 JA378592      08/05/2017 03:… 038X… 0313  ROBBERY        ARMED: OTH…\n##  9 11170225 JA538651      12/06/2017 09:… 092X… 031A  ROBBERY        ARMED: HAN…\n## 10 11228964 JB149656      12/24/2017 02:… 005X… 0330  ROBBERY        AGGRAVATED \n## # … with 14,136 more rows, and 15 more variables: `Location Description` <chr>,\n## #   Arrest <lgl>, Domestic <lgl>, Beat <chr>, District <chr>, Ward <dbl>,\n## #   `Community Area` <dbl>, `FBI Code` <chr>, `X Coordinate` <dbl>,\n## #   `Y Coordinate` <dbl>, Year <dbl>, `Updated On` <chr>, Latitude <dbl>,\n## #   Longitude <dbl>, Location <chr>\nggmap(north_lawndale) +\n  geom_point(data = violent,\n             aes(x = Longitude, y = Latitude,\n                 color = `Primary Type`)) +\n  scale_color_brewer(type = \"qual\", palette = \"Dark2\")\n\nggmap(kenwood) +\n  geom_point(data = violent,\n             aes(x = Longitude, y = Latitude,\n                 color = `Primary Type`)) +\n  scale_color_brewer(type = \"qual\", palette = \"Dark2\")"},{"path":"geoviz.html","id":"exercise-chicago-311-data","chapter":"Day 4 Geospatial visualizations","heading":"4.3 Exercise: Chicago 311 data","text":"city Chicago excellent data portal publishing large volume public records. ’ll look subset 311 service requests. used RSocrata data portal’s API retrieve portion data set.Download necessary data files following coding exercises using usethis::use_course(\"css-data-mining-viz/geoviz\").","code":"\nchi_311 <- read_csv(\"data/chi-311.csv\")\nglimpse(chi_311)\n## Rows: 167,552\n## Columns: 8\n## $ sr_number      <chr> \"SR19-01209373\", \"SR19-01129184\", \"SR19-01130159\", \"SR1…\n## $ sr_type        <chr> \"Dead Animal Pick-Up Request\", \"Dead Animal Pick-Up Req…\n## $ sr_short_code  <chr> \"SGQ\", \"SGQ\", \"SGQ\", \"SGQ\", \"SGQ\", \"SGQ\", \"SGQ\", \"SGQ\",…\n## $ created_date   <dttm> 2019-03-23 17:13:05, 2019-03-09 01:37:26, 2019-03-09 1…\n## $ community_area <dbl> 58, 40, 40, 67, 59, 59, 2, 59, 59, 64, 59, 25, 25, 59, …\n## $ ward           <dbl> 12, 20, 20, 17, 12, 12, 40, 12, 12, 13, 12, 29, 28, 12,…\n## $ latitude       <dbl> 41.8, 41.8, 41.8, 41.8, 41.8, 41.8, 42.0, 41.8, 41.8, 4…\n## $ longitude      <dbl> -87.7, -87.6, -87.6, -87.7, -87.7, -87.7, -87.7, -87.7,…"},{"path":"geoviz.html","id":"visualize-the-311-data","chapter":"Day 4 Geospatial visualizations","heading":"4.3.1 Visualize the 311 data","text":"Obtain map tiles using ggmap city Chicago.\nClick solution\n\n\n# store bounding box coordinates\nchi_bb <- c(left = -87.936287,\n            bottom = 41.679835,\n            right = -87.447052,\n            top = 42.000835)\n\n# retrieve bounding box\nchicago <- get_stamenmap(bbox = chi_bb,\n                         zoom = 11)\n\n# plot raster map\nggmap(chicago)\n\n\nObtain map tiles using ggmap city Chicago.Click solution\nGenerate scatterplot complaints potholes streets.\nClick solution\n\n\n# initialize map\nggmap(chicago) +\n  # add layer scatterplot\n  # use alpha show density points\n  geom_point(data = filter(chi_311, sr_type == \"Pothole Street Complaint\"),\n             mapping = aes(x = longitude,\n                           y = latitude),\n             size = .25,\n             alpha = .05)\n\n\nGenerate scatterplot complaints potholes streets.Click solution\nGenerate heatmap complaints potholes streets. see unusual patterns clusterings?\nClick solution\n\n\n# initialize map\nggmap(chicago) +\n  # add heatmap\n  stat_density_2d(data = filter(chi_311, sr_type == \"Pothole Street Complaint\"),\n                  mapping = aes(x = longitude,\n                                y = latitude,\n                                fill = stat(level)),\n                  alpha = .1,\n                  bins = 50,\n                  geom = \"polygon\") +\n  # customize color gradient\n  scale_fill_gradientn(colors = brewer.pal(9, \"YlOrRd\"))\n\nSeems clustered north side. Also looks occur along major arterial routes commuting traffic. Makes sense receive wear tear.\n\nGenerate heatmap complaints potholes streets. see unusual patterns clusterings?Click solution\nSeems clustered north side. Also looks occur along major arterial routes commuting traffic. Makes sense receive wear tear.Obtain map tiles Hyde Park.\nClick solution\n\n\n# store bounding box coordinates\nhp_bb <- c(left = -87.608221,\n           bottom = 41.783249,\n           right = -87.577643,\n           top = 41.803038)\n\n# retrieve bounding box\nhyde_park <- get_stamenmap(bbox = hp_bb,\n                           zoom = 15)\n\n# plot raster map\nggmap(hyde_park)\n\n\nObtain map tiles Hyde Park.Click solution\nGenerate scatterplot requests pick dead animals Hyde Park.\nClick solution\n\n\n# initialize map\nggmap(hyde_park) +\n  # add scatterplot layer\n  geom_point(data = filter(chi_311, sr_type == \"Dead Animal Pick-Request\"),\n             mapping = aes(x = longitude,\n                           y = latitude))\n\n\nGenerate scatterplot requests pick dead animals Hyde Park.Click solution\n","code":"\n# store bounding box coordinates\nchi_bb <- c(left = -87.936287,\n            bottom = 41.679835,\n            right = -87.447052,\n            top = 42.000835)\n\n# retrieve bounding box\nchicago <- get_stamenmap(bbox = chi_bb,\n                         zoom = 11)\n\n# plot the raster map\nggmap(chicago)\n# initialize map\nggmap(chicago) +\n  # add layer with scatterplot\n  # use alpha to show density of points\n  geom_point(data = filter(chi_311, sr_type == \"Pothole in Street Complaint\"),\n             mapping = aes(x = longitude,\n                           y = latitude),\n             size = .25,\n             alpha = .05)\n# initialize the map\nggmap(chicago) +\n  # add the heatmap\n  stat_density_2d(data = filter(chi_311, sr_type == \"Pothole in Street Complaint\"),\n                  mapping = aes(x = longitude,\n                                y = latitude,\n                                fill = stat(level)),\n                  alpha = .1,\n                  bins = 50,\n                  geom = \"polygon\") +\n  # customize the color gradient\n  scale_fill_gradientn(colors = brewer.pal(9, \"YlOrRd\"))\n# store bounding box coordinates\nhp_bb <- c(left = -87.608221,\n           bottom = 41.783249,\n           right = -87.577643,\n           top = 41.803038)\n\n# retrieve bounding box\nhyde_park <- get_stamenmap(bbox = hp_bb,\n                           zoom = 15)\n\n# plot the raster map\nggmap(hyde_park)\n# initialize the map\nggmap(hyde_park) +\n  # add a scatterplot layer\n  geom_point(data = filter(chi_311, sr_type == \"Dead Animal Pick-Up Request\"),\n             mapping = aes(x = longitude,\n                           y = latitude))"},{"path":"geoviz.html","id":"importing-spatial-data-files-using-sf","chapter":"Day 4 Geospatial visualizations","heading":"4.4 Importing spatial data files using sf","text":"Rather storing spatial data raster image files easily modifiable, can instead store spatial data vector files. Vector files store underlying geographical features (e.g. points, lines, polygons) numerical data software R can import use draw map.many popular file formats storing spatial data. look two common file types, shapefiles GeoJSON.","code":""},{"path":"geoviz.html","id":"file-formats","chapter":"Day 4 Geospatial visualizations","heading":"4.5 File formats","text":"","code":""},{"path":"geoviz.html","id":"shapefile","chapter":"Day 4 Geospatial visualizations","heading":"4.5.1 Shapefile","text":"Shapefiles commonly supported file type spatial data dating back early 1990s. Proprietary software geographic information systems (GIS) ArcGIS pioneered format helps maintain continued usage. shapefile encodes points, lines, polygons geographic space, actually set files. Shapefiles appear .shp extension, sometimes accompanying files ending .dbf .prj..shp stores geographic coordinates geographic features (e.g. country, state, county).dbf stores data associated geographic features (e.g. unemployment rate, crime rates, percentage votes cast Donald Trump).prj stores information projection coordinates shapefileWhen importing shapefile, need ensure files folder. example, structure Census Bureau’s 2013 state boundaries shapefile:complete shapefile. files missing, get error importing shapefile:","code":"## -- cb_2013_us_county_20m.dbf\n## -- cb_2013_us_county_20m.prj\n## -- cb_2013_us_county_20m.shp\n## -- cb_2013_us_county_20m.shp.iso.xml\n## -- cb_2013_us_county_20m.shp.xml\n## -- cb_2013_us_county_20m.shx\n## -- county_20m.ea.iso.xml## Error in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, : Open failed."},{"path":"geoviz.html","id":"geojson","chapter":"Day 4 Geospatial visualizations","heading":"4.5.2 GeoJSON","text":"GeoJSON newer format encoding variety geographical data structures using JavaScript Object Notation (JSON) file format. JSON formatted data frequently used web development services. explore detail get collecting data web. example GeoJSON file :GeoJSON files plain text files can contain many different types geometric features.","code":"{\n  \"type\": \"Feature\",\n  \"geometry\": {\n    \"type\": \"Point\",\n    \"coordinates\": [125.6, 10.1]\n  },\n  \"properties\": {\n    \"name\": \"Dinagat Islands\"\n  }\n}"},{"path":"geoviz.html","id":"simple-features","chapter":"Day 4 Geospatial visualizations","heading":"4.6 Simple features","text":"crap ton packages R allow interact shapefiles spatial data. focus modern package reading transforming spatial data tidy format. Simple features simple feature access refers formal standard describes objects real world can represented computers, emphasis spatial geometry objects. also describes objects can stored retrieved databases, geometrical operations defined .standard widely implemented spatial databases (PostGIS), commercial GIS (e.g., ESRI ArcGIS) forms vector data basis libraries GDAL. subset simple features forms GeoJSON standard.R well-supported classes storing spatial data (sp) interfacing mentioned environments (rgdal, rgeos), far lacked complete implementation simple features, making conversions times convoluted, inefficient incomplete. sf package tries fill gap.","code":""},{"path":"geoviz.html","id":"what-is-a-feature","chapter":"Day 4 Geospatial visualizations","heading":"4.6.1 What is a feature?","text":"feature thing object real world. Often features consist set features. instance, tree can feature set trees can form forest feature. Features geometry describing Earth feature located. also attributes, describe properties feature.","code":""},{"path":"geoviz.html","id":"dimensions","chapter":"Day 4 Geospatial visualizations","heading":"4.6.2 Dimensions","text":"geometries composed points. Points coordinates 2-, 3- 4-dimensional space. points geometry dimensionality. addition X Y coordinates, two optional additional dimensions:Z coordinate, denoting altitudean M coordinate (rarely used), denoting measure associated point, rather feature whole (case feature attribute); examples time measurement, measurement error coordinatesThe four possible cases :two-dimensional points refer x y, easting northing, longitude latitude, refer XYthree-dimensional points XYZthree-dimensional points XYMfour-dimensional points XYZM (third axis Z, fourth M)","code":""},{"path":"geoviz.html","id":"simple-feature-geometry-types","chapter":"Day 4 Geospatial visualizations","heading":"4.6.3 Simple feature geometry types","text":"following seven simple feature types common, instance ones used GeoJSON:","code":""},{"path":"geoviz.html","id":"coordinate-reference-system","chapter":"Day 4 Geospatial visualizations","heading":"4.6.4 Coordinate reference system","text":"Coordinates can placed Earth’s surface coordinate reference system (CRS) known; may spheroid CRS WGS84, projected, two-dimensional (Cartesian) CRS UTM zone Web Mercator, CRS three-dimensions, including time. Similarly, M-coordinates need attribute reference system, e.g. measurement unit.","code":""},{"path":"geoviz.html","id":"simple-features-in-r","chapter":"Day 4 Geospatial visualizations","heading":"4.7 Simple features in R","text":"sf stores simple features basic R data structures (lists, matrix, vectors, etc.). typical data structure stores geometric feature attributes data frame one row per feature. However since feature geometries single-valued, put list-column list element holding simple feature geometry feature.","code":""},{"path":"geoviz.html","id":"importing-spatial-data-using-sf","chapter":"Day 4 Geospatial visualizations","heading":"4.7.1 Importing spatial data using sf","text":"st_read() imports spatial data file converts simple feature data frame. import shapefile containing spatial boundaries community area city Chicago.short report printed gives file name, mentions 77 features (records, represented rows) 10 fields (attributes, represented columns), states spatial data file MULTIPOLYGON, provides bounding box coordinates, identifies projection method (discuss later). print first rows chi_shape:output see:row simple feature: single record, data.frame row, consisting attributes geometryThe geometry column simple feature list-column (object class sfc, column data.frame)value geometry single simple feature geometry (object class sfg)start recognize data frame structure. Substantively, community defines name community area row.st_read() also works GeoJSON files.","code":"\nchi_shape <- here(\"data/Boundaries - Community Areas (current)/geo_export_328cdcbf-33ba-4997-8ce8-90953c6fec19.shp\") %>%\n  st_read()\n## Reading layer `geo_export_328cdcbf-33ba-4997-8ce8-90953c6fec19' from data source `/Users/soltoffbc/Projects/Data Visualization/course-notes/data/Boundaries - Community Areas (current)/geo_export_328cdcbf-33ba-4997-8ce8-90953c6fec19.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 77 features and 9 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -87.9 ymin: 41.6 xmax: -87.5 ymax: 42\n## Geodetic CRS:  WGS84(DD)\nchi_shape\n## Simple feature collection with 77 features and 9 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -87.9 ymin: 41.6 xmax: -87.5 ymax: 42\n## Geodetic CRS:  WGS84(DD)\n## First 10 features:\n##    perimeter       community shape_len shape_area area comarea area_numbe\n## 1          0         DOUGLAS     31027   46004621    0       0         35\n## 2          0         OAKLAND     19566   16913961    0       0         36\n## 3          0     FULLER PARK     25339   19916705    0       0         37\n## 4          0 GRAND BOULEVARD     28197   48492503    0       0         38\n## 5          0         KENWOOD     23325   29071742    0       0         39\n## 6          0  LINCOLN SQUARE     36625   71352328    0       0          4\n## 7          0 WASHINGTON PARK     28175   42373881    0       0         40\n## 8          0       HYDE PARK     29747   45105380    0       0         41\n## 9          0        WOODLAWN     46937   57815180    0       0         42\n## 10         0     ROGERS PARK     34052   51259902    0       0          1\n##    area_num_1 comarea_id                       geometry\n## 1          35          0 MULTIPOLYGON (((-87.6 41.8,...\n## 2          36          0 MULTIPOLYGON (((-87.6 41.8,...\n## 3          37          0 MULTIPOLYGON (((-87.6 41.8,...\n## 4          38          0 MULTIPOLYGON (((-87.6 41.8,...\n## 5          39          0 MULTIPOLYGON (((-87.6 41.8,...\n## 6           4          0 MULTIPOLYGON (((-87.7 42, -...\n## 7          40          0 MULTIPOLYGON (((-87.6 41.8,...\n## 8          41          0 MULTIPOLYGON (((-87.6 41.8,...\n## 9          42          0 MULTIPOLYGON (((-87.6 41.8,...\n## 10          1          0 MULTIPOLYGON (((-87.7 42, -...\nchi_json <- here(\"data/Boundaries - Community Areas (current).geojson\") %>%\n  st_read()\n## Reading layer `Boundaries - Community Areas (current)' from data source \n##   `/Users/soltoffbc/Projects/Data Visualization/course-notes/data/Boundaries - Community Areas (current).geojson' \n##   using driver `GeoJSON'\n## Simple feature collection with 77 features and 9 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -87.9 ymin: 41.6 xmax: -87.5 ymax: 42\n## Geodetic CRS:  WGS 84\nchi_json\n## Simple feature collection with 77 features and 9 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -87.9 ymin: 41.6 xmax: -87.5 ymax: 42\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##          community area    shape_area perimeter area_num_1 area_numbe\n## 1          DOUGLAS    0 46004621.1581         0         35         35\n## 2          OAKLAND    0 16913961.0408         0         36         36\n## 3      FULLER PARK    0 19916704.8692         0         37         37\n## 4  GRAND BOULEVARD    0 48492503.1554         0         38         38\n## 5          KENWOOD    0 29071741.9283         0         39         39\n## 6   LINCOLN SQUARE    0 71352328.2399         0          4          4\n## 7  WASHINGTON PARK    0 42373881.4842         0         40         40\n## 8        HYDE PARK    0 45105380.1732         0         41         41\n## 9         WOODLAWN    0  57815179.512         0         42         42\n## 10     ROGERS PARK    0 51259902.4506         0          1          1\n##    comarea_id comarea     shape_len                       geometry\n## 1           0       0 31027.0545098 MULTIPOLYGON (((-87.6 41.8,...\n## 2           0       0 19565.5061533 MULTIPOLYGON (((-87.6 41.8,...\n## 3           0       0 25339.0897503 MULTIPOLYGON (((-87.6 41.8,...\n## 4           0       0 28196.8371573 MULTIPOLYGON (((-87.6 41.8,...\n## 5           0       0 23325.1679062 MULTIPOLYGON (((-87.6 41.8,...\n## 6           0       0 36624.6030848 MULTIPOLYGON (((-87.7 42, -...\n## 7           0       0 28175.3160866 MULTIPOLYGON (((-87.6 41.8,...\n## 8           0       0 29746.7082016 MULTIPOLYGON (((-87.6 41.8,...\n## 9           0       0 46936.9592443 MULTIPOLYGON (((-87.6 41.8,...\n## 10          0       0 34052.3975757 MULTIPOLYGON (((-87.7 42, -..."},{"path":"geoviz.html","id":"drawing-vector-maps-with-sf-and-ggplot2","chapter":"Day 4 Geospatial visualizations","heading":"4.8 Drawing vector maps with sf and ggplot2","text":"Unlike raster image maps, vector maps require obtain spatial data files contain detailed information necessary draw components map (e.g. points, lines, polygons). successfully import data R, ggplot2 works simple features data frames easily generate geospatial visualizations using core elements approaches ggplot().","code":""},{"path":"geoviz.html","id":"import-usa-state-boundaries","chapter":"Day 4 Geospatial visualizations","heading":"4.8.1 Import USA state boundaries","text":"First import spatial data file containing boundaries 50 states United States18 using sf::st_read():","code":"\nusa <- here(\"data\", \"census_bureau\",\n            \"cb_2013_us_state_20m\", \"cb_2013_us_state_20m.shp\") %>%\n  st_read()\n## Reading layer `cb_2013_us_state_20m' from data source \n##   `/Users/soltoffbc/Projects/Data Visualization/course-notes/data/census_bureau/cb_2013_us_state_20m/cb_2013_us_state_20m.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 52 features and 9 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -179 ymin: 17.9 xmax: 180 ymax: 71.4\n## Geodetic CRS:  NAD83"},{"path":"geoviz.html","id":"draw-the-boundaries","chapter":"Day 4 Geospatial visualizations","heading":"4.8.2 Draw the boundaries","text":"ggplot2 contains geometric object specifically simple feature objects called geom_sf(). works reasonably well need draw polygons, like state boundaries. Support simple features ggplot2 active development, may find adequate support plotting line point features. draw map, pass simple features data frame data argument.simple features data frames standardized geometry column always containing information geographic coordinates features, need specify additional parameters aes(). Notice problem map : wastes lot space. caused presence Alaska Hawaii dataset. Aleutian Islands cross 180th meridian, requiring map show Eastern hemisphere. Likewise, Hawaii substantially distant continental United States.","code":"\nggplot(data = usa) +\n  geom_sf()"},{"path":"geoviz.html","id":"plot-a-subset-of-a-map","chapter":"Day 4 Geospatial visualizations","heading":"4.8.2.1 Plot a subset of a map","text":"One solution plot just lower 48 states. , exclude Alaska Hawaii, well DC Puerto Rico.19 simple features data frames contain one row per feature example feature defined state, can use filter() dplyr exclude four states/territories.Since map ggplot() object, can easily modified like ggplot() graph. change color map borders:","code":"\n(usa_48 <- usa %>%\n  filter(!(NAME %in% c(\"Alaska\", \"District of Columbia\", \"Hawaii\", \"Puerto Rico\"))))\n## Simple feature collection with 48 features and 9 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -125 ymin: 24.5 xmax: -66.9 ymax: 49.4\n## Geodetic CRS:  NAD83\n## First 10 features:\n##    STATEFP  STATENS    AFFGEOID GEOID STUSPS        NAME LSAD    ALAND   AWATER\n## 1       01 01779775 0400000US01    01     AL     Alabama   00 1.31e+11 4.59e+09\n## 2       05 00068085 0400000US05    05     AR    Arkansas   00 1.35e+11 2.96e+09\n## 3       06 01779778 0400000US06    06     CA  California   00 4.03e+11 2.05e+10\n## 4       09 01779780 0400000US09    09     CT Connecticut   00 1.25e+10 1.82e+09\n## 5       12 00294478 0400000US12    12     FL     Florida   00 1.39e+11 3.14e+10\n## 6       13 01705317 0400000US13    13     GA     Georgia   00 1.49e+11 4.95e+09\n## 7       16 01779783 0400000US16    16     ID       Idaho   00 2.14e+11 2.40e+09\n## 8       17 01779784 0400000US17    17     IL    Illinois   00 1.44e+11 6.20e+09\n## 9       18 00448508 0400000US18    18     IN     Indiana   00 9.28e+10 1.54e+09\n## 10      20 00481813 0400000US20    20     KS      Kansas   00 2.12e+11 1.35e+09\n##                          geometry\n## 1  MULTIPOLYGON (((-88.3 30.2,...\n## 2  MULTIPOLYGON (((-94.6 36.5,...\n## 3  MULTIPOLYGON (((-119 33.5, ...\n## 4  MULTIPOLYGON (((-73.7 41.1,...\n## 5  MULTIPOLYGON (((-80.7 24.9,...\n## 6  MULTIPOLYGON (((-85.6 35, -...\n## 7  MULTIPOLYGON (((-117 44.4, ...\n## 8  MULTIPOLYGON (((-91.5 40.2,...\n## 9  MULTIPOLYGON (((-88.1 37.9,...\n## 10 MULTIPOLYGON (((-102 40, -1...\n\nggplot(data = usa_48) +\n  geom_sf()\nggplot(data = usa_48) +\n  geom_sf(fill = \"palegreen\", color = \"black\")"},{"path":"geoviz.html","id":"albersusa","chapter":"Day 4 Geospatial visualizations","heading":"4.8.2.2 albersusa","text":"Rather excluding entirely, maps United States place Alaska Hawaii insets south California. recently, R extremely tedious task required manually changing latitude longitude coordinates states place correct location. Fortunately several packages now available already done work . albersusa includes usa_sf() function returns simple features data frame contains adjusted coordinates Alaska Hawaii plot mainland. can installed GitHub using devtools::install_github(\"hrbrmstr/albersusa\").","code":"\nlibrary(albersusa)\nusa_sf()\n## Simple feature collection with 51 features and 13 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -125 ymin: 20.6 xmax: -66.9 ymax: 49.4\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##         geo_id fips_state                 name lsad census_area iso_3166_2\n## 1  0400000US04         04              Arizona           113594         AZ\n## 2  0400000US05         05             Arkansas            52035         AR\n## 3  0400000US06         06           California           155779         CA\n## 4  0400000US08         08             Colorado           103642         CO\n## 5  0400000US09         09          Connecticut             4842         CT\n## 6  0400000US11         11 District of Columbia               61         DC\n## 7  0400000US13         13              Georgia            57513         GA\n## 8  0400000US17         17             Illinois            55519         IL\n## 9  0400000US18         18              Indiana            35826         IN\n## 10 0400000US22         22            Louisiana            43204         LA\n##      census pop_estimataes_base pop_2010 pop_2011 pop_2012 pop_2013 pop_2014\n## 1   6392017             6392310  6411999  6472867  6556236  6634997  6731484\n## 2   2915918             2915958  2922297  2938430  2949300  2958765  2966369\n## 3  37253956            37254503 37336011 37701901 38062780 38431393 38802500\n## 4   5029196             5029324  5048575  5119661  5191709  5272086  5355866\n## 5   3574097             3574096  3579345  3590537  3594362  3599341  3596677\n## 6    601723              601767   605210   620427   635040   649111   658893\n## 7   9687653             9688681  9714464  9813201  9919000  9994759 10097343\n## 8  12830632            12831587 12840097 12858725 12873763 12890552 12880580\n## 9   6483802             6484192  6490308  6516560  6537632  6570713  6596855\n## 10  4533372             4533479  4545581  4575972  4604744  4629284  4649676\n##                          geometry\n## 1  MULTIPOLYGON (((-113 37, -1...\n## 2  MULTIPOLYGON (((-94 33, -94...\n## 3  MULTIPOLYGON (((-120 34, -1...\n## 4  MULTIPOLYGON (((-107 41, -1...\n## 5  MULTIPOLYGON (((-72.4 42, -...\n## 6  MULTIPOLYGON (((-77 38.8, -...\n## 7  MULTIPOLYGON (((-84.8 35, -...\n## 8  MULTIPOLYGON (((-89.4 42.5,...\n## 9  MULTIPOLYGON (((-84.8 40.4,...\n## 10 MULTIPOLYGON (((-88.9 29.8,...\n\nggplot(data = usa_sf()) +\n  geom_sf()"},{"path":"geoviz.html","id":"add-data-to-the-map","chapter":"Day 4 Geospatial visualizations","heading":"4.8.3 Add data to the map","text":"Region boundaries serve background geospatial data visualization - now need add data. types geographic data (points symbols) overlaid top boundaries, whereas data (fill) incorporated region layer .","code":""},{"path":"geoviz.html","id":"points-1","chapter":"Day 4 Geospatial visualizations","heading":"4.8.3.1 Points","text":"Let’s use usa_48 map data add points. airports data frame nycflights13 package includes geographic info airports United States.airport ’s geographic location encoded lat lon. draw points map, basically draw scatterplot x = lon y = lat. fact simply :Let’s overlay mapped state borders:Slight problem. airports listed outside continental United States. couple ways rectify . Unfortunately airports include variable identifying state filter() operation simple. easiest solution crop limits graph using coord_sf() show mainland:Alternatively, can use st_as_sf() convert airports simple features data frame.coords tells st_as_sf() columns contain geographic coordinates airport. graph points map, use second geom_sf():","code":"\nlibrary(nycflights13)\nairports\n## # A tibble: 1,458 × 8\n##    faa   name                             lat    lon   alt    tz dst   tzone    \n##    <chr> <chr>                          <dbl>  <dbl> <dbl> <dbl> <chr> <chr>    \n##  1 04G   Lansdowne Airport               41.1  -80.6  1044    -5 A     America/…\n##  2 06A   Moton Field Municipal Airport   32.5  -85.7   264    -6 A     America/…\n##  3 06C   Schaumburg Regional             42.0  -88.1   801    -6 A     America/…\n##  4 06N   Randall Airport                 41.4  -74.4   523    -5 A     America/…\n##  5 09J   Jekyll Island Airport           31.1  -81.4    11    -5 A     America/…\n##  6 0A9   Elizabethton Municipal Airport  36.4  -82.2  1593    -5 A     America/…\n##  7 0G6   Williams County Airport         41.5  -84.5   730    -5 A     America/…\n##  8 0G7   Finger Lakes Regional Airport   42.9  -76.8   492    -5 A     America/…\n##  9 0P2   Shoestring Aviation Airfield    39.8  -76.6  1000    -5 U     America/…\n## 10 0S9   Jefferson County Intl           48.1 -123.    108    -8 A     America/…\n## # … with 1,448 more rows\nggplot(airports, aes(lon, lat)) +\n  geom_point()\nggplot(data = usa_48) + \n  geom_sf() + \n  geom_point(data = airports, aes(x = lon, y = lat), shape = 1)\nggplot(data = usa_48) + \n  geom_sf() + \n  geom_point(data = airports, aes(x = lon, y = lat), shape = 1) +\n  coord_sf(xlim = c(-130, -60),\n           ylim = c(20, 50))\nairports_sf <- st_as_sf(airports, coords = c(\"lon\", \"lat\"))\nst_crs(airports_sf) <- 4326   # set the coordinate reference system\nairports_sf\n## Simple feature collection with 1458 features and 6 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -177 ymin: 19.7 xmax: 174 ymax: 72.3\n## Geodetic CRS:  WGS 84\n## # A tibble: 1,458 × 7\n##    faa   name                    alt    tz dst   tzone     geometry\n##  * <chr> <chr>                 <dbl> <dbl> <chr> <chr>  <POINT [°]>\n##  1 04G   Lansdowne Airport      1044    -5 A     Amer… (-80.6 41.1)\n##  2 06A   Moton Field Municipa…   264    -6 A     Amer… (-85.7 32.5)\n##  3 06C   Schaumburg Regional     801    -6 A     Amer…   (-88.1 42)\n##  4 06N   Randall Airport         523    -5 A     Amer… (-74.4 41.4)\n##  5 09J   Jekyll Island Airport    11    -5 A     Amer… (-81.4 31.1)\n##  6 0A9   Elizabethton Municip…  1593    -5 A     Amer… (-82.2 36.4)\n##  7 0G6   Williams County Airp…   730    -5 A     Amer… (-84.5 41.5)\n##  8 0G7   Finger Lakes Regiona…   492    -5 A     Amer… (-76.8 42.9)\n##  9 0P2   Shoestring Aviation …  1000    -5 U     Amer… (-76.6 39.8)\n## 10 0S9   Jefferson County Intl   108    -8 A     Amer…  (-123 48.1)\n## # … with 1,448 more rows\nggplot() + \n  geom_sf(data = usa_48) + \n  geom_sf(data = airports_sf, shape = 1) +\n  coord_sf(xlim = c(-130, -60),\n           ylim = c(20, 50))"},{"path":"geoviz.html","id":"symbols-1","chapter":"Day 4 Geospatial visualizations","heading":"4.8.3.2 Symbols","text":"can change size type symbols map. instance, can draw bubble plot (also known proportional symbol map) encode altitude airport size channel:Circle area proportional airport’s altitude (feet). scale based number arriving flights flights:airports contains list virtually commercial airports United States. However flights contains data flights departing New York City airports (JFK, LaGuardia, Newark) services airports around country.","code":"\nggplot(data = usa_48) + \n  geom_sf() + \n  geom_point(data = airports, aes(x = lon, y = lat, size = alt),\n             fill = \"grey\", color = \"black\", alpha = .2) +\n  coord_sf(xlim = c(-130, -60),\n           ylim = c(20, 50)) +\n  scale_size_area(guide = FALSE)\nairports_n <- flights %>%\n  count(dest) %>%\n  left_join(airports, by = c(\"dest\" = \"faa\"))\n\nggplot(data = usa_48) + \n  geom_sf() + \n  geom_point(data = airports_n, aes(x = lon, y = lat, size = n),\n             fill = \"grey\", color = \"black\", alpha = .2) +\n  coord_sf(xlim = c(-130, -60),\n           ylim = c(20, 50)) +\n  scale_size_area(guide = FALSE)"},{"path":"geoviz.html","id":"fill-choropleths","chapter":"Day 4 Geospatial visualizations","heading":"4.8.3.3 Fill (choropleths)","text":"Choropleth maps encode information assigning shades colors defined areas map (e.g. countries, states, counties, zip codes). lots ways tweak customize graphs, generally good idea remember color one harder--decode channels.continue use usa_48 simple features data frame draw choropleth number foreign-born individuals state. get files census_bureau folder. Let’s also normalize measure total population get rate foreign-born individuals population:","code":"\n(fb_state <- here(\"data\", \"census_bureau\",\n                  \"ACS_13_5YR_B05012_state\", \"ACS_13_5YR_B05012.csv\") %>%\n   read_csv() %>%\n  mutate(rate = HD01_VD03 / HD01_VD01))\n## # A tibble: 51 × 10\n##    GEO.id      GEO.id2 `GEO.display-la…` HD01_VD01 HD02_VD01 HD01_VD02 HD02_VD02\n##    <chr>       <chr>   <chr>                 <dbl> <lgl>         <dbl>     <dbl>\n##  1 0400000US01 01      Alabama             4799277 NA          4631045      2881\n##  2 0400000US02 02      Alaska               720316 NA           669941      1262\n##  3 0400000US04 04      Arizona             6479703 NA          5609835      7725\n##  4 0400000US05 05      Arkansas            2933369 NA          2799972      2568\n##  5 0400000US06 06      California         37659181 NA         27483342     30666\n##  6 0400000US08 08      Colorado            5119329 NA          4623809      5778\n##  7 0400000US09 09      Connecticut         3583561 NA          3096374      5553\n##  8 0400000US10 10      Delaware             908446 NA           831683      2039\n##  9 0400000US11 11      District of Colu…    619371 NA           534142      2017\n## 10 0400000US12 12      Florida            19091156 NA         15392410     16848\n## # … with 41 more rows, and 3 more variables: HD01_VD03 <dbl>, HD02_VD03 <dbl>,\n## #   rate <dbl>"},{"path":"geoviz.html","id":"join-the-data","chapter":"Day 4 Geospatial visualizations","heading":"4.8.3.3.1 Join the data","text":"Now data, want draw map. fb_state contains one row per state, usa_48. Since one--one match data frames, join data frames together first, use single data frame draw map. differs approach drawing points point feature thing polygon feature. , airports states. spatial data stored data frame one row per state, need merge data frames together column uniquely identifies row data frame.","code":"\n(usa_fb <- usa_48 %>%\n  left_join(fb_state, by = c(\"STATEFP\" = \"GEO.id2\")))\n## Simple feature collection with 48 features and 18 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -125 ymin: 24.5 xmax: -66.9 ymax: 49.4\n## Geodetic CRS:  NAD83\n## First 10 features:\n##    STATEFP  STATENS    AFFGEOID GEOID STUSPS        NAME LSAD    ALAND   AWATER\n## 1       01 01779775 0400000US01    01     AL     Alabama   00 1.31e+11 4.59e+09\n## 2       05 00068085 0400000US05    05     AR    Arkansas   00 1.35e+11 2.96e+09\n## 3       06 01779778 0400000US06    06     CA  California   00 4.03e+11 2.05e+10\n## 4       09 01779780 0400000US09    09     CT Connecticut   00 1.25e+10 1.82e+09\n## 5       12 00294478 0400000US12    12     FL     Florida   00 1.39e+11 3.14e+10\n## 6       13 01705317 0400000US13    13     GA     Georgia   00 1.49e+11 4.95e+09\n## 7       16 01779783 0400000US16    16     ID       Idaho   00 2.14e+11 2.40e+09\n## 8       17 01779784 0400000US17    17     IL    Illinois   00 1.44e+11 6.20e+09\n## 9       18 00448508 0400000US18    18     IN     Indiana   00 9.28e+10 1.54e+09\n## 10      20 00481813 0400000US20    20     KS      Kansas   00 2.12e+11 1.35e+09\n##         GEO.id GEO.display-label HD01_VD01 HD02_VD01 HD01_VD02 HD02_VD02\n## 1  0400000US01           Alabama   4799277        NA   4631045      2881\n## 2  0400000US05          Arkansas   2933369        NA   2799972      2568\n## 3  0400000US06        California  37659181        NA  27483342     30666\n## 4  0400000US09       Connecticut   3583561        NA   3096374      5553\n## 5  0400000US12           Florida  19091156        NA  15392410     16848\n## 6  0400000US13           Georgia   9810417        NA   8859747      7988\n## 7  0400000US16             Idaho   1583364        NA   1489560      2528\n## 8  0400000US17          Illinois  12848554        NA  11073828     10091\n## 9  0400000US18           Indiana   6514861        NA   6206801      4499\n## 10 0400000US20            Kansas   2868107        NA   2677007      3095\n##    HD01_VD03 HD02_VD03   rate                       geometry\n## 1     168232      2881 0.0351 MULTIPOLYGON (((-88.3 30.2,...\n## 2     133397      2568 0.0455 MULTIPOLYGON (((-94.6 36.5,...\n## 3   10175839     30666 0.2702 MULTIPOLYGON (((-119 33.5, ...\n## 4     487187      5553 0.1360 MULTIPOLYGON (((-73.7 41.1,...\n## 5    3698746     16848 0.1937 MULTIPOLYGON (((-80.7 24.9,...\n## 6     950670      7988 0.0969 MULTIPOLYGON (((-85.6 35, -...\n## 7      93804      2528 0.0592 MULTIPOLYGON (((-117 44.4, ...\n## 8    1774726     10093 0.1381 MULTIPOLYGON (((-91.5 40.2,...\n## 9     308060      4500 0.0473 MULTIPOLYGON (((-88.1 37.9,...\n## 10    191100      3100 0.0666 MULTIPOLYGON (((-102 40, -1..."},{"path":"geoviz.html","id":"draw-the-map","chapter":"Day 4 Geospatial visualizations","heading":"4.8.3.3.2 Draw the map","text":"newly combined data frame, use geom_sf() define fill aesthetic based column usa_fb want visualize.","code":"\nggplot(data = usa_fb) +\n  geom_sf(aes(fill = rate))"},{"path":"geoviz.html","id":"bin-data-to-discrete-intervals","chapter":"Day 4 Geospatial visualizations","heading":"4.8.3.4 Bin data to discrete intervals","text":"creating heatmap continuous variable, one must decide whether keep variable continuous collapse series bins discrete colors. keep variable continuous technically precise, human eye usually distinguish two colors similar one another. converting variable discrete variable, easily distinguish different levels. decide convert continuous variable discrete variable, need decide . cut() base R function converting continuous variables discrete values, ggplot2 offers two functions explicitly define want bin numeric vector (column).cut_interval() makes n groups equal range:Whereas cut_number() makes n groups (approximately) equal numbers observations:See StackOverflow thread -depth discussion merits bucketizing continuous variable whether use cut_interval() cut_number().","code":"\nusa_fb %>%\n  mutate(rate_cut = cut_interval(rate, n = 6)) %>%\n  ggplot() +\n  geom_sf(aes(fill = rate_cut))\nusa_fb %>%\n  mutate(rate_cut = cut_number(rate, n = 6)) %>%\n  ggplot() +\n  geom_sf(aes(fill = rate_cut))"},{"path":"geoviz.html","id":"changing-map-projection","chapter":"Day 4 Geospatial visualizations","heading":"4.8.4 Changing map projection","text":"\nFigure 4.2: Mercator Projection\nRepresenting portions globe flat surface can challenging. Depending project map, can distort emphasize certain features map. Fortunately, ggplot() includes coord_sf() function allows us easily implement different projection methods. order implement coordinate transformations, need know coordinate reference system defines projection method. “easiest” approach provide known proj4string defines projection method. PROJ4 generic coordinate transformation software allows convert projection methods. get really geospatial analysis visualization, helpful learn system.purposes , proj4string character string R defines coordinate system includes parameters specific given coordinate transformation. PROJ4 includes documentation common projection methods can get started. projection methods relatively simple require just name projection, like Mercator projection (\"+proj=merc\"):coordinate systems require specification standard lines, lines define areas surface map tangent globe. include Gall-Peters, Albers equal-area, Lambert azimuthal.","code":"\nmap_proj_base <- ggplot(data = usa_48) +\n  geom_sf()\nmap_proj_base +\n  coord_sf(crs = \"+proj=merc\") +\n  ggtitle(\"Mercator projection\")\nmap_proj_base +\n  coord_sf(crs = \"+proj=cea +lon_0=0 +lat_ts=45\") +\n  ggtitle(\"Gall-Peters projection\")\n\nmap_proj_base +\n  coord_sf(crs = \"+proj=aea +lat_1=25 +lat_2=50 +lon_0=-100\") +\n  ggtitle(\"Albers equal-area projection\")\n\nmap_proj_base +\n  coord_sf(crs = \"+proj=laea +lat_0=35 +lon_0=-100\") +\n  ggtitle(\"Lambert azimuthal projection\")"},{"path":"geoviz.html","id":"practice-drawing-vector-maps","chapter":"Day 4 Geospatial visualizations","heading":"4.9 Practice drawing vector maps","text":"","code":""},{"path":"geoviz.html","id":"american-community-survey","chapter":"Day 4 Geospatial visualizations","heading":"4.9.1 American Community Survey","text":"U.S. Census Bureau conducts American Community Survey gathers detailed information topics demographics, employment, educational attainment, etc. make vast portion data available application programming interface (API), can accessed intuitively R via tidycensus package. previously discussed use package obtain statistical data decennial census. However Census Bureau also detailed information political geographic boundaries can combine statistical measures easily construct geospatial visualizations.already, obtain API key store securely computer.","code":""},{"path":"geoviz.html","id":"exercise-visualize-income-data","chapter":"Day 4 Geospatial visualizations","heading":"4.9.2 Exercise: Visualize income data","text":"Obtain information median household income 2017 Cook County, IL tract-level using ACS. retrieve geographic features tract, set geometry = TRUE function.\n\ncan use load_variables(year = 2017, dataset = \"acs5\") retrieve list variables available search find correct variable name.\n\nClick solution\n\n\ncook_inc <- get_acs(state = \"IL\",\n                    county = \"Cook\",\n                    geography = \"tract\", \n                    variables = c(medincome = \"B19013_001\"), \n                    year = 2017,\n                    geometry = TRUE)\n\ncook_inc\n## Simple feature collection 1319 features 5 fields (1 geometry empty)\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -88.3 ymin: 41.5 xmax: -87.5 ymax: 42.2\n## Geodetic CRS:  NAD83\n## First 10 features:\n##          GEOID                                       NAME  variable estimate\n## 1  17031010201 Census Tract 102.01, Cook County, Illinois medincome    40841\n## 2  17031030200    Census Tract 302, Cook County, Illinois medincome    64089\n## 3  17031031700    Census Tract 317, Cook County, Illinois medincome    44555\n## 4  17031031900    Census Tract 319, Cook County, Illinois medincome    61211\n## 5  17031050200    Census Tract 502, Cook County, Illinois medincome    74375\n## 6  17031051300    Census Tract 513, Cook County, Illinois medincome   149271\n## 7  17031061500    Census Tract 615, Cook County, Illinois medincome   117656\n## 8  17031062600    Census Tract 626, Cook County, Illinois medincome   144211\n## 9  17031063400    Census Tract 634, Cook County, Illinois medincome    95488\n## 10 17031070600    Census Tract 706, Cook County, Illinois medincome   151250\n##      moe                       geometry\n## 1   7069 MULTIPOLYGON (((-87.7 42, -...\n## 2  12931 MULTIPOLYGON (((-87.7 42, -...\n## 3  12220 MULTIPOLYGON (((-87.7 42, -...\n## 4   6343 MULTIPOLYGON (((-87.7 42, -...\n## 5  18773 MULTIPOLYGON (((-87.7 42, -...\n## 6  26389 MULTIPOLYGON (((-87.7 41.9,...\n## 7  11416 MULTIPOLYGON (((-87.7 41.9,...\n## 8  22537 MULTIPOLYGON (((-87.7 41.9,...\n## 9   4904 MULTIPOLYGON (((-87.6 41.9,...\n## 10 47800 MULTIPOLYGON (((-87.7 41.9,...\n\nObtain information median household income 2017 Cook County, IL tract-level using ACS. retrieve geographic features tract, set geometry = TRUE function.can use load_variables(year = 2017, dataset = \"acs5\") retrieve list variables available search find correct variable name.Click solution\nDraw choropleth using median household income data. Use continuous color gradient identify tract’s median household income.\nClick solution\n\n\nggplot(data = cook_inc) +\n  # use fill color avoid gray boundary lines\n  geom_sf(aes(fill = estimate, color = estimate)) +\n  # increase interpretability graph\n  scale_color_continuous(labels = scales::dollar) +\n  scale_fill_continuous(labels = scales::dollar) +\n  labs(title = \"Median household income Cook County, IL\",\n       subtitle = \"2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\n\n\nDraw choropleth using median household income data. Use continuous color gradient identify tract’s median household income.Click solution\n","code":"\ncook_inc <- get_acs(state = \"IL\",\n                    county = \"Cook\",\n                    geography = \"tract\", \n                    variables = c(medincome = \"B19013_001\"), \n                    year = 2017,\n                    geometry = TRUE)\ncook_inc\n## Simple feature collection with 1319 features and 5 fields (with 1 geometry empty)\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -88.3 ymin: 41.5 xmax: -87.5 ymax: 42.2\n## Geodetic CRS:  NAD83\n## First 10 features:\n##          GEOID                                       NAME  variable estimate\n## 1  17031010201 Census Tract 102.01, Cook County, Illinois medincome    40841\n## 2  17031030200    Census Tract 302, Cook County, Illinois medincome    64089\n## 3  17031031700    Census Tract 317, Cook County, Illinois medincome    44555\n## 4  17031031900    Census Tract 319, Cook County, Illinois medincome    61211\n## 5  17031050200    Census Tract 502, Cook County, Illinois medincome    74375\n## 6  17031051300    Census Tract 513, Cook County, Illinois medincome   149271\n## 7  17031061500    Census Tract 615, Cook County, Illinois medincome   117656\n## 8  17031062600    Census Tract 626, Cook County, Illinois medincome   144211\n## 9  17031063400    Census Tract 634, Cook County, Illinois medincome    95488\n## 10 17031070600    Census Tract 706, Cook County, Illinois medincome   151250\n##      moe                       geometry\n## 1   7069 MULTIPOLYGON (((-87.7 42, -...\n## 2  12931 MULTIPOLYGON (((-87.7 42, -...\n## 3  12220 MULTIPOLYGON (((-87.7 42, -...\n## 4   6343 MULTIPOLYGON (((-87.7 42, -...\n## 5  18773 MULTIPOLYGON (((-87.7 42, -...\n## 6  26389 MULTIPOLYGON (((-87.7 41.9,...\n## 7  11416 MULTIPOLYGON (((-87.7 41.9,...\n## 8  22537 MULTIPOLYGON (((-87.7 41.9,...\n## 9   4904 MULTIPOLYGON (((-87.6 41.9,...\n## 10 47800 MULTIPOLYGON (((-87.7 41.9,...\nggplot(data = cook_inc) +\n  # use fill and color to avoid gray boundary lines\n  geom_sf(aes(fill = estimate, color = estimate)) +\n  # increase interpretability of graph\n  scale_color_continuous(labels = scales::dollar) +\n  scale_fill_continuous(labels = scales::dollar) +\n  labs(title = \"Median household income in Cook County, IL\",\n       subtitle = \"In 2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")"},{"path":"geoviz.html","id":"exercise-customize-your-maps","chapter":"Day 4 Geospatial visualizations","heading":"4.9.3 Exercise: Customize your maps","text":"Draw choropleth Cook County, convert median household income discrete variable 6 levels.\nClick solution\n\nUsing cut_interval():\n\ncook_inc %>%\n  mutate(inc_cut = cut_interval(estimate, n = 6)) %>%\n  ggplot() +\n  # use fill color avoid gray boundary lines\n  geom_sf(aes(fill = inc_cut, color = inc_cut)) +\n  # increase interpretability graph\n  labs(title = \"Median household income Cook County, IL\",\n       subtitle = \"2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\n\nUsing cut_number():\n\ncook_inc %>%\n  mutate(inc_cut = cut_number(estimate, n = 6)) %>%\n  ggplot() +\n  # use fill color avoid gray boundary lines\n  geom_sf(aes(fill = inc_cut, color = inc_cut)) +\n  # increase interpretability graph\n  labs(title = \"Median household income Cook County, IL\",\n       subtitle = \"2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\n\n\nDraw choropleth Cook County, convert median household income discrete variable 6 levels.Click solution\nUsing cut_interval():\n\ncook_inc %>%\n  mutate(inc_cut = cut_interval(estimate, n = 6)) %>%\n  ggplot() +\n  # use fill color avoid gray boundary lines\n  geom_sf(aes(fill = inc_cut, color = inc_cut)) +\n  # increase interpretability graph\n  labs(title = \"Median household income Cook County, IL\",\n       subtitle = \"2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\nUsing cut_interval():Using cut_number():\n\ncook_inc %>%\n  mutate(inc_cut = cut_number(estimate, n = 6)) %>%\n  ggplot() +\n  # use fill color avoid gray boundary lines\n  geom_sf(aes(fill = inc_cut, color = inc_cut)) +\n  # increase interpretability graph\n  labs(title = \"Median household income Cook County, IL\",\n       subtitle = \"2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\n\n\nUsing cut_number():Draw choropleth Cook County using discrete variable, select appropriate color palette using Color Brewer.\nClick solution\n\nUsing cut_interval() Blue-Green palette:\n\ncook_inc %>%\n  mutate(inc_cut = cut_interval(estimate, n = 6)) %>%\n  ggplot() +\n  # use fill color avoid gray boundary lines\n  geom_sf(aes(fill = inc_cut, color = inc_cut)) +\n  scale_fill_brewer(type = \"seq\", palette = \"BuGn\") +\n  scale_color_brewer(type = \"seq\", palette = \"BuGn\") +\n  # increase interpretability graph\n  labs(title = \"Median household income Cook County, IL\",\n       subtitle = \"2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\n\nUsing cut_number() Blue-Green palette:\n\ncook_inc %>%\n  mutate(inc_cut = cut_number(estimate, n = 6)) %>%\n  ggplot() +\n  # use fill color avoid gray boundary lines\n  geom_sf(aes(fill = inc_cut, color = inc_cut)) +\n  scale_fill_brewer(type = \"seq\", palette = \"BuGn\") +\n  scale_color_brewer(type = \"seq\", palette = \"BuGn\") +\n # increase interpretability graph\n  labs(title = \"Median household income Cook County, IL\",\n       subtitle = \"2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\n\ncan choose palette sequential data.\n\nDraw choropleth Cook County using discrete variable, select appropriate color palette using Color Brewer.Click solution\nUsing cut_interval() Blue-Green palette:\n\ncook_inc %>%\n  mutate(inc_cut = cut_interval(estimate, n = 6)) %>%\n  ggplot() +\n  # use fill color avoid gray boundary lines\n  geom_sf(aes(fill = inc_cut, color = inc_cut)) +\n  scale_fill_brewer(type = \"seq\", palette = \"BuGn\") +\n  scale_color_brewer(type = \"seq\", palette = \"BuGn\") +\n  # increase interpretability graph\n  labs(title = \"Median household income Cook County, IL\",\n       subtitle = \"2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\nUsing cut_interval() Blue-Green palette:Using cut_number() Blue-Green palette:\n\ncook_inc %>%\n  mutate(inc_cut = cut_number(estimate, n = 6)) %>%\n  ggplot() +\n  # use fill color avoid gray boundary lines\n  geom_sf(aes(fill = inc_cut, color = inc_cut)) +\n  scale_fill_brewer(type = \"seq\", palette = \"BuGn\") +\n  scale_color_brewer(type = \"seq\", palette = \"BuGn\") +\n # increase interpretability graph\n  labs(title = \"Median household income Cook County, IL\",\n       subtitle = \"2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\nUsing cut_number() Blue-Green palette:can choose palette sequential data.Use viridis color palette Cook County map drawn using continuous measure.\nClick solution\n\n\nggplot(data = cook_inc) +\n  # use fill color avoid gray boundary lines\n  geom_sf(aes(fill = estimate, color = estimate)) +\n  # increase interpretability graph\n  scale_color_viridis(labels = scales::dollar) +\n  scale_fill_viridis(labels = scales::dollar) +\n  labs(title = \"Median household income Cook County, IL\",\n       subtitle = \"2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\n\n\nUse viridis color palette Cook County map drawn using continuous measure.Click solution\n","code":"\ncook_inc %>%\n  mutate(inc_cut = cut_interval(estimate, n = 6)) %>%\n  ggplot() +\n  # use fill and color to avoid gray boundary lines\n  geom_sf(aes(fill = inc_cut, color = inc_cut)) +\n  # increase interpretability of graph\n  labs(title = \"Median household income in Cook County, IL\",\n       subtitle = \"In 2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\ncook_inc %>%\n  mutate(inc_cut = cut_number(estimate, n = 6)) %>%\n  ggplot() +\n  # use fill and color to avoid gray boundary lines\n  geom_sf(aes(fill = inc_cut, color = inc_cut)) +\n  # increase interpretability of graph\n  labs(title = \"Median household income in Cook County, IL\",\n       subtitle = \"In 2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\ncook_inc %>%\n  mutate(inc_cut = cut_interval(estimate, n = 6)) %>%\n  ggplot() +\n  # use fill and color to avoid gray boundary lines\n  geom_sf(aes(fill = inc_cut, color = inc_cut)) +\n  scale_fill_brewer(type = \"seq\", palette = \"BuGn\") +\n  scale_color_brewer(type = \"seq\", palette = \"BuGn\") +\n  # increase interpretability of graph\n  labs(title = \"Median household income in Cook County, IL\",\n       subtitle = \"In 2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\ncook_inc %>%\n  mutate(inc_cut = cut_number(estimate, n = 6)) %>%\n  ggplot() +\n  # use fill and color to avoid gray boundary lines\n  geom_sf(aes(fill = inc_cut, color = inc_cut)) +\n  scale_fill_brewer(type = \"seq\", palette = \"BuGn\") +\n  scale_color_brewer(type = \"seq\", palette = \"BuGn\") +\n # increase interpretability of graph\n  labs(title = \"Median household income in Cook County, IL\",\n       subtitle = \"In 2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")\nggplot(data = cook_inc) +\n  # use fill and color to avoid gray boundary lines\n  geom_sf(aes(fill = estimate, color = estimate)) +\n  # increase interpretability of graph\n  scale_color_viridis(labels = scales::dollar) +\n  scale_fill_viridis(labels = scales::dollar) +\n  labs(title = \"Median household income in Cook County, IL\",\n       subtitle = \"In 2017\",\n       color = NULL,\n       fill = NULL,\n       caption = \"Source: American Community Survey\")"},{"path":"geoviz.html","id":"selecting-optimal-color-palettes","chapter":"Day 4 Geospatial visualizations","heading":"4.10 Selecting optimal color palettes","text":"Selection color palette perhaps important decision make drawing choropleth. default, ggplot2 picks evenly spaced hues around Hue-Chroma-Luminance (HCL) color space:20ggplot2 gives many different ways defining customizing scale_color_ scale_fill_ palettes, tell optimal specific usage graph.","code":""},{"path":"geoviz.html","id":"color-brewer","chapter":"Day 4 Geospatial visualizations","heading":"4.10.1 Color Brewer","text":"Color Brewer diagnostic tool selecting optimal color palettes maps discrete variables. authors generated different color palettes designed make differentiating categories easy depending scaling variable. need define number categories variable, nature data (sequential, diverging, qualitative), color scheme. also options select palettes colorblind safe, print friendly, photocopy safe. Depending combination options, may find color palette matches criteria. case, consider reducing number data classes.","code":""},{"path":"geoviz.html","id":"sequential","chapter":"Day 4 Geospatial visualizations","heading":"4.10.1.1 Sequential","text":"Sequential palettes work best ordered data progresses low high value.","code":"\ndisplay.brewer.all(type = \"seq\")"},{"path":"geoviz.html","id":"diverging","chapter":"Day 4 Geospatial visualizations","heading":"4.10.1.2 Diverging","text":"Diverging palettes work variables meaningful mid-range values, well extreme low high values.","code":"\ndisplay.brewer.all(type = \"div\")"},{"path":"geoviz.html","id":"qualitative","chapter":"Day 4 Geospatial visualizations","heading":"4.10.1.3 Qualitative","text":"Qualitative palettes best used nominal data inherent ordering categories.","code":"\ndisplay.brewer.all(type = \"qual\")"},{"path":"geoviz.html","id":"viridis","chapter":"Day 4 Geospatial visualizations","heading":"4.10.2 Viridis","text":"viridis package imports several color palettes continuous variables matplotlib package Python. palettes tested colorful, perceptually uniform, robust colorblindness, pretty. use ggplot2, use scale_color_viridis() scale_fill_viridis():","code":"\nlibrary(viridis)\n\nviridis_base <- ggplot(state_inc) +\n  geom_sf(aes(fill = estimate)) +\n  labs(title = \"Median household income, 2016\",\n       subtitle = \"Palette: viridis\",\n       caption = \"Source: 2016 American Community Survey\",\n       fill = NULL) +\n  scale_fill_viridis(labels = scales::dollar)\n\nviridis_base\nviridis_base +\n  scale_fill_viridis(option = \"cividis\", labels = scales::dollar) +\n  labs(subtitle = \"Palette: cividis\")\nviridis_base +\n  scale_fill_viridis(option = \"inferno\", labels = scales::dollar) +\n  labs(subtitle = \"Palette: inferno\")\nviridis_base +\n  scale_fill_viridis(option = \"magma\", labels = scales::dollar) +\n  labs(subtitle = \"Palette: magma\")\nviridis_base +\n  scale_fill_viridis(option = \"plasma\", labels = scales::dollar) +\n  labs(subtitle = \"Palette: plasma\")"},{"path":"geoviz.html","id":"session-info-3","chapter":"Day 4 Geospatial visualizations","heading":"Session info","text":"","code":"\ndevtools::session_info()\n## ─ Session info ───────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.1.2 (2021-11-01)\n##  os       macOS Monterey 12.2.1\n##  system   aarch64, darwin20\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       America/Chicago\n##  date     2022-03-04\n##  pandoc   2.17.1.1 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/ (via rmarkdown)\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────\n##  package       * version    date (UTC) lib source\n##  albersusa     * 0.4.1      2022-01-06 [1] Github (hrbrmstr/albersusa@07aa87f)\n##  assertthat      0.2.1      2019-03-21 [1] CRAN (R 4.1.0)\n##  backports       1.4.1      2021-12-13 [1] CRAN (R 4.1.1)\n##  bit             4.0.4      2020-08-04 [1] CRAN (R 4.1.1)\n##  bit64           4.0.5      2020-08-30 [1] CRAN (R 4.1.0)\n##  bitops          1.0-7      2021-04-24 [1] CRAN (R 4.1.0)\n##  bookdown        0.24       2021-09-02 [1] CRAN (R 4.1.1)\n##  brio            1.1.3      2021-11-30 [1] CRAN (R 4.1.1)\n##  broom           0.7.12     2022-01-28 [1] CRAN (R 4.1.1)\n##  bslib           0.3.1      2021-10-06 [1] CRAN (R 4.1.1)\n##  cachem          1.0.6      2021-08-19 [1] CRAN (R 4.1.1)\n##  callr           3.7.0      2021-04-20 [1] CRAN (R 4.1.0)\n##  cellranger      1.1.0      2016-07-27 [1] CRAN (R 4.1.0)\n##  class           7.3-20     2022-01-13 [1] CRAN (R 4.1.1)\n##  classInt        0.4-3      2020-04-07 [1] CRAN (R 4.1.0)\n##  cli             3.2.0      2022-02-14 [1] CRAN (R 4.1.1)\n##  codetools       0.2-18     2020-11-04 [1] CRAN (R 4.1.2)\n##  colorspace      2.0-3      2022-02-21 [1] CRAN (R 4.1.1)\n##  crayon          1.5.0      2022-02-14 [1] CRAN (R 4.1.1)\n##  curl            4.3.2      2021-06-23 [1] CRAN (R 4.1.0)\n##  DBI             1.1.2      2021-12-20 [1] CRAN (R 4.1.1)\n##  dbplyr          2.1.1      2021-04-06 [1] CRAN (R 4.1.0)\n##  desc            1.4.0      2021-09-28 [1] CRAN (R 4.1.1)\n##  devtools        2.4.3      2021-11-30 [1] CRAN (R 4.1.1)\n##  digest          0.6.29     2021-12-01 [1] CRAN (R 4.1.1)\n##  dplyr         * 1.0.8      2022-02-08 [1] CRAN (R 4.1.1)\n##  e1071           1.7-9      2021-09-16 [1] CRAN (R 4.1.1)\n##  ellipsis        0.3.2      2021-04-29 [1] CRAN (R 4.1.0)\n##  evaluate        0.15       2022-02-18 [1] CRAN (R 4.1.1)\n##  fansi           1.0.2      2022-01-14 [1] CRAN (R 4.1.1)\n##  farver          2.1.0      2021-02-28 [1] CRAN (R 4.1.0)\n##  fastmap         1.1.0      2021-01-25 [1] CRAN (R 4.1.0)\n##  forcats       * 0.5.1      2021-01-27 [1] CRAN (R 4.1.1)\n##  foreign         0.8-82     2022-01-13 [1] CRAN (R 4.1.1)\n##  fs              1.5.2      2021-12-08 [1] CRAN (R 4.1.1)\n##  generics        0.1.2      2022-01-31 [1] CRAN (R 4.1.1)\n##  ggmap         * 3.0.0      2019-02-05 [1] CRAN (R 4.1.1)\n##  ggplot2       * 3.3.5      2021-06-25 [1] CRAN (R 4.1.1)\n##  glue            1.6.1      2022-01-22 [1] CRAN (R 4.1.1)\n##  gridExtra       2.3        2017-09-09 [1] CRAN (R 4.1.1)\n##  gtable          0.3.0      2019-03-25 [1] CRAN (R 4.1.1)\n##  haven           2.4.3      2021-08-04 [1] CRAN (R 4.1.1)\n##  here          * 1.0.1      2020-12-13 [1] CRAN (R 4.1.0)\n##  highr           0.9        2021-04-16 [1] CRAN (R 4.1.0)\n##  hms             1.1.1      2021-09-26 [1] CRAN (R 4.1.1)\n##  htmltools       0.5.2      2021-08-25 [1] CRAN (R 4.1.1)\n##  httr            1.4.2      2020-07-20 [1] CRAN (R 4.1.0)\n##  isoband         0.2.5      2021-07-13 [1] CRAN (R 4.1.0)\n##  jpeg            0.1-9      2021-07-24 [1] CRAN (R 4.1.0)\n##  jquerylib       0.1.4      2021-04-26 [1] CRAN (R 4.1.0)\n##  jsonlite        1.8.0      2022-02-22 [1] CRAN (R 4.1.1)\n##  KernSmooth      2.23-20    2021-05-03 [1] CRAN (R 4.1.2)\n##  kimisc          0.4        2017-12-18 [1] CRAN (R 4.1.0)\n##  knitr           1.37       2021-12-16 [1] CRAN (R 4.1.1)\n##  labeling        0.4.2      2020-10-20 [1] CRAN (R 4.1.0)\n##  lattice         0.20-45    2021-09-22 [1] CRAN (R 4.1.2)\n##  lifecycle       1.0.1      2021-09-24 [1] CRAN (R 4.1.1)\n##  lubridate       1.8.0      2021-10-07 [1] CRAN (R 4.1.1)\n##  magrittr        2.0.2      2022-01-26 [1] CRAN (R 4.1.1)\n##  maptools        1.1-2      2021-09-07 [1] CRAN (R 4.1.1)\n##  MASS            7.3-55     2022-01-13 [1] CRAN (R 4.1.1)\n##  memoise         2.0.1      2021-11-26 [1] CRAN (R 4.1.1)\n##  modelr          0.1.8      2020-05-19 [1] CRAN (R 4.1.0)\n##  munsell         0.5.0      2018-06-12 [1] CRAN (R 4.1.0)\n##  nycflights13  * 1.0.2      2021-04-12 [1] CRAN (R 4.1.0)\n##  patchwork     * 1.1.1      2020-12-17 [1] CRAN (R 4.1.1)\n##  pillar          1.7.0      2022-02-01 [1] CRAN (R 4.1.1)\n##  pkgbuild        1.3.1      2021-12-20 [1] CRAN (R 4.1.1)\n##  pkgconfig       2.0.3      2019-09-22 [1] CRAN (R 4.1.0)\n##  pkgload         1.2.4      2021-11-30 [1] CRAN (R 4.1.1)\n##  plyr            1.8.6      2020-03-03 [1] CRAN (R 4.1.0)\n##  png             0.1-7      2013-12-03 [1] CRAN (R 4.1.0)\n##  prettyunits     1.1.1      2020-01-24 [1] CRAN (R 4.1.0)\n##  processx        3.5.2      2021-04-30 [1] CRAN (R 4.1.0)\n##  proxy           0.4-26     2021-06-07 [1] CRAN (R 4.1.0)\n##  ps              1.6.0      2021-02-28 [1] CRAN (R 4.1.0)\n##  purrr         * 0.3.4      2020-04-17 [1] CRAN (R 4.1.0)\n##  R6              2.5.1      2021-08-19 [1] CRAN (R 4.1.1)\n##  rappdirs        0.3.3      2021-01-31 [1] CRAN (R 4.1.0)\n##  RColorBrewer  * 1.1-2      2014-12-07 [1] CRAN (R 4.1.0)\n##  Rcpp            1.0.8      2022-01-13 [1] CRAN (R 4.1.1)\n##  readr         * 2.1.2      2022-01-30 [1] CRAN (R 4.1.1)\n##  readxl          1.3.1      2019-03-13 [1] CRAN (R 4.1.0)\n##  remotes         2.4.2      2021-11-30 [1] CRAN (R 4.1.1)\n##  reprex          2.0.1      2021-08-05 [1] CRAN (R 4.1.1)\n##  rgdal           1.5-28     2021-12-15 [1] CRAN (R 4.1.1)\n##  rgeos           0.5-9      2021-12-15 [1] CRAN (R 4.1.1)\n##  RgoogleMaps     1.4.5.3    2020-02-12 [1] CRAN (R 4.1.0)\n##  rjson           0.2.21     2022-01-09 [1] CRAN (R 4.1.1)\n##  rlang           1.0.1      2022-02-03 [1] CRAN (R 4.1.1)\n##  rmarkdown       2.11       2021-09-14 [1] CRAN (R 4.1.1)\n##  rnaturalearth * 0.1.0      2017-03-21 [1] CRAN (R 4.1.0)\n##  rprojroot       2.0.2      2020-11-15 [1] CRAN (R 4.1.0)\n##  rstudioapi      0.13       2020-11-12 [1] CRAN (R 4.1.0)\n##  rvest           1.0.2      2021-10-16 [1] CRAN (R 4.1.1)\n##  s2              1.0.7      2021-09-28 [1] CRAN (R 4.1.1)\n##  sass            0.4.0      2021-05-12 [1] CRAN (R 4.1.0)\n##  scales          1.1.1      2020-05-11 [1] CRAN (R 4.1.0)\n##  sessioninfo     1.2.2      2021-12-06 [1] CRAN (R 4.1.1)\n##  sf            * 1.0-6      2022-02-04 [1] CRAN (R 4.1.1)\n##  sp              1.4-6      2021-11-14 [1] CRAN (R 4.1.1)\n##  stringi         1.7.6      2021-11-29 [1] CRAN (R 4.1.1)\n##  stringr       * 1.4.0      2019-02-10 [1] CRAN (R 4.1.1)\n##  testthat        3.1.2      2022-01-20 [1] CRAN (R 4.1.1)\n##  tibble        * 3.1.6      2021-11-07 [1] CRAN (R 4.1.1)\n##  tidycensus    * 1.1.0.9000 2022-01-25 [1] Github (walkerke/tidycensus@8b8e38a)\n##  tidyr         * 1.2.0      2022-02-01 [1] CRAN (R 4.1.1)\n##  tidyselect      1.1.2      2022-02-21 [1] CRAN (R 4.1.1)\n##  tidyverse     * 1.3.1      2021-04-15 [1] CRAN (R 4.1.0)\n##  tigris          1.6        2022-02-22 [1] CRAN (R 4.1.1)\n##  tzdb            0.2.0      2021-10-27 [1] CRAN (R 4.1.1)\n##  units           0.8-0      2022-02-05 [1] CRAN (R 4.1.1)\n##  usethis         2.1.5      2021-12-09 [1] CRAN (R 4.1.1)\n##  utf8            1.2.2      2021-07-24 [1] CRAN (R 4.1.0)\n##  uuid            1.0-3      2021-11-01 [1] CRAN (R 4.1.1)\n##  vctrs           0.3.8      2021-04-29 [1] CRAN (R 4.1.0)\n##  viridis       * 0.6.2      2021-10-13 [1] CRAN (R 4.1.1)\n##  viridisLite   * 0.4.0      2021-04-13 [1] CRAN (R 4.1.0)\n##  vroom           1.5.7      2021-11-30 [1] CRAN (R 4.1.1)\n##  withr           2.4.3      2021-11-30 [1] CRAN (R 4.1.1)\n##  wk              0.6.0      2022-01-03 [1] CRAN (R 4.1.2)\n##  xfun            0.29       2021-12-14 [1] CRAN (R 4.1.1)\n##  xml2            1.3.3      2021-11-30 [1] CRAN (R 4.1.1)\n##  yaml            2.3.5      2022-02-21 [1] CRAN (R 4.1.1)\n## \n##  [1] /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library\n## \n## ──────────────────────────────────────────────────────────────────────────────"},{"path":"shiny.html","id":"shiny","chapter":"Day 5 Shiny applications","heading":"Day 5 Shiny applications","text":"","code":""},{"path":"shiny.html","id":"learning-objectives-4","chapter":"Day 5 Shiny applications","heading":"Learning objectives","text":"","code":""},{"path":"shiny.html","id":"morning-4","chapter":"Day 5 Shiny applications","heading":"5.0.1 Morning","text":"Introduce Shiny appsDemonstrate element Shiny appDistinguish UI server componentsBuild UI component Shiny app","code":""},{"path":"shiny.html","id":"afternoon-4","chapter":"Day 5 Shiny applications","heading":"5.0.2 Afternoon","text":"Define reactivityBuild server component Shiny app","code":""},{"path":"shiny.html","id":"assigned-readings-4","chapter":"Day 5 Shiny applications","heading":"Assigned readings","text":"None.","code":""},{"path":"shiny.html","id":"what-is-shiny","chapter":"Day 5 Shiny applications","heading":"5.1 What is Shiny?","text":"Shiny package RStudio can used build interactive web pages R. may sound scary words “web pages”, ’s geared R users experience web development, need know HTML/CSS/JavaScript.can quite lot Shiny: think easy way make interactive web page, web page can seamlessly interact R display R objects (plots, tables, anything else R). get sense wide range things can Shiny, can visit Shiny gallery, hosts examples basic (complex) Shiny apps.lesson, ’ll walk steps building Shiny app using subset city Chicago’s current employee data set. city annually releases updated file employees city government, including information department, job title, salary/wage. build app report information specifically wage employees. final version app can seen . activity deemed exercise throughout tutorial mandatory building app, good getting practice Shiny.want even practice, another great tutorial official Shiny tutorial. RStudio also provides handy cheatsheet remember little details already learned basics.","code":""},{"path":"shiny.html","id":"before-we-begin","chapter":"Day 5 Shiny applications","heading":"5.2 Before we begin","text":"Download necessary files Shiny app lesson using usethis::use_course(\"uc-cfss/shiny-demo\").’ll need shiny package, install .ensure successfully installed Shiny, try running one demo apps.example app running, press Escape close app, ready build first Shiny app!","code":"\ninstall.packages(\"shiny\")\nlibrary(shiny)\nrunExample(\"01_hello\")"},{"path":"shiny.html","id":"shiny-app-basics","chapter":"Day 5 Shiny applications","heading":"5.3 Shiny app basics","text":"Every Shiny app composed two parts: web page shows app user, computer powers app. computer runs app can either laptop (’re running app RStudio) server somewhere else. , Shiny app developer, need write two parts (’re going write computer, rather code powers app). Shiny terminology, called UI (user interface) server.UI just web document user gets see, ’s HTML write using Shiny’s functions. UI responsible creating layout app telling Shiny exactly things go. server responsible logic app; ’s set instructions tell web page show user interacts page.look app building, page see built UI code. ’ll notice controls , user, can manipulate. adjust price choose type alcohol, ’ll notice plot table get updated. UI responsible creating controls telling Shiny place controls place plot table, server responsible creating actual plot data table.","code":""},{"path":"shiny.html","id":"create-an-empty-shiny-app","chapter":"Day 5 Shiny applications","heading":"5.4 Create an empty Shiny app","text":"Shiny apps follow template:template working minimal Shiny app doesn’t much. initializes empty UI empty server, runs app using empty parts. Copy template new file named app.R new folder. important name file app.R, otherwise recognized Shiny app. also important place app folder, folder already R scripts files, unless files used app.saving file, RStudio recognize Shiny app, see usual Run button top change Run App.\nFigure 5.1: Shiny Run App\ndon’t see Run App button, means either old version RStudio, don’t Shiny installed, didn’t follow file naming conventions.Click Run App button, now app run. won’t see much ’s empty app, see console text printed form Listening http://127.0.0.1:5274 little stop sign appeared top console. ’ll also notice can’t run commands console. R busy–R session currently powering Shiny app listening user interaction (won’t happen app nothing yet).Click stop button stop app, press Escape key.\nFigure 5.2: Shiny Stop App\nmay noticed click Run App button, ’s just running function shiny::runApp() console. can run command instead clicking button prefer.Exercise: Try running empty app using runApp() function instead using Run App button.","code":"\nlibrary(shiny)\nui <- fluidPage()\nserver <- function(input, output) {}\nshinyApp(ui = ui, server = server)"},{"path":"shiny.html","id":"alternate-way-to-create-a-shiny-app-separate-ui-and-server-files","chapter":"Day 5 Shiny applications","heading":"5.4.1 Alternate way to create a Shiny app: separate UI and server files","text":"Another way define Shiny app separating UI server code two files: ui.R server.R. preferable way write Shiny apps app complex involves code, tutorial ’ll stick simple single file. want break app two files, simply put code assigned ui variable ui.R code assigned server function server.R. RStudio sees two files folder, know ’re writing Shiny app.Exercise: Try making new Shiny app creating two files ui.R server.R. Remember folder. Also remember put new, isolated folder (app.R already exists).","code":""},{"path":"shiny.html","id":"let-rstudio-fill-out-a-shiny-app-template-for-you","chapter":"Day 5 Shiny applications","heading":"5.4.2 Let RStudio fill out a Shiny app template for you","text":"can also create new Shiny app using RStudio’s menu selecting File > New File > Shiny Web App…. , RStudio let choose want single-file app (app.R) two-file app (ui.R+server.R). RStudio initialize simple functional Shiny app code . personally don’t use feature find easier simply type lines Shiny app save files.","code":""},{"path":"shiny.html","id":"load-the-dataset","chapter":"Day 5 Shiny applications","heading":"5.5 Load the dataset","text":"raw dataset contains information employees city Chicago (employees-.csv). processed dataset ’ll using app subset employees wage employees (paid hourly), opposed salaried employees. subset employees-wage.csv file.Add line app load data variable called employ. look something like (sure add library(tidyverse) library(readr) script can use read_csv function):Place line app third line, just library(shiny) library(tidyverse). Make sure file path file name correct, otherwise app won’t run. Try run app make sure file can loaded without errors.want verify app can successfully read data, can add print() statement reading data. won’t make anything happen Shiny app, see summary dataset printed console, let know dataset indeed loaded correctly. can place following line reading data:get confirmation data properly loaded, can remove line.Exercise: Load data file R get feel ’s . big , variables , normal wage ranges, etc.","code":"\nemploy <- read_csv(\"employees-wage.csv\")\nprint(glimpse(employ))"},{"path":"shiny.html","id":"build-the-basic-ui","chapter":"Day 5 Shiny applications","heading":"5.6 Build the basic UI","text":"Let’s start populating app elements visually. usually first thing writing Shiny app - add elements UI.","code":""},{"path":"shiny.html","id":"add-plain-text-to-the-ui","chapter":"Day 5 Shiny applications","heading":"5.6.1 Add plain text to the UI","text":"can place R strings inside fluidPage() render text.Replace line app assigns empty fluidPage() ui one , run app.entire UI built passing comma-separated arguments fluidPage() function. passing regular text, web page just render boring unformatted text.Exercise: Add several strings fluidPage() run app. Nothing exciting happening yet, just see text appear one contiguous block.","code":"\nfluidPage(\"City of Chicago Wage Employees\", \"hourly wage\")"},{"path":"shiny.html","id":"add-formatted-text-and-other-html-elements","chapter":"Day 5 Shiny applications","heading":"5.6.2 Add formatted text and other HTML elements","text":"want text formatted nicer, Shiny many functions wrappers around HTML tags format text. can use h1() function top-level header (<h1> HTML), h2() secondary header (<h2> HTML), strong() make text bold (<strong> HTML), em() make text italicized (<em> HTML), many .also functions wrappers HTML tags, br() line break, img() image, () hyperlink, others.functions actually just wrappers HTML tags equivalent name. can add arbitrary HTML tag using tags object, can learn reading help file tags.Just demonstration, try replacing fluidPage() function UI withRun app code UI. Notice formatting text understand rendered way.people know basic HTML: named argument pass HTML function becomes attribute HTML element, unnamed argument child element. means can, example, create blue text div(\"blue\", style = \"color: blue;\").Exercise: Experiment different HTML-wrapper functions inside fluidPage(). Run fluidPage(...) function console see HTML creates.","code":"\nui <- fluidPage(\n  h1(\"My app\"),\n  \"Chicago\",\n  \"Wage Employees\",\n  br(),\n  \"Hourly\",\n  strong(\"wage\")\n)"},{"path":"shiny.html","id":"add-a-title","chapter":"Day 5 Shiny applications","heading":"5.6.3 Add a title","text":"add title app h1(), Shiny also special function titlePanel(). Using titlePanel() adds visible big title-like text top page, also sets “official” title web page. means look name tab browser, ’ll see title.Overwrite fluidPage() experimented far, replace simple one , simply title nothing else.Exercise: Look documentation titlePanel() function notice another argument. Use argument see can see .","code":"\nfluidPage(\n  titlePanel(\"City of Chicago Wage Employees\")\n)"},{"path":"shiny.html","id":"add-a-layout","chapter":"Day 5 Shiny applications","heading":"5.6.4 Add a layout","text":"may noticed far, just adding text HTML tags, everything unstructured elements simply stack one one column. ’ll use sidebarLayout() add simple structure. provides simple two-column layout smaller sidebar larger main panel. ’ll build app inputs user can manipulate sidebar, results shown main panel right.Add following code titlePanel()Remember arguments inside fluidPage() need separated commas.far complete app looks like (hopefully isn’t surprise )\nFigure 5.3: Shiny layout\nwant lot flexible design, can much fine control things go using grid layout. won’t cover , ’re interested, look documentation ?column ?fluidRow.Exercise: Add UI two panels (sidebar panel main panel) see app now two columns.","code":"\nsidebarLayout(\n  sidebarPanel(\"our inputs will go here\"),\n  mainPanel(\"the results will go here\")\n)\nlibrary(shiny)\nlibrary(tidyverse)\n\nemploy <- read_csv(\"employees-wage.csv\")\n\nui <- fluidPage(\n  titlePanel(\"City of Chicago Wage Employees\"),\n  sidebarLayout(\n    sidebarPanel(\"our inputs will go here\"),\n    mainPanel(\"the results will go here\")\n  )\n)\n\nserver <- function(input, output) {}\n\nshinyApp(ui = ui, server = server)"},{"path":"shiny.html","id":"all-ui-functions-are-simply-html-wrappers","chapter":"Day 5 Shiny applications","heading":"5.7 All UI functions are simply HTML wrappers","text":"already mentioned, ’s important remember: entire UI just HTML, Shiny simply gives easy tools write without know HTML. convince , look output printing contents ui variable.make appreciate Shiny making write horrendous HTML hand.","code":"\nprint(ui)<div class=\"container-fluid\">\n  <h2>City of Chicago Wage Employees<\/h2>\n  <div class=\"row\">\n    <div class=\"col-sm-4\">\n      <form class=\"well\">our inputs will go here<\/form>\n    <\/div>\n    <div class=\"col-sm-8\">the results will go here<\/div>\n  <\/div>\n<\/div>"},{"path":"shiny.html","id":"add-inputs-to-the-ui","chapter":"Day 5 Shiny applications","heading":"5.8 Add inputs to the UI","text":"Inputs gives users way interact Shiny app. Shiny provides many input functions support many kinds interactions user app. example, textInput() used let user enter text, numericInput() lets user select number, dateInput() selecting date, selectInput() creating select box (aka dropdown menu).\nFigure 5.4: Shiny inputs\ninput functions first two arguments: inputId label. inputId name Shiny use refer input want retrieve current value. important note every input must unique inputId. give one input id, Shiny unfortunately give explicit error, app won’t work correctly. label argument specifies text display label goes along input widget. Every input can also multiple arguments specific input type. way find arguments can use specific input function look help file.Exercise: Read documentation ?numericInput try adding numeric input UI. Experiment different arguments. Run app see can interact input. try different inputs types.","code":""},{"path":"shiny.html","id":"input-for-hourly-wage","chapter":"Day 5 Shiny applications","heading":"5.8.1 Input for hourly wage","text":"first input want specifying wage range (minimum maximum hourly wage). sensible types input either numericInput() sliderInput() since used selecting numbers. use numericInput(), ’d use two inputs, one minimum value one maximum. Looking documentation sliderInput(), ’ll see supplying vector length two value argument, can used specify range rather single number. sounds like want case, ’ll use sliderInput().create slider input, maximum value needs provided. manually determine highest hourly wage rate dataset hardcode app. ’re already using R, let’s calculate dynamically. , write short piece R code determine largest value wage column. max() exactly .looking documentation slider input function, following piece code can constructed.Place code slider input inside sidebarPanel() (replace text wrote earlier input).Exercise: Run code sliderInput() R console see returns. Change parameters sliderInput(), see changes result. ’s important truly understand functions UI simply convenient way write HTML, apparent whenever run functions .","code":"## [1] 109\nsliderInput(inputId = \"wage\",\n            label = \"Wage range\",\n            min = 0,\n            max = max(employ$wage, na.rm = TRUE),\n            value = c(0, max(employ$wage, na.rm = TRUE)),\n            pre = \"$\")"},{"path":"shiny.html","id":"input-for-fullpart-time","chapter":"Day 5 Shiny applications","heading":"5.8.2 Input for full/part-time","text":"many employees city full-time workers, large portion work city part-time. Part-time workers likely seasonal employees, hourly wages may systematically differ full-time employees. helpful include option filter datset two types employees.want kind text input. allowing user enter text freely isn’t right solution want restrict user two choices. either use radio buttons select box purpose. Let’s use radio buttons now since two options, take look documentation radioButtons() come reasonable input function code. look like :Add input code inside sidebarPanel(), previous input (separate comma).","code":"\nradioButtons(inputId = \"full_time\",\n             label = \"Full or part-time\",\n             choices = c(\"Full-Time\", \"Part-Time\"))"},{"path":"shiny.html","id":"input-for-department","chapter":"Day 5 Shiny applications","heading":"5.8.3 Input for department","text":"Different departments offer different wage structures depending value skills demand. city classifies wage employees 22 distinct departments:appropriate input type case probably select box selectInput(). However don’t want write entire vector hand:Instead, like ’ll extract values directly data frame:Add function well app. followed along, entire app code:\nFigure 5.5: Shiny add inputs\n","code":"## c(\"Animal Care and Control\", \"Aviation\", \"Budget & Management\", \"Business Affairs and Consumer Protection\", \"City Council\", \"Community Development\", \"Cultural Affairs and Special Events\", \"Emergency Management & Communications\", \"Family & Support\", \"Finance\", \"Fire\", \"General Services\", \"Human Resources\", \"Law\", \"Mayor's Office\", \"Police\", \"Procurement Services\", \"Public Health\", \"Public Library\", \"Streets & Sanitation\", \"Transportation\", \"Water Management\")\nselectInput(inputId = \"department\",\n            label = \"Department\",\n            choices = sort(unique(employ$department)),\n            multiple = TRUE)\nlibrary(shiny)\nlibrary(tidyverse)\n\nemploy <- read_csv(\"employees-wage.csv\")\n\nui <- fluidPage(\n  titlePanel(\"City of Chicago Wage Employees\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(inputId = \"wage\",\n                  label = \"Wage range\",\n                  min = 0,\n                  max = max(employ$wage, na.rm = TRUE),\n                  value = c(0, max(employ$wage, na.rm = TRUE)),\n                  pre = \"$\"),\n      radioButtons(inputId = \"full_time\",\n                   label = \"Full or part-time\",\n                   choices = c(\"Full-Time\", \"Part-Time\")),\n      selectInput(inputId = \"department\",\n                  label = \"Department\",\n                  choices = sort(unique(employ$department)),\n                  multiple = TRUE)\n    ),\n    mainPanel(\"the results will go here\")\n  )\n)\n\nserver <- function(input, output) {}\n\nshinyApp(ui = ui, server = server)"},{"path":"shiny.html","id":"add-placeholders-for-outputs","chapter":"Day 5 Shiny applications","heading":"5.9 Add placeholders for outputs","text":"creating inputs, add elements UI display outputs. Outputs can object R creates want display app - plot, table, text. ’re still building UI, point can add placeholders outputs determine output ID , won’t actually show anything. output needs constructed server code later.Shiny provides several output functions, one type output. Similarly input functions, output functions outputId argument used identify output, argument must unique output.","code":""},{"path":"shiny.html","id":"output-for-a-plot-of-the-results","chapter":"Day 5 Shiny applications","heading":"5.9.1 Output for a plot of the results","text":"top main panel ’ll plot showing distribution hourly wages. Since want plot, function use plotOutput().Add following code mainPanel() (replace existing text):add placeholder UI plot named hourlyPlot.Exercise: remind still merely constructing HTML creating actual plots yet, run plotOutput() function console see create HTML.","code":"\nplotOutput(\"hourlyPlot\")"},{"path":"shiny.html","id":"output-for-a-table-summary-of-the-results","chapter":"Day 5 Shiny applications","heading":"5.9.2 Output for a table summary of the results","text":"plot, table shows summary number employees per department currently included plot. get table, use tableOutput() function.simple way create UI element hold table output:Add output mainPanel() well. Maybe add couple br() two outputs, just space buffer aren’t close .","code":"\ntableOutput(\"employTable\")"},{"path":"shiny.html","id":"checkpoint-what-our-app-looks-like-after-implementing-the-ui","chapter":"Day 5 Shiny applications","heading":"5.10 Checkpoint: what our app looks like after implementing the UI","text":"’ve followed along, app now code:","code":"\nlibrary(shiny)\nlibrary(tidyverse)\n\nemploy <- read_csv(\"employees-wage.csv\")\n\nui <- fluidPage(\n  titlePanel(\"City of Chicago Wage Employees\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(inputId = \"wage\",\n                  label = \"Wage range\",\n                  min = 0,\n                  max = max(employ$wage, na.rm = TRUE),\n                  value = c(0, max(employ$wage, na.rm = TRUE)),\n                  pre = \"$\"),\n      radioButtons(inputId = \"full_time\",\n                   label = \"Full or part-time\",\n                   choices = c(\"Full-Time\", \"Part-Time\")),\n      selectInput(inputId = \"department\",\n                  label = \"Department\",\n                  choices = sort(unique(employ$department)),\n                  multiple = TRUE)\n    ),\n    mainPanel(plotOutput(\"hourlyPlot\"),\n              tableOutput(\"employTable\"))\n  )\n)\n\nserver <- function(input, output) {}\n\nshinyApp(ui = ui, server = server)"},{"path":"shiny.html","id":"implement-server-logic-to-create-outputs","chapter":"Day 5 Shiny applications","heading":"5.11 Implement server logic to create outputs","text":"far wrote code inside assigned ui variable (code written ui.R). ’s usually easier part Shiny app. Now write server function, responsible listening changes inputs creating outputs show app.look server function, ’ll notice always defined two arguments: input output. must define two arguments! input output list-like objects. names suggest, input list read values output list write values . input contain values different inputs given time, output save output objects (tables plots) display app.","code":""},{"path":"shiny.html","id":"building-an-output","chapter":"Day 5 Shiny applications","heading":"5.11.1 Building an output","text":"Recall created two output placeholders: hourlyPlot (plot) employTable (table). need write code R tell Shiny kind plot table display. three rules build output Shiny.Save output object output list (remember app template - every server function output argument)Build object render* function, * type outputAccess input values using input list (every server function input argument)third rule required want output depend input, let’s first see build basic output using first two rules. ’ll create plot send hourlyPlot output.simple code shows first two rules: ’re creating plot inside renderPlot() function, assigning hourlyPlot output list. Remember every output created UI must unique ID, now see . order attach R object output ID x, assign R object output$x.Since hourlyPlot defined plotOutput, must use renderPlot function, must create plot inside renderPlot function.add code inside server function, see plot 100 random points app.Exercise: code inside renderPlot() doesn’t one line, can long ’d like long returns plot. Try making complex plot using ggplot2. plot doesn’t use dataset, anything, just make sure can use renderPlot().","code":"\noutput$hourlyPlot <- renderPlot({\n  plot(rnorm(100))\n})"},{"path":"shiny.html","id":"making-an-output-react-to-an-input","chapter":"Day 5 Shiny applications","heading":"5.11.2 Making an output react to an input","text":"Now ’ll take plot one step . Instead always plotting plot (100 random numbers), let’s use minimum wage selected number points show. doesn’t make much sense, ’s just learn make output depend input.Replace previous code server function code, run app. Whenever choose new minimum price range, plot update new number points. Notice thing different code instead using number 100 using input$wage[1].mean? Just like variable output contains list outputs (need assign code ), variable input contains list inputs defined UI. input$wage return vector length 2 containing minimum maximum wage. Whenever user manipulates slider app, values updated, whatever code relies gets re-evaluated. concept known reactivity, get minutes.Notice short 3 lines code using 3 rules building outputs: saving output list (output$hourlyPlot <-), using render* function build output (renderPlot({})), accessing input value (input$wage[1]).","code":"\noutput$hourlyPlot <- renderPlot({\n  plot(rnorm(input$wage[1]))\n})"},{"path":"shiny.html","id":"building-the-plot-output","chapter":"Day 5 Shiny applications","heading":"5.11.3 Building the plot output","text":"Now knowledge required build plot visualizing aspect data. ’ll create simple histogram hourly wage rate employees using 3 rules create plot output.First need make sure ggplot2 loaded, add library(ggplot2) top (just continue use library(tidyverse).Next ’ll return histogram hourly wage wage renderPlot(). Let’s start just histogram whole data, unfiltered.run app code inside server, see histogram app. change input values, nothing happens yet, next step actually filter dataset based inputs.Recall 3 inputs: wage, full_time, department. can filter data based values three inputs. now, filter wage full_time – ’ll return department little bit. ’ll use dplyr functions filter data, sure include library(dplyr) top. ’ll plot filtered data instead original data.Place code server function run app. change hourly wage full/part-time inputs, see histogram update.Read code understand . ’ve successfully created interactive app - plot changing according user’s selection.make sure ’re page, code look like point:\nFigure 5.6: Shiny add plot\nExercise: current plot doesn’t look nice, enhance plot make much pleasant look .","code":"\noutput$hourlyPlot <- renderPlot({\n  ggplot(employ, aes(wage)) +\n    geom_histogram()\n})\noutput$hourlyPlot <- renderPlot({\n  employ %>%\n    filter(full_time == input$full_time,\n           wage >= input$wage[[1]],\n           wage <= input$wage[[2]]) %>%\n    ggplot(aes(wage)) +\n    geom_histogram()\n})\nlibrary(shiny)\nlibrary(tidyverse)\n\nemploy <- read_csv(\"employees-wage.csv\")\n\nui <- fluidPage(\n  titlePanel(\"City of Chicago Wage Employees\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(inputId = \"wage\",\n                  label = \"Wage range\",\n                  min = 0,\n                  max = max(employ$wage, na.rm = TRUE),\n                  value = c(0, max(employ$wage, na.rm = TRUE)),\n                  pre = \"$\"),\n      radioButtons(inputId = \"full_time\",\n                   label = \"Full or part-time\",\n                   choices = c(\"Full-Time\", \"Part-Time\")),\n      selectInput(inputId = \"department\",\n                  label = \"Department\",\n                  choices = sort(unique(employ$department)),\n                  multiple = TRUE)\n    ),\n    mainPanel(plotOutput(\"hourlyPlot\"),\n              tableOutput(\"employTable\"))\n  )\n)\n\nserver <- function(input, output) {\n  output$hourlyPlot <- renderPlot({\n    employ %>%\n      filter(full_time == input$full_time,\n             wage >= input$wage[[1]],\n             wage <= input$wage[[2]]) %>%\n      ggplot(aes(wage)) +\n      geom_histogram()\n  })\n}\n\nshinyApp(ui = ui, server = server)"},{"path":"shiny.html","id":"building-the-table-output","chapter":"Day 5 Shiny applications","heading":"5.11.4 Building the table output","text":"Building next output much easier now ’ve done . output called employTable (defined UI) table summarizing number employees per department filtered data frame. Since ’s table output, use renderTable() function. ’ll exact filtering data, simply return summarized data data.frame. Shiny know needs display table ’s defined tableOutput.code creating table output make sense without much explanation:Add code server. Don’t overwrite previous definition output$hourlyPlot, just add code , inside server function. Run app, amazed! can now see table showing number wage employees per department match criteria.Notice building ui, using predefined function called fluidPage() different elements UI separated commas. element page argument fluidPage() function. building server, writing new function. reason don’t separate element comma. just write like function!Exercise: Add new output. Either new plot, new table, piece text changes based inputs. example, add text output (textOutput() UI, renderText() server) says many results found. choose , recommend first adding output UI, building output server static text make sure syntax correct. can see text output app make reflect inputs. Pro-tip: since textOutput() written UI, can wrap UI functions. example, h2(textOutput(...)) result larger text.","code":"\noutput$employTable <- renderTable({\n  employ %>%\n    filter(full_time == input$full_time,\n           wage >= input$wage[[1]],\n           wage <= input$wage[[2]]) %>%\n    count(department)\n})"},{"path":"shiny.html","id":"reactivity-101","chapter":"Day 5 Shiny applications","heading":"5.12 Reactivity 101","text":"Shiny uses concept called reactive programming. enables outputs react changes inputs. Reactivity Shiny complex, extreme oversimplification, means value variable x changes, anything relies x gets re-evaluated. Notice different used R. Consider following code:value y? ’s 6. reactive programming, x y reactive variables, value y 11 updated whenever x changed. powerful technique useful creating responsiveness Shiny apps, might bit weird first ’s different concept ’re used .reactive variables behave way, Shiny inputs automatically reactive. ’s can always use input$x render functions, can sure whatever output depends x use updated value x whenever x changes.might wondering means “depend” variable. official terminology, simply means variable referenced code. merely accessing value reactive variable, causes current code block “depend” variable. Consider following sample code create plot specific number points specific color:render function accesses two different inputs: input$mycolor input$mynumber. means code block depends variables, whenever either one two inputs updated, code gets re-executed new input values output$someoutput updated.","code":"\nx <- 5\ny <- x + 1\nx <- 10\noutput$someoutput <- renderPlot({\n  col <- input$mycolor\n  num <- input$mynumber\n  plot(rnorm(num), col = col)\n})"},{"path":"shiny.html","id":"creating-and-accessing-reactive-variables","chapter":"Day 5 Shiny applications","heading":"5.12.1 Creating and accessing reactive variables","text":"One important thing remember reactive variables (input list) can used inside reactive contexts. render* function reactive context, can always use input$x reactive variable inside render functions. two common reactive contexts ’ll get minute: reactive({}) observe({}). show means, let’s try accessing price input value server function, without explicitly inside reactive context. Simply add print(input$wage) inside server function, get error running app:Shiny clear error : trying access reactive variable outside reactive context. fix , can use observe({}) function access input variable. Inside server, replace print(input$wage) observe({ print(input$wage) }), now app run fine. Note observe({}) statement depends input$wage, whenever change value price, code inside observe({}) run , new value printed. actually simple yet useful debugging technique Shiny: often want know value reactive variable holds, need remember wrap cat(input$x) print(input$x) observe({}).far saw one reactive variable: input list. can also create reactive variables using reactive({}) function. reactive({}) function similar observe({}) also reactive context, means get re-run whenever reactive variables get updated. difference reactive({}) returns value. see action, let’s create variable called wageDiff difference maximum minimum wage selected. try naively define wageDiff <- diff(input$wage), ’ll see error something outside reactive context. input$wage reactive variable, can’t use reactive variable outside reactive context. Since want assign value, use reactive({}) function. Try adding following line server:Now app run. want access reactive variable defined reactive({}), must add parentheses variable name, ’s function. demonstrate , add observe({ print(wageDiff()) }) server function. Notice use wageDiff() rather wageDiff. ’s important remember , can get confusing unclear errors simply try access custom reactive variable without parentheses.can think reactivity causing chain reaction: one reactive value changes, anything depends get updated. updated values reactive variables, reactive contexts depend variables also get updated turn. concrete example, let’s think happens change value wage page. Since input$wage reactive variable, expression uses get updated. means two render functions earlier execute depend input$wage, well wageDiff variable also depends . since wageDiff reactive variable, Shiny check anything depends wageDiff, indeed - observe({}) function prints value wageDiff. wageDiff gets updated, observe({}) function run, value get printed.Reactivity usually hardest part Shiny understand, don’t quite get , don’t feel bad. Try reading section , promise time experience get comfortable reactivity. feel confident reactivity, may good idea read advanced documentation describing reactivity, since section greatly simplifies ideas make understandable. great resource RStudio’s tutorial reactivity.continuing next section, can remove observe({}) reactive({}) functions wrote section since just learning purposes.Exercise: Read section really understand reactive variable means, 3 main reactive contexts , can define reactive variables, reactivity chain events works.","code":"Operation not allowed without an active reactive context. (You tried to do something that can only be done from inside a reactive expression or observer.)\nwageDiff <- reactive({\n  diff(input$wage)\n})"},{"path":"shiny.html","id":"using-reactive-variables-to-reduce-code-duplication","chapter":"Day 5 Shiny applications","heading":"5.12.2 Using reactive variables to reduce code duplication","text":"may noticed exact code filtering dataset two places, render function. can solve problem defining reactive variable hold filtered dataset, use variable render functions.first step create reactive variable. following code added server() function.variable employ_filter defined exactly like , except body wrapped reactive({}), ’s defined server function instead inside individual render functions. Now reactive variable, can use output render functions. Try , think ’re done, check code . Don’t forget order access value reactive expression, must follow name variable parentheses! server function look like now.reminder, Shiny creates dependency tree reactive expressions know value depends value. example, wage input changes, Shiny looks values depend input$wage, sees employ_filter reactive expression depends price input, re-evaluates employ_filter. , employ_filter changed, Shiny now looks see expressions depend employ_filter, finds two render functions use employ_filter. Shiny re-executes two render functions well.","code":"\nemploy_filter <- reactive({\n  employ %>%\n    filter(\n      # filter by full or part-time\n      full_time == input$full_time,\n      # filter by hourly wage\n      wage >= input$wage[[1]],\n      wage <= input$wage[[2]]\n    )    \n})\nserver <- function(input, output) {\n  employ_filter <- reactive({\n    employ %>%\n      filter(\n        # filter by full or part-time\n        full_time == input$full_time,\n        # filter by hourly wage\n        wage >= input$wage[[1]],\n        wage <= input$wage[[2]]\n      )    \n  })\n  \n  output$hourlyPlot <- renderPlot({\n    ggplot(employ_filter(), aes(wage)) +\n      geom_histogram()\n  })\n\n  output$employTable <- renderTable({\n    employ_filter() %>%\n      count(department)\n  })\n}"},{"path":"shiny.html","id":"blank-plots-showing-up","chapter":"Day 5 Shiny applications","heading":"5.12.3 Blank plots showing up","text":"Let’s now consider incorporate department input. input$department character vector varying length (depending number departments selected), use %% operator correctly filter employ. simple implementation look like :notice happens run app. get blank plot:\nFigure 5.7: Shiny App Blank Plot\nHowever select department (e.g. City Council), histrogram correctly drawn. gives? problem select values selectInput(inputId = \"department\"), value input$department possible values employ$department – ’s value NULL. employ data frame filtered 0 rows every observation value department (even value NA).Fixing (relatively) simple. Inside employ_filter reactive function, check department input exists, just filter column. ’s easier write employ_filter single piped operation:21Now render function tries access input$department, get NULL value user makes selection therefore skips filtering employ based department. also reliable fix app generates temporary error messages vanish second. may occur output relies object yet generated Shiny server() function.","code":"\nemploy_filter <- reactive({\n  employ %>%\n    filter(\n      # filter by full or part-time\n      full_time == input$full_time,\n      # filter by hourly wage\n      wage >= input$wage[[1]],\n      wage <= input$wage[[2]],\n      department %in% input$department\n    )    \n})\nemploy_filter <- reactive({\n  employees <- employ\n  \n  # filter by department\n  if(!is.null(input$department)) {\n    employees <- filter(employees, department %in% input$department)\n  }\n  \n  # filter by full or part-time\n  employees <- filter(employees, full_time == input$full_time)\n  \n  # filter by hourly wage\n  employees <- filter(employees,\n                      wage >= input$wage[[1]],\n                      wage <= input$wage[[2]])\n})"},{"path":"shiny.html","id":"using-uioutput-to-create-ui-elements-dynamically","chapter":"Day 5 Shiny applications","heading":"5.13 Using uiOutput() to create UI elements dynamically","text":"One output functions can add UI uiOutput(). According naming convention (e.g. plotOutput() output render plot), output used render UI. may sound bit confusing, ’s actually useful. ’s usually used create inputs (UI) server, words - can create inputs dynamically.input normally create UI created app starts, changed. one inputs depends another input? case, want able create input dynamically, server, use uiOutput(). uiOutput() can used create UI element, ’s often used create input UI elements. rules regarding building outputs apply, means output (UI element case) created function renderUI().","code":""},{"path":"shiny.html","id":"basic-example-of-uioutput","chapter":"Day 5 Shiny applications","heading":"5.13.1 Basic example of uiOutput()","text":"basic example, consider app:run tiny app, see whenever change value numeric input, slider input re-generated. behavior can come handy often.","code":"\nlibrary(shiny)\nui <- fluidPage(\n  numericInput(\"num\", \"Maximum slider value\", 5),\n  uiOutput(\"slider\")\n)\n\nserver <- function(input, output) {\n  output$slider <- renderUI({\n    sliderInput(\"slider\", \"Slider\", min = 0,\n                max = input$num, value = 0)\n  })\n}\n\nshinyApp(ui = ui, server = server)"},{"path":"shiny.html","id":"use-uioutput-in-our-app-to-populate-the-job-titles","chapter":"Day 5 Shiny applications","heading":"5.13.2 Use uiOutput() in our app to populate the job titles","text":"can use concept app populate choices job title selector. employ$job_title contains 145 distinct job titles, applicable every department. helpful allow app users filter dataset job title, allow input job titles fall within specified department(s).First need add placeholder selectInput() UI :need create output (create UI element - yeah, can bit confusing first), add following code server function:Finally make sure data properly updates, change employ_filter server function :Now run app, able see different job titles available department available job titles update select specific departments.","code":"\nuiOutput(\"jobTitle\")\noutput$jobTitle <- renderUI({\n  employees <- employ\n  \n  # filter by department\n  if(!is.null(input$department)) {\n    employees <- filter(employees, department %in% input$department)\n  }\n  \n  # filter by full or part-time\n  employees <- filter(employees, full_time == input$full_time)\n  \n  # filter by hourly wage\n  employees <- filter(employees,\n                      wage >= input$wage[[1]],\n                      wage <= input$wage[[2]])\n  \n  selectInput(inputId = \"jobTitle\",\n              label = \"Job Title\",\n              choices = sort(unique(employees$job_title)),\n              multiple = TRUE)\n})\nemploy_filter <- reactive({\n  employees <- employ\n  \n  # filter by department\n  if(!is.null(input$department)) {\n    employees <- filter(employees, department %in% input$department)\n  }\n  \n  # filter by job title\n  if(!is.null(input$jobTitle)) {\n    employees <- filter(employees, job_title %in% input$jobTitle)\n  }\n  \n  # filter by full or part-time\n  employees <- filter(employees, full_time == input$full_time)\n  \n  # filter by hourly wage\n  employees <- filter(employees,\n                      wage >= input$wage[[1]],\n                      wage <= input$wage[[2]])\n})"},{"path":"shiny.html","id":"final-shiny-app-code","chapter":"Day 5 Shiny applications","heading":"5.14 Final Shiny app code","text":"case got lost somewhere, final code. app now functional, plenty features can add make better.","code":"\nlibrary(shiny)\nlibrary(tidyverse)\n\nemploy <- read_csv(\"employees-wage.csv\")\n\nui <- fluidPage(\n  titlePanel(\"City of Chicago Wage Employees\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(inputId = \"wage\",\n                  label = \"Wage range\",\n                  min = 0,\n                  max = max(employ$wage, na.rm = TRUE),\n                  value = c(0, max(employ$wage, na.rm = TRUE)),\n                  pre = \"$\"),\n      radioButtons(inputId = \"full_time\",\n                   label = \"Full or part-time\",\n                   choices = c(\"Full-Time\", \"Part-Time\")),\n      selectInput(inputId = \"department\",\n                  label = \"Department\",\n                  choices = sort(unique(employ$department)),\n                  multiple = TRUE),\n      uiOutput(\"jobTitle\")\n    ),\n    mainPanel(plotOutput(\"hourlyPlot\"),\n              tableOutput(\"employTable\"))\n  )\n)\n\nserver <- function(input, output) {\n  employ_filter <- reactive({\n    employees <- employ\n    \n    # filter by department\n    if(!is.null(input$department)) {\n      employees <- filter(employees, department %in% input$department)\n    }\n    \n    # filter by job title\n    if(!is.null(input$jobTitle)) {\n      employees <- filter(employees, job_title %in% input$jobTitle)\n    }\n    \n    # filter by full or part-time\n    employees <- filter(employees, full_time == input$full_time)\n    \n    # filter by hourly wage\n    employees <- filter(employees,\n                        wage >= input$wage[[1]],\n                        wage <= input$wage[[2]])\n  })\n\n  output$jobTitle <- renderUI({\n    employees <- employ\n    \n    # filter by department\n    if(!is.null(input$department)) {\n      employees <- filter(employees, department %in% input$department)\n    }\n    \n    # filter by full or part-time\n    employees <- filter(employees, full_time == input$full_time)\n    \n    # filter by hourly wage\n    employees <- filter(employees,\n                        wage >= input$wage[[1]],\n                        wage <= input$wage[[2]])\n    \n    selectInput(inputId = \"jobTitle\",\n                label = \"Job Title\",\n                choices = sort(unique(employees$job_title)),\n                multiple = TRUE)\n  })\n  \n  output$hourlyPlot <- renderPlot({\n    ggplot(employ_filter(), aes(wage)) +\n      geom_histogram()\n  })\n\n  output$employTable <- renderTable({\n    employ_filter() %>%\n      count(department)\n  })\n}\n\nshinyApp(ui = ui, server = server)"},{"path":"shiny.html","id":"share-your-app-with-the-world","chapter":"Day 5 Shiny applications","heading":"5.15 Share your app with the world","text":"Remember every single app web page powered R session computer? far, ’ve running Shiny locally, means computer used power app. also means app accessible anyone internet. want share app world, need host somewhere.","code":""},{"path":"shiny.html","id":"host-on-shinyapps.io","chapter":"Day 5 Shiny applications","heading":"5.15.1 Host on shinyapps.io","text":"RStudio provides service called shinyapps.io lets host apps free. integrated seamlessly RStudio can publish apps click button, free version. free version allows certain number apps per user certain number activity app, good enough . also lets see basic stats usage app.Hosting app shinyapps.io easy recommended way getting app online. Go www.shinyapps.io sign account. ’re ready publish app, click “Publish Application” button RStudio follow instructions. might asked install couple packages ’s first time.\nFigure 5.8: Shiny Publish\nsuccessful deployment shinyapps.io, redirected app browser. can use URL show family cool app wrote.","code":""},{"path":"shiny.html","id":"host-on-a-shiny-server","chapter":"Day 5 Shiny applications","heading":"5.15.2 Host on a Shiny Server","text":"option hosting app private Shiny server. Shiny Server also product RStudio lets host apps server. means instead RStudio hosting app , private server. means lot freedom flexibility, also means need server comfortable administering server.","code":""},{"path":"shiny.html","id":"more-shiny-features-to-check-out","chapter":"Day 5 Shiny applications","heading":"5.16 More Shiny features to check out","text":"Shiny extremely powerful lots features haven’t covered. ’s sneak peek just common Shiny features advanced.","code":""},{"path":"shiny.html","id":"shiny-in-rmarkdown","chapter":"Day 5 Shiny applications","heading":"5.16.1 Shiny in Rmarkdown","text":"can include Shiny inputs outputs Rmarkdown document! means Rmarkdown document can interactive. Learn . ’s simple example include interactive Shiny elements R Markdown document:","code":"---\noutput: html_document\nruntime: shiny\n---\n\n```{r echo=FALSE, eval = TRUE}\nsliderInput(\"num\", \"Choose a number\",\n            0, 100, 20)\n\nrenderPlot({\n    plot(seq(input$num))\n})\n```"},{"path":"shiny.html","id":"use-conditionalpanel-to-conditionally-show-ui-elements","chapter":"Day 5 Shiny applications","heading":"5.16.2 Use conditionalPanel() to conditionally show UI elements","text":"can use conditionalPanel() either show hide UI element based simple condition, value another input. Learn ?conditionalPanel.","code":"\nlibrary(shiny)\nui <- fluidPage(\n  numericInput(\"num\", \"Number\", 5, 1, 10),\n  conditionalPanel(\n    \"input.num >=5\",\n    \"Hello!\"\n  )\n)\nserver <- function(input, output) {}\nshinyApp(ui = ui, server = server)"},{"path":"shiny.html","id":"use-navbarpage-or-tabsetpanel-to-have-multiple-tabs-in-the-ui","chapter":"Day 5 Shiny applications","heading":"5.16.3 Use navbarPage() or tabsetPanel() to have multiple tabs in the UI","text":"apps requires single “view”, can separate tabs. Learn ?navbarPage ?tabsetPanel.","code":"\nlibrary(shiny)\nui <- fluidPage(\n  tabsetPanel(\n    tabPanel(\"Tab 1\", \"Hello\"),\n    tabPanel(\"Tab 2\", \"there!\")\n  )\n)\nserver <- function(input, output) {}\nshinyApp(ui = ui, server = server)"},{"path":"shiny.html","id":"use-dt-for-beautiful-interactive-tables","chapter":"Day 5 Shiny applications","heading":"5.16.4 Use DT for beautiful, interactive tables","text":"Whenever use tableOutput() + renderTable(), table Shiny creates static boring-looking table. download DT package, can replace default table much sleeker table just using DT::dataTableOutput() + DT::renderDataTable(). ’s worth trying. Learn DT’s website.","code":""},{"path":"shiny.html","id":"use-isolate-function-to-remove-a-dependency-on-a-reactive-variable","chapter":"Day 5 Shiny applications","heading":"5.16.5 Use isolate() function to remove a dependency on a reactive variable","text":"multiple reactive variables inside reactive context, whole code block get re-executed whenever reactive variables change variables become dependencies code. want suppress behavior cause reactive variable dependency, can wrap code uses variable inside isolate() function. reactive variables inside isolate() result code re-executing value changed. Read behavior ?isolate.","code":""},{"path":"shiny.html","id":"use-updateinput-functions-to-update-input-values-programmatically","chapter":"Day 5 Shiny applications","heading":"5.16.6 Use update*Input() functions to update input values programmatically","text":"input function equivalent update*Input function can used update parameters.Note used additional argument session defining server function. input output arguments mandatory, session argument optional. need define session argument want use functions need access session. session parameter actually useful information , can learn ?shiny::session.","code":"\nlibrary(shiny)\nui <- fluidPage(\n  sliderInput(\"slider\", \"Move me\", value = 5, 1, 10),\n  numericInput(\"num\", \"Number\", value = 5, 1, 10)\n)\nserver <- function(input, output, session) {\n  observe({\n    updateNumericInput(session, \"num\", value = input$slider)\n  })\n}\nshinyApp(ui = ui, server = server)"},{"path":"shiny.html","id":"scoping-rules-in-shiny-apps","chapter":"Day 5 Shiny applications","heading":"5.16.7 Scoping rules in Shiny apps","text":"Scoping important understand Shiny want support one user time. Since app can hosted online, multiple users can use app simultaneously. variables (datasets global parameters) shared users, can safely define globally. variable specific user’s session defined globally.can think server function sandbox user. code outside server function run shared instances Shiny app. code inside server run every user visits app. means user-specific variables defined inside server. look code Virginia ABC Store app, ’ll see followed rule: raw dataset loaded outside server therefore available users, employ_filter object constructed inside server every user version . employ_filter global variable, one user changes values app, users connected app see change happen.can learn scoping rules Shiny .","code":""},{"path":"shiny.html","id":"use-global.r-to-define-objects-available-to-both-ui.r-and-server.r","chapter":"Day 5 Shiny applications","heading":"5.16.8 Use global.R to define objects available to both ui.R and server.R","text":"objects want available ui.R server.R, can place global.R. can learn global.R scoping rules .","code":""},{"path":"shiny.html","id":"add-images","chapter":"Day 5 Shiny applications","heading":"5.16.9 Add images","text":"can add image Shiny app placing image “www/” folder using UI function img(src = \"image.png\"). Shiny know automatically look “www/” folder image.","code":""},{"path":"shiny.html","id":"add-javascriptcss","chapter":"Day 5 Shiny applications","heading":"5.16.10 Add JavaScript/CSS","text":"know JavaScript CSS welcome use app.want add JavaScript use common JavaScript functions apps, might want check shinyjs.","code":"\nlibrary(shiny)\nui <- fluidPage(\n  tags$head(tags$script(\"alert('Hello!');\")),\n  tags$head(tags$style(\"body{ color: blue; }\")),\n  \"Hello\"\n)\nserver <- function(input, output) {\n  \n}\nshinyApp(ui = ui, server = server)"},{"path":"shiny.html","id":"awesome-add-on-packages-to-shiny","chapter":"Day 5 Shiny applications","heading":"5.17 Awesome add-on packages to Shiny","text":"Many people written packages enhance Shiny way add extra functionality. list several popular packages people often use together Shiny:shinyjs: Easily improve user interaction user experience Shiny apps secondsshinythemes: Easily alter appearance appleaflet: Add interactive maps appsggvis: Similar ggplot2, plots focused web-based interactiveshinydashboard: Gives tools create visual “dashboards”","code":""},{"path":"shiny.html","id":"resources","chapter":"Day 5 Shiny applications","heading":"5.18 Resources","text":"Shiny popular package lots resources web. ’s compiled list resources fairly easy read understand.Shiny official tutorialShiny cheatsheetLots short useful articles different topics ShinyShiny RmarkdownGet help Shiny Google group StackOverflowPublish apps free shinyapps.ioLearn reactivity worksLearn useful debugging techniquesShiny tips & tricks improving apps solving common problems","code":""},{"path":"shiny.html","id":"acknowledgments-2","chapter":"Day 5 Shiny applications","heading":"Acknowledgments","text":"page derived part “UBC STAT 545A 547M”, licensed CC -NC 3.0 Creative Commons License.","code":""},{"path":"shiny.html","id":"session-info-4","chapter":"Day 5 Shiny applications","heading":"Session info","text":"","code":"## ─ Session info ───────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.1.2 (2021-11-01)\n##  os       macOS Monterey 12.2.1\n##  system   aarch64, darwin20\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       America/Chicago\n##  date     2022-03-04\n##  pandoc   2.17.1.1 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/ (via rmarkdown)\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────\n##  package     * version date (UTC) lib source\n##  assertthat    0.2.1   2019-03-21 [1] CRAN (R 4.1.0)\n##  backports     1.4.1   2021-12-13 [1] CRAN (R 4.1.1)\n##  bit           4.0.4   2020-08-04 [1] CRAN (R 4.1.1)\n##  bit64         4.0.5   2020-08-30 [1] CRAN (R 4.1.0)\n##  bookdown      0.24    2021-09-02 [1] CRAN (R 4.1.1)\n##  brio          1.1.3   2021-11-30 [1] CRAN (R 4.1.1)\n##  broom         0.7.12  2022-01-28 [1] CRAN (R 4.1.1)\n##  bslib         0.3.1   2021-10-06 [1] CRAN (R 4.1.1)\n##  cachem        1.0.6   2021-08-19 [1] CRAN (R 4.1.1)\n##  callr         3.7.0   2021-04-20 [1] CRAN (R 4.1.0)\n##  cellranger    1.1.0   2016-07-27 [1] CRAN (R 4.1.0)\n##  cli           3.2.0   2022-02-14 [1] CRAN (R 4.1.1)\n##  codetools     0.2-18  2020-11-04 [1] CRAN (R 4.1.2)\n##  colorspace    2.0-3   2022-02-21 [1] CRAN (R 4.1.1)\n##  crayon        1.5.0   2022-02-14 [1] CRAN (R 4.1.1)\n##  curl          4.3.2   2021-06-23 [1] CRAN (R 4.1.0)\n##  DBI           1.1.2   2021-12-20 [1] CRAN (R 4.1.1)\n##  dbplyr        2.1.1   2021-04-06 [1] CRAN (R 4.1.0)\n##  desc          1.4.0   2021-09-28 [1] CRAN (R 4.1.1)\n##  devtools      2.4.3   2021-11-30 [1] CRAN (R 4.1.1)\n##  digest        0.6.29  2021-12-01 [1] CRAN (R 4.1.1)\n##  dplyr       * 1.0.8   2022-02-08 [1] CRAN (R 4.1.1)\n##  ellipsis      0.3.2   2021-04-29 [1] CRAN (R 4.1.0)\n##  evaluate      0.15    2022-02-18 [1] CRAN (R 4.1.1)\n##  fansi         1.0.2   2022-01-14 [1] CRAN (R 4.1.1)\n##  fastmap       1.1.0   2021-01-25 [1] CRAN (R 4.1.0)\n##  forcats     * 0.5.1   2021-01-27 [1] CRAN (R 4.1.1)\n##  fs            1.5.2   2021-12-08 [1] CRAN (R 4.1.1)\n##  generics      0.1.2   2022-01-31 [1] CRAN (R 4.1.1)\n##  ggplot2     * 3.3.5   2021-06-25 [1] CRAN (R 4.1.1)\n##  glue          1.6.1   2022-01-22 [1] CRAN (R 4.1.1)\n##  gtable        0.3.0   2019-03-25 [1] CRAN (R 4.1.1)\n##  haven         2.4.3   2021-08-04 [1] CRAN (R 4.1.1)\n##  here        * 1.0.1   2020-12-13 [1] CRAN (R 4.1.0)\n##  highr         0.9     2021-04-16 [1] CRAN (R 4.1.0)\n##  hms           1.1.1   2021-09-26 [1] CRAN (R 4.1.1)\n##  htmltools     0.5.2   2021-08-25 [1] CRAN (R 4.1.1)\n##  httr          1.4.2   2020-07-20 [1] CRAN (R 4.1.0)\n##  jquerylib     0.1.4   2021-04-26 [1] CRAN (R 4.1.0)\n##  jsonlite      1.8.0   2022-02-22 [1] CRAN (R 4.1.1)\n##  knitr       * 1.37    2021-12-16 [1] CRAN (R 4.1.1)\n##  lifecycle     1.0.1   2021-09-24 [1] CRAN (R 4.1.1)\n##  lubridate     1.8.0   2021-10-07 [1] CRAN (R 4.1.1)\n##  magrittr      2.0.2   2022-01-26 [1] CRAN (R 4.1.1)\n##  memoise       2.0.1   2021-11-26 [1] CRAN (R 4.1.1)\n##  modelr        0.1.8   2020-05-19 [1] CRAN (R 4.1.0)\n##  munsell       0.5.0   2018-06-12 [1] CRAN (R 4.1.0)\n##  pillar        1.7.0   2022-02-01 [1] CRAN (R 4.1.1)\n##  pkgbuild      1.3.1   2021-12-20 [1] CRAN (R 4.1.1)\n##  pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 4.1.0)\n##  pkgload       1.2.4   2021-11-30 [1] CRAN (R 4.1.1)\n##  prettyunits   1.1.1   2020-01-24 [1] CRAN (R 4.1.0)\n##  processx      3.5.2   2021-04-30 [1] CRAN (R 4.1.0)\n##  ps            1.6.0   2021-02-28 [1] CRAN (R 4.1.0)\n##  purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.1.0)\n##  R6            2.5.1   2021-08-19 [1] CRAN (R 4.1.1)\n##  Rcpp          1.0.8   2022-01-13 [1] CRAN (R 4.1.1)\n##  readr       * 2.1.2   2022-01-30 [1] CRAN (R 4.1.1)\n##  readxl        1.3.1   2019-03-13 [1] CRAN (R 4.1.0)\n##  remotes       2.4.2   2021-11-30 [1] CRAN (R 4.1.1)\n##  reprex        2.0.1   2021-08-05 [1] CRAN (R 4.1.1)\n##  rlang         1.0.1   2022-02-03 [1] CRAN (R 4.1.1)\n##  rmarkdown     2.11    2021-09-14 [1] CRAN (R 4.1.1)\n##  rprojroot     2.0.2   2020-11-15 [1] CRAN (R 4.1.0)\n##  rstudioapi    0.13    2020-11-12 [1] CRAN (R 4.1.0)\n##  rvest         1.0.2   2021-10-16 [1] CRAN (R 4.1.1)\n##  sass          0.4.0   2021-05-12 [1] CRAN (R 4.1.0)\n##  scales        1.1.1   2020-05-11 [1] CRAN (R 4.1.0)\n##  sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.1.1)\n##  stringi       1.7.6   2021-11-29 [1] CRAN (R 4.1.1)\n##  stringr     * 1.4.0   2019-02-10 [1] CRAN (R 4.1.1)\n##  testthat      3.1.2   2022-01-20 [1] CRAN (R 4.1.1)\n##  tibble      * 3.1.6   2021-11-07 [1] CRAN (R 4.1.1)\n##  tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.1.1)\n##  tidyselect    1.1.2   2022-02-21 [1] CRAN (R 4.1.1)\n##  tidyverse   * 1.3.1   2021-04-15 [1] CRAN (R 4.1.0)\n##  tzdb          0.2.0   2021-10-27 [1] CRAN (R 4.1.1)\n##  usethis       2.1.5   2021-12-09 [1] CRAN (R 4.1.1)\n##  utf8          1.2.2   2021-07-24 [1] CRAN (R 4.1.0)\n##  vctrs         0.3.8   2021-04-29 [1] CRAN (R 4.1.0)\n##  vroom         1.5.7   2021-11-30 [1] CRAN (R 4.1.1)\n##  withr         2.4.3   2021-11-30 [1] CRAN (R 4.1.1)\n##  xfun          0.29    2021-12-14 [1] CRAN (R 4.1.1)\n##  xml2          1.3.3   2021-11-30 [1] CRAN (R 4.1.1)\n##  yaml          2.3.5   2022-02-21 [1] CRAN (R 4.1.1)\n## \n##  [1] /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library\n## \n## ──────────────────────────────────────────────────────────────────────────────"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
