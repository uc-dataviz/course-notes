# Geospatial visualizations {#geoviz}

```{r knitr-opts-override, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r setup, cache = FALSE, echo = TRUE}
library(tidyverse)
library(sf)
library(ggmap)
library(rnaturalearth)
library(RColorBrewer)
library(patchwork)
library(tidycensus)
library(viridis)
library(here)

# useful on MacOS to speed up rendering of geom_sf() objects
if (!identical(getOption("bitmapType"), "cairo") && isTRUE(capabilities()[["cairo"]])) {
  options(bitmapType = "cairo")
}
```

## Learning objectives {-}

### Morning

* Introduce the major components of a geospatial visualization
* Identify how to draw raster maps using `ggmaps` and `get_map()`
* Practice generating raster maps

### Afternoon

* Define shapefiles and import spatial data using the `sf` package
* Draw maps using `ggplot2` and `geom_sf()`
* Change coordinate systems
* Generate appropriate color palettes to visualize additional dimensions of data

## Assigned readings {-}

* Chapter 7, @healy2018data - accessible via the [book's website](https://socviz.co/)

## Introduction to geospatial visualization

**Geospatial visualizations** are one of the earliest forms of information visualizations. They were used historically for navigation and were essential tools before the modern technological era of humanity. Data maps were first popularized in the seventeenth century and have grown in complexity and detail since then. Consider [Google Maps](https://www.google.com/maps), the sheer volume of data depicted, and the analytical pathways available to its users. Of course geospatial data visualizations do not require computational skills to generate.

### John Snow and the Broad Street water pump

```{r snow, fig.cap = "Original map made by John Snow in 1854. Cholera cases are highlighted in black. [Source: Wikipedia.](https://commons.wikimedia.org/wiki/File:Snow-cholera-map-1.jpg)"}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Snow-cholera-map-1.jpg/819px-Snow-cholera-map-1.jpg")
```

In the nineteenth century the theory of bacteria was not widely accepted by the medical community or the public.^[Drawn from [John Snow and the Broad Street Pump](http://www.ph.ucla.edu/epi/snow/snowcricketarticle.html)] A mother washed her baby's diaper in a well in 1854 in London, sparking an outbreak of **cholera**, an intestinal disease that causes vomiting, diarrhea, and eventually death. This disease had presented itself previously in London but its cause was still unknown.

Dr. John Snow lived in Soho, the suburb of London where the disease manifested in 1854, and wanted to understand how cholera spreads through a population (an early day epidemiologist). Snow recorded the location of individuals who contracted cholera, including their places of residence and employment. He used this information to draw a map of the region, recording the location of individuals who contracted the disease. They seemed to be clustered around the well pump along Broad Street. Snow used this map to deduce the source of the outbreak was the well, observing that almost all of the infected individuals lived near, and drank from, the well. Based on this information, the government removed the handle from the well pump so the public could not draw water from it. As a result, the cholera epidemic ended.

### *Carte figurative des pertes successives en hommes de l'Armée Française dans la campagne de Russie 1812-1813)*

```{r minard-orig, fig.cap = "Charles Minard's 1869 chart showing the number of men in Napoleon’s 1812 Russian campaign army, their movements, as well as the temperature they encountered on the return path. [Source: Wikipedia.](https://en.wikipedia.org/wiki/File:Minard.png)"}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/2/29/Minard.png")
```

```{r minard-translate, fig.cap = "English translation of Minard's map. [Source: Wikipedia.](https://commons.wikimedia.org/wiki/File:Minard_Update.png)"}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/e/e2/Minard_Update.png")
```

This illustration is identifed in Edward Tufte's **The Visual Display of Quantitative Information** as one of "the best statistical drawings ever created". It also demonstrates a very important rule of warfare: [never invade Russia in the winter](https://en.wikipedia.org/wiki/Russian_Winter).

In 1812, Napoleon ruled most of Europe. He wanted to seize control of the British islands, but could not overcome the UK defenses. He decided to impose an embargo to weaken the nation in preparation for invasion, but Russia refused to participate. Angered at this decision, Napoleon launched an invasion of Russia with over 400,000 troops in the summer of 1812. Russia was unable to defeat Napoleon in battle, but instead waged a war of attrition. The Russian army was in near constant retreat, burning or destroying anything of value along the way to deny France usable resources. While Napoleon's army maintained the military advantage, his lack of food and the emerging European winter decimated his forces. He left France with an army of approximately 422,000 soldiers; he returned to France with just 10,000.

Charles Minard's map is a stunning achievement for his era. It incorporates data across six dimensions to tell the story of Napoleon's failure. The graph depicts:

* Size of the army
* Location in two physical dimensions (latitude and longitude)
* Direction of the army's movement
* Temperature on dates during Napoleon's retreat

What makes this such an effective visualization?^[Source: [Dataviz History: Charles Minard's Flow Map of Napoleon's Russian Campaign of 1812](https://datavizblog.com/2013/05/26/dataviz-history-charles-minards-flow-map-of-napoleons-russian-campaign-of-1812-part-5/)]

* Forces visual comparisons (colored bands for advancing and retreating)
* Shows causality (temperature chart)
* Captures multivariate complexity
* Integrates text and graphic into a coherent whole (perhaps the first infographic, and done well!)
* Illustrates high quality content (based on reliable data)
* Places comparisons adjacent to each other (all on the same page, no jumping back and forth between pages)
* Mimimalistic in nature (avoids what we will later term "chart junk")

### Designing modern maps

Geometric visualizations are used to depict spatial features, and with the incorporation of data reveal additional attributes and information. The main features of a map are defined by its **scale** (the proportion between distances and sizes on the map), its **projection** (how the three-dimensional Earth is represented on a two-dimensional surface), and its **symbols** (how data is depicted and visualized on the map).

#### Scale

**Scale** defines the proportion between distances and sizes on a map and their actual distances and sizes on Earth. Depending on the total geographic area for which you have data to visualize, you could create a **small-scale map** or a **large-scale map**. So for instance, a map of the United States would be considered large-scale:

```{r large-scale}
# establish bounding box, get map, and plot
c(left = -128.364258,
  bottom = 11.480025,
  right = -65.742188,
  top = 55.329144) %>%
  get_stamenmap(zoom = 5) %>%
  ggmap()
```

Whereas a map of Hyde Park would be small-scale:

```{r small-scale}
# establish bounding box, get map, and plot
c(left = -87.612448,
  bottom = 41.783393,
  right = -87.581871,
  top = 41.803470) %>%
  get_stamenmap(zoom = 15) %>%
  ggmap()
```

The smaller the scale, the easier it is to include additional details in the map.

#### Projection

**Projection** is the process of taking a globe (i.e. a three-dimensional object)^[Assuming you are not a [flat-Earther](https://www.livescience.com/24310-flat-earth-belief.html).] and visualizing it on a two-dimensional picture. There is no 100% perfect method for doing this, as any projection method will have to distort some features of the map to achieve a two-dimensional representation. There are five properties to consider when defining a projection method:

1. Shape
1. Area
1. Angles
1. Distance
1. Direction

Projection methods typically maximize the accuracy of one or two of these properties, but no more. For instance, **conformal projections** such as the **mercator** projection preserves shape and local angles and is very useful for sea navigation, but distorts the area of landmasses.

```{r import-world, include = FALSE}
world <- ne_countries(returnclass = "sf")
```

```{r mercator, dependson = "import-world"}
world %>%
  st_transform("+proj=merc") %>%
  ggplot() +
  geom_sf() +
  ggtitle("Mercator projection")
```

The farther away from the equator one travels, the more distorted the size of the region.

Another family of projections called **equal-area projections** preserves area ratios, so that the relative size of areas on a map are proportional to their areas on the Earth.

```{r equal-area, dependson = "import-world"}
world %>%
  st_transform("+proj=laea") %>%
  ggplot() +
  geom_sf() +
  ggtitle("Lambert equal area projection")

world %>%
  st_transform("+proj=cea") %>%
  ggplot() +
  geom_sf() +
  ggtitle("Equal area cylindrical projection")
```

The downside is that equal-area projections tend to distory shapes heavily, so shapes of areas can become distorted. No method can be both conformal and equal-area simultaneously, but some methods such as the **Mollweide** projection achieve a trade-off between these sets of characteristics.

```{r mollweide, dependson = "import-world"}
world %>%
  st_transform("+proj=moll") %>%
  ggplot() +
  geom_sf() +
  ggtitle("Mollweide projection")
```

#### Symbols

Different types of symbols are used to denote different types of information on a spatial visualization. For instance, consider the following map of Hyde Park:

```{r bb-hydepark-stamen}
# store bounding box coordinates
hydepark_bb <- c(left = -87.612448,
                 bottom = 41.783393,
                 right = -87.581871,
                 top = 41.803470)

hydepark_stamen <- get_stamenmap(bbox = hydepark_bb,
                                 zoom = 16)
ggmap(hydepark_stamen)
```

* Line are used to indicate roadways
* Fill is used to indicate type of land (grassland, water, urban, etc.)
* Symbols/shapes are used to locate buildings
* Text labels are used to indicate geographic locations

Data maps do not just encode geographic features on the visualization. They also plot quantitative and qualitative data on the mapping surface itself. Minard's drawing was not just of geographic coordinates and features - it also visualizes quantitative data such as troop deaths and temperature. Different symbols are used depending on the type of data you seek to visualize.

## Drawing raster maps with `ggmap`

```{r knitr-opts-override-2, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

[`ggmap`](https://github.com/dkahle/ggmap) is a package for R that retrieves raster map tiles from online mapping services like [Google Maps](https://www.google.com/maps) and plots them using the `ggplot2` framework. The map tiles are **raster** because they are static image files generated previously by the mapping service. You do not need any data files containing information on things like scale, projection, boundaries, etc. because that information is already created by the map tile. This severely limits your ability to redraw or change the appearance of the geographic map, however the tradeoff means you can immediately focus on incorporating additional data into the map.

```{block2, type = "rmdalert", echo = TRUE}
Google has [changed its API requirements](https://developers.google.com/maps/documentation/geocoding/usage-and-billing), and **ggmap** users are now required to provide an API key *and* enable billing. I would not recommend trying to use Google Maps to obtain map images. The code below would work for you, but Google now charges you each time you obtain a map image. Stick to the other providers such as Stamen Maps.

```

### Obtain map images

`ggmap` supports open-source map providers such as [OpenStreetMap](https://www.openstreetmap.org/) and [Stamen Maps](http://maps.stamen.com/#terrain/12/37.7706/-122.3782), as well as the proprietary Google Maps. Obtaining map tiles requires use of the `get_map()` function. There are two formats for specifying the mapping region you wish to obtain:

1. Bounding box
1. Center/zoom

### Specifying map regions

#### Bounding box

**Bounding box** requires the user to specify the four corners of the box defining the map region. For instance, to obtain a map of Chicago using Stamen Maps:

```{r bb-chicago-stamen}
# store bounding box coordinates
chi_bb <- c(left = -87.936287,
            bottom = 41.679835,
            right = -87.447052,
            top = 42.000835)

chicago_stamen <- get_stamenmap(bbox = chi_bb,
                                zoom = 11)
chicago_stamen
```

To view the map, use `ggmap()`:

```{r bb-chicago-stamen-plot}
ggmap(chicago_stamen)
```

The `zoom` argument in `get_stamenmap()` controls the level of detail in the map. The larger the number, the greater the detail.

```{r bb-chicago-stamen-zoom-in}
get_stamenmap(bbox = chi_bb,
              zoom = 12) %>%
  ggmap()
```

The smaller the number, the lesser the detail.

```{r bb-chicago-stamen-zoom-out}
get_stamenmap(bbox = chi_bb,
              zoom = 10) %>%
  ggmap()
```

Trial and error will help you decide on the appropriate level of detail depending on what data you need to visualize on the map.

```{block2, type = "rmdnote", echo = TRUE}
Use [bboxfinder.com](http://bboxfinder.com/#0.000000,0.000000,0.000000,0.000000) to determine the exact longitude/latitude coordinates for the bounding box you wish to obtain.

```

#### Center/zoom

While Stamen Maps and OpenStreetMap require the bounding box format for obtaining map tiles and allow you to increase or decrease the level of detail within a single bounding box, Google Maps requires specifying the **center** coordinate of the map (a single longitude/latitude location) and the level of **zoom** or detail. `zoom` is an integer value from `3` (continent) to `21` (building). This means the level of detail is hardcoded to the size of the mapping region. The default `zoom` level is `10`.

```{r center-zoom-chicago, eval = FALSE}
# store center coordinate
chi_center <- c(lon = -87.65, lat = 41.855)

chicago_google <- get_googlemap(center = chi_center)
ggmap(chicago_google)

get_googlemap(center = chi_center,
              zoom = 12) %>%
  ggmap()

get_googlemap(center = chi_center,
              zoom = 8) %>%
  ggmap()
```

```{block2, type = "rmdnote", echo = TRUE}
Use [Find Latitude and Longitude](https://www.findlatitudeandlongitude.com/) to get the exact GPS coordinates of the center location.

```

### Types of map tiles

Each map tile provider offers a range of different types of maps depending on the background you want for the map. Stamen Maps offers several different types:

```{r stamen-maptype, echo = FALSE, fig.asp = 1}
stamen_maptype <- tibble(maptype = c("terrain", "terrain-background",
                                     "terrain-labels", "terrain-lines",
                                     "toner", "toner-2010",
                                     "toner-background", "toner-hybrid",
                                     "toner-labels", "toner-lines",
                                     "toner-lite", "watercolor")) %>%
  mutate(bb = map(maptype, ~ get_stamenmap(bbox = chi_bb, zoom = 10, maptype = .x)),
         ggmap = map2(bb, maptype, ~ ggmap(.x) +
                        labs(title = .y,
                             x = NULL,
                             y = NULL) +
                        theme_minimal(base_size = 10) +
                        theme(axis.text = element_blank(),
                              axis.ticks = element_blank())))

wrap_plots(stamen_maptype$ggmap)
```

Google Maps is a bit more limited, but still offers a few major types:

```{r google-maptype, echo = FALSE, eval = FALSE}
google_maptype <- tibble(maptype = c("terrain", "satellite",
                                         "roadmap", "hybrid")) %>%
  mutate(bb = map(maptype, ~ get_googlemap(center = chi_center, maptype = .x)),
         ggmap = map2(bb, maptype, ~ ggmap(.x) +
                        ggtitle(.y)))

wrap_plots(google_maptype$ggmap)
```

See the documentation for the `get_*map()` function for the exact code necessary to get each type of map.

```{block2, type = "rmdnote", echo = TRUE}
`get_map()` is a wrapper that automatically queries Google Maps, OpenStreetMap, or Stamen Maps depending on the function arguments and inputs. While useful, it also combines all the different arguments of `get_googlemap()`, `get_stamenmap()`, and `getopenstreetmap()` and can become a bit jumbled. Use at your own risk.

```

### Import crime data

Now that we can obtain map tiles and draw them using `ggmap()`, let's explore how to add data to the map. The city of Chicago has [an excellent data portal](https://data.cityofchicago.org/) publishing a large volume of public records. Here we'll look at [crime data from 2017](https://data.cityofchicago.org/Public-Safety/Crimes-2017/d62x-nvdr).^[[Full documentation of the data from the larger 2001-present crime dataset.](https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2).] I previously downloaded a `.csv` file containing all the records, which I import using `read_csv()`:

```{block2, type = "rmdnote", echo = TRUE}
If you are copying-and-pasting code from this demonstration, change this line of code to `crimes <- read_csv("https://cfss.uchicago.edu/data/Crimes_-_2017.csv")` to download the file from the course website.

```

```{r import-crimes}
crimes <- here("data", "Crimes_-_2017.csv") %>%
  read_csv()
glimpse(crimes)
```

Each row of the data frame is a single reported incident of crime. Geographic location is encoded in several ways, though most importantly for us the exact longitude and latitude of the incident is encoded in the `Longitude` and `Latitude` columns respectively.

### Plot high-level map of crime

Let's start with a simple high-level overview of reported crime in Chicago. First we need a map for the entire city.

```{r import-chicago}
chicago <- chicago_stamen
ggmap(chicago)
```

### Using `geom_point()`

Since each row is a single reported incident of crime, we could use `geom_point()` to map the location of every crime in the dataset. Because `ggmap()` uses the map tiles (here, defined by `chicago`) as the basic input, we specify `data` and `mapping` inside of `geom_point()`, rather than inside `ggplot()`:

```{r plot-crime-point, dependson = "import-crimes"}
ggmap(chicago) +
  geom_point(data = crimes,
             mapping = aes(x = Longitude,
                           y = Latitude))
```

What went wrong? All we get is a sea of black.

```{r num-crimes, dependson = "import-crimes"}
nrow(crimes)
```

Oh yeah. There were `r nrow(crimes)` reported incidents of crime in the city. Each incident is represented by a dot on the map. How can we make this map more usable? One option is to decrease the size and increase the transparancy of each data point so dense clusters of crime become apparent:

```{r plot-crime-point-alpha, dependson = "import-crimes"}
ggmap(chicago) +
  geom_point(data = crimes,
             aes(x = Longitude,
                 y = Latitude),
             size = .25,
             alpha = .01)
```

Better, but still not quite as useful as it could be.

### Using `stat_density_2d()`

Instead of relying on `geom_point()` and plotting the raw data, a better approach is to create a **heatmap**. More precisely, this will be a two-dimensional kernel density estimation (KDE). In this context, KDE will take all the raw data (i.e. reported incidents of crime) and convert it into a smoothed plot showing geographic concentrations of crime. The core function in `ggplot2` to generate this kind of plot is `geom_density_2d()`:

```{r kde-contour, dependson = "import-crimes"}
ggmap(chicago) +
  geom_density_2d(data = crimes,
                  aes(x = Longitude,
                      y = Latitude))
```

By default, `geom_density_2d()` draws a [**contour plot**](https://en.wikipedia.org/wiki/Contour_line) with lines of constant value. That is, each line represents approximately the same frequency of crime all along that specific line. Contour plots are frequently used in maps (known as **topographic maps**) to denote elevation.

```{r contour-plot, echo = FALSE,, fig.cap = "The Cadillac Mountains. Source: [US Geological Survey](https://www.usgs.gov/media/images/cadillacmountainss)."}
knitr::include_graphics("https://prd-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/thumbnails/image/CadillacMountainscreenshot.jpg")
```

Rather than drawing lines, instead we can fill in the graph so that we use the `fill` aesthetic to draw bands of crime density. To do that, we use the related function `stat_density_2d()`:

```{r kde-fill, dependson = "import-crimes"}
ggmap(chicago) +
  stat_density_2d(data = crimes,
                  aes(x = Longitude,
                      y = Latitude,
                      fill = stat(level)),
                  geom = "polygon")
```

Note the two new arguments:

* `geom = "polygon"` - change the [geometric object](/notes/grammar-of-graphics/#geometric-objects) to be drawn from a `density_2d` geom to a `polygon` geom
* `fill = stat(level)` - the value for the `fill` aesthetic is the `level` calculated within `stat_density_2d()`, which we access using the `stat()` notation.

This is an improvement, but we can adjust some additional settings to make the graph visually more useful. Specifically,

* Increase the number of `bins`, or unique bands of color allowed on the graph
* Make the heatmap semi-transparent using `alpha` so we can still view the underlying map
* Change the color palette to better distinguish between high and low crime areas. Here I use `brewer.pal()` from the `RColorBrewer` package to create a custom color palette using reds and yellows.

```{r plot-crime-density, dependson = "import-crimes"}
ggmap(chicago) +
  stat_density_2d(data = crimes,
                  aes(x = Longitude,
                      y = Latitude,
                      fill = stat(level)),
                  alpha = .2,
                  bins = 25,
                  geom = "polygon") +
  scale_fill_gradientn(colors = brewer.pal(7, "YlOrRd"))
```

From this map, a couple trends are noticeable:

* The downtown region has the highest crime incidence rate. Not surprising given its population density during the workday.
* There are clusters of crime on the south and west sides. Also not surprising if you know anything about the city of Chicago.

### Looking for variation

Because `ggmap` is built on `ggplot2`, we can use the core features of `ggplot2` to modify the graph. One major feature is faceting. Let's focus our analysis on four types of crimes with similar frequency of reported incidents^[Specifically burglary, motor vehicle theft, narcotics, and robbery.] and facet by type of crime:

```{r plot-crime-wday, dependson = "import-crimes"}
ggmap(chicago) +
  stat_density_2d(data = crimes %>%
                    filter(`Primary Type` %in% c("BURGLARY", "MOTOR VEHICLE THEFT",
                                                 "NARCOTICS", "ROBBERY")),
                  aes(x = Longitude,
                      y = Latitude,
                      fill = stat(level)),
                  alpha = .4,
                  bins = 10,
                  geom = "polygon") +
  scale_fill_gradientn(colors = brewer.pal(7, "YlOrRd")) +
  facet_wrap(~ `Primary Type`)
```

There is a large difference in the geographic density of narcotics crimes relative to the other catgories. While burglaries, motor vehicle thefts, and robberies are reasonably prevalent all across the city, the vast majority of narcotics crimes occur in the west and south sides of the city.

### Locations of murders

While `geom_point()` was not appropriate for graphing a large number of observations in a dense geographic location, it does work rather well for less dense areas. Now let's limit our analysis strictly to reported incidents of homicide in 2017.

```{r homicide, dependson = "import-crimes"}
(homicides <- crimes %>%
  filter(`Primary Type` == "HOMICIDE"))
```

We can draw a map of the city with all homicides indicated on the map using `geom_point()`:

```{r homicide-city, dependson = "homicide"}
ggmap(chicago) +
  geom_point(data = homicides,
             mapping = aes(x = Longitude,
                           y = Latitude),
             size = 1)
```

Compared to our previous overviews, few if any homicides are reported downtown. We can also narrow down the geographic location to map specific neighborhoods in Chicago. First we obtain map tiles for those specific regions. Here we'll examine North Lawndale and Kenwood.

```{r get-community-areas, include = FALSE}
library(sf)

# import shapefile with area names and numbers
areas <- here("data", "Boundaries - Community Areas (current)",
              "geo_export_328cdcbf-33ba-4997-8ce8-90953c6fec19.shp") %>%
  st_read()

crimes %>%
  filter(`Primary Type` == "HOMICIDE") %>%
  count(`Community Area`, sort = TRUE) %>%
  left_join(areas %>%
              select(community, area_numbe) %>%
              mutate(area_numbe = as.numeric(as.character(area_numbe))),
            by = c("Community Area" = "area_numbe"))
```

```{r get-high-low-murder-maps}
# North Lawndale is the highest homicides in 2017
# Compare to Kenwood
north_lawndale_bb <- c(
  left = -87.749047,
  bottom = 41.840185,
  right = -87.687893,
  top = 41.879850
)
north_lawndale <- get_stamenmap(bbox = north_lawndale_bb,
                                zoom = 14)

kenwood_bb <- c(
  left = -87.613113,
  bottom = 41.799215,
  right = -87.582536,
  top = 41.819064
)
kenwood <- get_stamenmap(bbox = kenwood_bb,
                                zoom = 15)

ggmap(north_lawndale)
ggmap(kenwood)
```

To plot homicides specifically in these neighborhoods, change `ggmap(chicago)` to the appropriate map tile:

```{r plot-murder, dependson = "homicide"}
ggmap(north_lawndale) +
  geom_point(data = homicides,
             aes(x = Longitude, y = Latitude))

ggmap(kenwood) +
  geom_point(data = homicides,
             aes(x = Longitude, y = Latitude))
```

North Lawndale had the most reported homicides in 2017, whereas Kenwood had only a handful. And even though `homicides` contained data for homicides across the entire city, `ggmap()` automatically cropped the graph to keep just the homicides that occurred within the bounding box.

All the other aesthetic customizations of `geom_point()` work with `ggmap`. So we could expand these neighborhood maps to include all violent crime categories^[Specifcally homicides, criminal sexual assault, and robbery. [Aggravated assault and aggravated robbery are also defined as violent crimes by the Chicago Police Departmant](http://gis.chicagopolice.org/clearmap_crime_sums/crime_types.html), but the coding system for this data set does not distinguish between ordinary and aggravated types of assault and robbery.] and distinguish each type by `color`:

```{r violent, dependson = "import-crimes"}
(violent <- crimes %>%
  filter(`Primary Type` %in% c("HOMICIDE",
                               "CRIM SEXUAL ASSAULT",
                               "ROBBERY")))
```

```{r plot-violent, dependson = "violent"}
ggmap(north_lawndale) +
  geom_point(data = violent,
             aes(x = Longitude, y = Latitude,
                 color = `Primary Type`)) +
  scale_color_brewer(type = "qual", palette = "Dark2")

ggmap(kenwood) +
  geom_point(data = violent,
             aes(x = Longitude, y = Latitude,
                 color = `Primary Type`)) +
  scale_color_brewer(type = "qual", palette = "Dark2")
```

## Exercise: Chicago 311 data

The city of Chicago has [an excellent data portal](https://data.cityofchicago.org/) publishing a large volume of public records. Here we'll look at a subset of the [311 service requests](https://data.cityofchicago.org/Service-Requests/311-Service-Requests/v6vf-nfxy). I used `RSocrata` and the data portal's [API](/notes/application-program-interface/) to retrieve a portion of the data set.

```{block2, type = "rmdnote", echo = TRUE}
Download the necessary data files for the following coding exercises using `usethis::use_course("css-data-mining-viz/geoviz")`.

```

```{r chi-311-raw, eval = FALSE, include = FALSE}
library(RSocrata)

# use API to get 311 complaints for dead animals and potholes
short_codes <- c("SGQ", "PHF")
short_codes_urls <- str_c("https://data.cityofchicago.org/resource/v6vf-nfxy.json?sr_short_code=", short_codes)

chi_311_full <- map_df(short_codes_urls, read.socrata) %>%
  as_tibble()

# clean up/shrink the dataset for class exercises
chi_311 <- chi_311_full %>%
  select(starts_with("sr"), created_date, community_area, ward, latitude, longitude) %>%
  mutate_at(.vars = vars(community_area, ward, latitude, longitude), as.numeric) %>%
  write_csv(here("data", "chi-311.csv"))
```

```{r chi-311}
chi_311 <- read_csv("data/chi-311.csv")
```

```{r chi-311-glimpse, dependson = "chi-311"}
glimpse(chi_311)
```

### Visualize the 311 data

1. Obtain map tiles using `ggmap` for the city of Chicago.

    <details> 
      <summary>Click for the solution</summary>
      <p>
    
    ```{r bb-chicago}
    # store bounding box coordinates
    chi_bb <- c(left = -87.936287,
                bottom = 41.679835,
                right = -87.447052,
                top = 42.000835)
    
    # retrieve bounding box
    chicago <- get_stamenmap(bbox = chi_bb,
                             zoom = 11)
    
    # plot the raster map
    ggmap(chicago)
    ```
        
      </p>
    </details>

1. Generate a scatterplot of complaints about potholes in streets.

    <details> 
      <summary>Click for the solution</summary>
      <p>
    
    ```{r potholes-point, dependson = c("chi-311", "bb-chicago")}
    # initialize map
    ggmap(chicago) +
      # add layer with scatterplot
      # use alpha to show density of points
      geom_point(data = filter(chi_311, sr_type == "Pothole in Street Complaint"),
                 mapping = aes(x = longitude,
                               y = latitude),
                 size = .25,
                 alpha = .05)
    ```
        
      </p>
    </details>

1. Generate a heatmap of complaints about potholes in streets. Do you see any unusual patterns or clusterings?

    <details> 
      <summary>Click for the solution</summary>
      <p>
    
    ```{r potholes-heatmap, dependson = c("chi-311", "bb-chicago")}
    # initialize the map
    ggmap(chicago) +
      # add the heatmap
      stat_density_2d(data = filter(chi_311, sr_type == "Pothole in Street Complaint"),
                      mapping = aes(x = longitude,
                                    y = latitude,
                                    fill = stat(level)),
                      alpha = .1,
                      bins = 50,
                      geom = "polygon") +
      # customize the color gradient
      scale_fill_gradientn(colors = brewer.pal(9, "YlOrRd"))
    ```
        
    Seems to be clustered on the north side. Also looks to occur along major arterial routes for commuting traffic. Makes sense because they receive the most wear and tear.
        
      </p>
    </details>

1. Obtain map tiles for Hyde Park.

    <details> 
      <summary>Click for the solution</summary>
      <p>
    
    ```{r bb-hyde-park}
    # store bounding box coordinates
    hp_bb <- c(left = -87.608221,
               bottom = 41.783249,
               right = -87.577643,
               top = 41.803038)
    
    # retrieve bounding box
    hyde_park <- get_stamenmap(bbox = hp_bb,
                               zoom = 15)
    
    # plot the raster map
    ggmap(hyde_park)
    ```
        
      </p>
    </details>

1. Generate a scatterplot of requests to pick up dead animals in Hyde Park.

    <details> 
      <summary>Click for the solution</summary>
      <p>
    
    ```{r dead-animals-point, dependson = c("chi-311", "bb-hyde-park")}
    # initialize the map
    ggmap(hyde_park) +
      # add a scatterplot layer
      geom_point(data = filter(chi_311, sr_type == "Dead Animal Pick-Up Request"),
                 mapping = aes(x = longitude,
                               y = latitude))
    ```
        
      </p>
    </details>

## Importing spatial data files using `sf`

Rather than storing spatial data as raster image files which are not easily modifiable, we can instead store spatial data  as **vector** files. Vector files store the underlying geographical features (e.g. points, lines, polygons) as numerical data which software such as R can import and use to draw a map.

There are [many popular file formats for storing spatial data.](https://en.wikipedia.org/wiki/GIS_file_formats#Popular_GIS_file_formats) Here we will look at two common file types, **shapefiles** and **GeoJSON**.

## File formats

### Shapefile

**Shapefiles** are a commonly supported file type for spatial data dating back to the early 1990s. Proprietary software for geographic information systems (GIS) such as [ArcGIS](https://www.esri.com/en-us/arcgis/about-arcgis/overview) pioneered this format and helps maintain its continued usage. A shapefile encodes points, lines, and polygons in geographic space, and is actually a set of files. Shapefiles appear with a `.shp` extension, sometimes with accompanying files ending in `.dbf` and `.prj`.

* `.shp` stores the geographic coordinates of the geographic features (e.g. country, state, county)
* `.dbf` stores data associated with the geographic features (e.g. unemployment rate, crime rates, percentage of votes cast for Donald Trump)
* `.prj` stores information about the projection of the coordinates in the shapefile

When importing a shapefile, you need to ensure all the files are in the same folder. For example, here is the structure of the [Census Bureau's 2013 state boundaries shapefile](https://www.census.gov/cgi-bin/geo/shapefiles/index.php):

```{r twee, include = FALSE}
# source: https://gist.github.com/jennybc/2bf1dbe6eb1f261dfe60

## quick-and-dirty ersatz Unix tree command in R
## inspired by this one-liner:
## ls -R | grep ":$" | sed -e 's/:$//' -e 's/[^-][^\/]*\//--/g' -e 's/^/   /' -e 's/-/|/'
## found here (among many other places):
## http://serverfault.com/questions/143954/how-to-generate-an-ascii-representation-of-a-unix-file-hierarchy

twee <- function(path = getwd(), level = Inf) {
  fad <-
    list.files(path = path, recursive = TRUE, no.. = TRUE, include.dirs = TRUE)

  fad_split_up <- strsplit(fad, "/")

  too_deep <- lapply(fad_split_up, length) > level
  fad_split_up[too_deep] <- NULL

  jfun <- function(x) {
    n <- length(x)
    if (n > 1) {
      x[n - 1] <- "|__"
    }
    if (n > 2) {
      x[1:(n - 2)] <- "   "
    }
    x <- if (n == 1) c("-- ", x) else c("   ", x)
    x
  }
  fad_subbed_out <- lapply(fad_split_up, jfun)

  cat(unlist(lapply(fad_subbed_out, paste, collapse = "")), sep = "\n")
}
```

```{r shapefile-str, echo = FALSE}
twee(path = here( "data", "census_bureau", "cb_2013_us_county_20m"))
```

**This is the complete shapefile.** If any of these files are missing, you will get an error importing your shapefile:

```
## Error in CPL_read_ogr(dsn, layer, query, as.character(options), quiet, : Open failed.
```

### GeoJSON

**GeoJSON** is a newer format for encoding a variety of geographical data structures using the **J**ava**S**cript **O**bject **N**otation (JSON) file format. JSON formatted data is frequently used in web development and services. We will explore it in more detail when we get to [collecting data from the web.](/notes/write-an-api-function/#intro-to-json-and-xml) An example of a GeoJSON file is below:

```json
{
  "type": "Feature",
  "geometry": {
    "type": "Point",
    "coordinates": [125.6, 10.1]
  },
  "properties": {
    "name": "Dinagat Islands"
  }
}
```

GeoJSON files are plain text files and can contain many different types of geometric features.

## Simple features

[There are a crap ton of packages for R that allow you to interact with shapefiles and spatial data.](https://cran.r-project.org/web/views/Spatial.html) Here we will focus on a modern package for reading and transforming spatial data in a tidy format. [Simple features](https://en.wikipedia.org/wiki/Simple_Features) or [**simple feature access**](http://www.opengeospatial.org/standards/sfa) refers to a formal standard that describes how objects in the real world can be represented in computers, with emphasis on the **spatial** geometry of these objects. It also describes how such objects can be stored in and retrieved from databases, and which geometrical operations should be defined for them.

The standard is widely implemented in spatial databases (such as PostGIS), commercial GIS (e.g., [ESRI ArcGIS](http://www.esri.com/)) and forms the vector data basis for libraries such as [GDAL](http://www.gdal.org/). A subset of simple features forms the [GeoJSON](http://geojson.org/) standard.

R has well-supported classes for storing spatial data ([`sp`](https://CRAN.R-project.org/package=sp)) and interfacing to the above mentioned environments ([`rgdal`](https://CRAN.R-project.org/package=rgdal), [`rgeos`](https://CRAN.R-project.org/package=rgeos)), but has so far lacked a complete implementation of simple features, making conversions at times convoluted, inefficient or incomplete. The [`sf`](http://github.com/r-spatial/sf) package tries to fill this gap.

### What is a feature?

A **feature** is a thing or an object in the real world. Often features will consist of a set of features. For instance, a tree can be a feature but a set of trees can form a forest which is itself a feature. Features have **geometry** describing where on Earth the feature is located. They also have attributes, which describe other properties of the feature.

### Dimensions

All geometries are composed of points. Points are coordinates in a 2-, 3- or 4-dimensional space. All points in a geometry have the same dimensionality. In addition to X and Y coordinates, there are two optional additional dimensions:

* a Z coordinate, denoting altitude
* an M coordinate (rarely used), denoting some **measure** that is associated with the point, rather than with the feature as a whole (in which case it would be a feature attribute); examples could be time of measurement, or measurement error of the coordinates

The four possible cases then are:

1. two-dimensional points refer to x and y, easting and northing, or longitude and latitude, we refer to them as XY
2. three-dimensional points as XYZ
3. three-dimensional points as XYM
4. four-dimensional points as XYZM (the third axis is Z, fourth M)

### Simple feature geometry types

The following seven simple feature types are the most common, and are for instance the only ones used for [GeoJSON](https://tools.ietf.org/html/rfc7946):

| type | description                                        |
| ---- | -------------------------------------------------- |
| `POINT` | zero-dimensional geometry containing a single point |
| `LINESTRING` | sequence of points connected by straight, non-self intersecting line pieces; one-dimensional geometry |
| `POLYGON` | geometry with a positive area (two-dimensional); sequence of points form a closed, non-self intersecting ring; the first ring denotes the exterior ring, zero or more subsequent rings denote holes in this exterior ring |
| `MULTIPOINT` | set of points; a MULTIPOINT is simple if no two Points in the MULTIPOINT are equal |
| `MULTILINESTRING` | set of linestrings |
| `MULTIPOLYGON` | set of polygons |
| `GEOMETRYCOLLECTION` | set of geometries of any type except GEOMETRYCOLLECTION |

### Coordinate reference system

Coordinates can only be placed on the Earth's surface when their coordinate reference system (CRS) is known; this may be an spheroid CRS such as WGS84, a projected, two-dimensional (Cartesian) CRS such as a UTM zone or Web Mercator, or a CRS in three-dimensions, or including time. Similarly, M-coordinates need an attribute reference system, e.g. a [measurement unit](https://CRAN.R-project.org/package=units).

## Simple features in R

`sf` stores simple features as basic R data structures (lists, matrix, vectors, etc.). The typical data structure stores geometric and feature attributes as a data frame with one row per feature. However since feature geometries are not single-valued, they are put in a **list-column** with each list element holding the simple feature geometry of that feature.

### Importing spatial data using `sf`

`st_read()` imports a spatial data file and converts it to a simple feature data frame. Here we import a shapefile containing the spatial boundaries of each [community area in the city of Chicago](https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Community-Areas-current-/cauq-8yn6).

```{r import-chi-sp}
chi_shape <- here("data/Boundaries - Community Areas (current)/geo_export_328cdcbf-33ba-4997-8ce8-90953c6fec19.shp") %>%
  st_read()
```

The short report printed gives the file name, mentions that there are `r nrow(chi_shape)` features (records, represented as rows) and `r ncol(chi_shape)` fields (attributes, represented as columns), states that the spatial data file is a `MULTIPOLYGON`, provides the bounding box coordinates, and identifies the projection method (which we will discuss later). If we print the first rows of `chi_shape`:

```{r chi-sp}
chi_shape
```

In the output we see:

* Each row is a simple feature: a single record, or `data.frame` row, consisting of attributes and geometry
* The `geometry` column is a simple feature list-column (an object of class `sfc`, which is a column in the `data.frame`)
* Each value in `geometry` is a single simple feature geometry (an object of class `sfg`)

We start to recognize the data frame structure. Substantively, `community` defines the name of the community area for each row.

`st_read()` also works with GeoJSON files.

```{r import-chi-json}
chi_json <- here("data/Boundaries - Community Areas (current).geojson") %>%
  st_read()
chi_json
```

## Drawing vector maps with `sf` and `ggplot2`

Unlike [raster image maps](/notes/raster-maps-with-ggmap/), vector maps require you to obtain [spatial data files](/notes/simple-features/) which contain detailed information necessary to draw all the components of a map (e.g. points, lines, polygons). Once you successfully import that data into R, `ggplot2` works with simple features data frames to easily generate geospatial visualizations using all the core elements and approaches of `ggplot()`.

### Import USA state boundaries

First we will import a spatial data file containing the boundaries of all 50 states in the United States^[Plus the District of Columbia and Puerto Rico] using `sf::st_read()`:

```{r import-usa}
usa <- here("data", "census_bureau",
            "cb_2013_us_state_20m", "cb_2013_us_state_20m.shp") %>%
  st_read()
```

### Draw the boundaries

`ggplot2` contains a geometric object specifically for simple feature objects called `geom_sf()`. This works reasonably well when you need to draw **polygons**, like our state boundaries. Support for simple features in `ggplot2` is under active development, so you may not find adequate support for plotting line or point features. To draw the map, we pass the simple features data frame as the `data` argument.

```{r geom-sf}
ggplot(data = usa) +
  geom_sf()
```

Because simple features data frames are standardized with the `geometry` column always containing information on the geographic coordinates of the features, we do not need to specify additional parameters for `aes()`. Notice a problem with the map above: it wastes a lot of space. This is caused by the presence of Alaska and Hawaii in the dataset. The Aleutian Islands cross the the 180th meridian, requiring the map to show the Eastern hemisphere. Likewise, Hawaii is substantially distant from the continental United States.

#### Plot a subset of a map

One solution is to plot just the lower 48 states. That is, exclude Alaska and Hawaii, as well as DC and Puerto Rico.^[Issues of political sovereignty aside, these entities are frequently excluded from maps depending on the data to be incorporated. You can always choose to leave them in the map.] Because simple features data frames contain one row per feature and in this example a feature is defined as a state, we can use `filter()` from `dplyr` to exclude these four states/territories.

```{r usa-subset}
(usa_48 <- usa %>%
  filter(!(NAME %in% c("Alaska", "District of Columbia", "Hawaii", "Puerto Rico"))))

ggplot(data = usa_48) +
  geom_sf()
```

Since the map is a `ggplot()` object, it can easily be modified like any other `ggplot()` graph. We could change the color of the map and the borders:

```{r usa-fill}
ggplot(data = usa_48) +
  geom_sf(fill = "palegreen", color = "black")
```

#### `albersusa`

Rather than excluding them entirely, most maps of the United States place Alaska and Hawaii as **insets** to the south of California. Until recently, in R this was an extremely tedious task that required manually changing the latitude and longitude coordinates for these states to place them in the correct location. Fortunately several packages are now available that have already done the work for you. [`albersusa`](https://github.com/hrbrmstr/albersusa) includes the `usa_sf()` function which returns a simple features data frame which contains adjusted coordinates for Alaska and Hawaii to plot them with the mainland. It can be installed from GitHub using `devtools::install_github("hrbrmstr/albersusa")`.

```{r albersusa}
library(albersusa)
usa_sf()

ggplot(data = usa_sf()) +
  geom_sf()
```

### Add data to the map

Region boundaries serve as the background in geospatial data visualization - so now we need to add data. Some types of geographic data (points and symbols) are overlaid on top of the boundaries, whereas other data (fill) are incorporated into the region layer itself.

#### Points

Let's use our `usa_48` map data to add some points. The `airports` data frame in the `nycflights13` package includes geographic info on airports in the United States.

```{r nycflights}
library(nycflights13)
airports
```

Each airport has it's geographic location encoded through `lat` and `lon`. To draw these points on the map, basically we draw a scatterplot with `x = lon` and `y = lat`. In fact we could simply do that:

```{r scatter}
ggplot(airports, aes(lon, lat)) +
  geom_point()
```

Let's overlay it with the mapped state borders:

```{r flights-usa}
ggplot(data = usa_48) + 
  geom_sf() + 
  geom_point(data = airports, aes(x = lon, y = lat), shape = 1)
```

Slight problem. We have airports listed outside of the continental United States. There are a couple ways to rectify this. Unfortunately `airports` does not include a variable identifying state so the `filter()` operation is not that simple. The easiest solution is to crop the limits of the graph using `coord_sf()` to only show the mainland:

```{r crop}
ggplot(data = usa_48) + 
  geom_sf() + 
  geom_point(data = airports, aes(x = lon, y = lat), shape = 1) +
  coord_sf(xlim = c(-130, -60),
           ylim = c(20, 50))
```

Alternatively, we can use `st_as_sf()` to convert `airports` to a simple features data frame.

```{r flights-sf}
airports_sf <- st_as_sf(airports, coords = c("lon", "lat"))
st_crs(airports_sf) <- 4326   # set the coordinate reference system
airports_sf
```

`coords` tells `st_as_sf()` which columns contain the geographic coordinates of each airport. To graph the points on the map, we use a second `geom_sf()`:

```{r flights-sf-plot}
ggplot() + 
  geom_sf(data = usa_48) + 
  geom_sf(data = airports_sf, shape = 1) +
  coord_sf(xlim = c(-130, -60),
           ylim = c(20, 50))
```

#### Symbols

We can change the size or type of symbols on the map. For instance, we can draw a **bubble plot** (also known as a **proportional symbol map**) and encode the altitude of the airport through the size channel:

```{r airport-alt}
ggplot(data = usa_48) + 
  geom_sf() + 
  geom_point(data = airports, aes(x = lon, y = lat, size = alt),
             fill = "grey", color = "black", alpha = .2) +
  coord_sf(xlim = c(-130, -60),
           ylim = c(20, 50)) +
  scale_size_area(guide = FALSE)
```

Circle area is proportional to the airport's altitude (in feet). Or we could scale it based on the number of arriving flights in `flights`:

```{r airport-dest}
airports_n <- flights %>%
  count(dest) %>%
  left_join(airports, by = c("dest" = "faa"))

ggplot(data = usa_48) + 
  geom_sf() + 
  geom_point(data = airports_n, aes(x = lon, y = lat, size = n),
             fill = "grey", color = "black", alpha = .2) +
  coord_sf(xlim = c(-130, -60),
           ylim = c(20, 50)) +
  scale_size_area(guide = FALSE)
```

```{block2, type = "rmdnote", echo = TRUE}
`airports` contains a list of virtually all commercial airports in the United States. However `flights` only contains data on flights departing from New York City airports (JFK, LaGuardia, or Newark) and only services a few airports around the country.

```

#### Fill (choropleths)

**Choropleth maps** encode information by assigning shades of colors to defined areas on a map (e.g. countries, states, counties, zip codes). There are lots of ways to tweak and customize these graphs, which is generally a good idea because remember that color is one of the harder-to-decode channels.

We will continue to use the `usa_48` simple features data frame and draw a choropleth for the number of foreign-born individuals in each state. We get those files from the `census_bureau` folder. Let's also normalize our measure by the total population to get the rate of foreign-born individuals in the population:

```{r import-foreign}
(fb_state <- here("data", "census_bureau",
                  "ACS_13_5YR_B05012_state", "ACS_13_5YR_B05012.csv") %>%
   read_csv() %>%
  mutate(rate = HD01_VD03 / HD01_VD01))
```

##### Join the data

Now that we have our data, we want to draw it on the map. `fb_state` contains one row per state, as does `usa_48`. Since there is a one-to-one match between the data frames, we join the data frames together first, then use that single data frame to draw the map. This differs from the approach above for drawing points because a point feature is not the same thing as a polygon feature. That is, there were more airports then there were states. Because the spatial data is stored in a data frame with one row per state, all we need to do is merge the data frames together on a column that uniquely identifies each row in each data frame.

```{r usa-foreign-join}
(usa_fb <- usa_48 %>%
  left_join(fb_state, by = c("STATEFP" = "GEO.id2")))
```

##### Draw the map

With the newly combined data frame, use `geom_sf()` and define the `fill` aesthetic based on the column in `usa_fb` you want to visualize.

```{r geom-map-state}
ggplot(data = usa_fb) +
  geom_sf(aes(fill = rate))
```

#### Bin data to discrete intervals

When creating a heatmap with a continuous variable, one must decide whether to keep the variable as continuous or collapse it into a series of bins with discrete colors. While keep the variable continuous is technically more precise, [the human eye cannot usually distinguish between two colors which are very similar to one another.](https://www.perceptualedge.com/articles/visual_business_intelligence/heatmaps_to_bin_or_not.pdf) By converting the variable to a discrete variable, you easily distinguish between the different levels. If you decide to convert a continuous variable to a discrete variable, you will need to decide how to do this. While `cut()` is a base R function for converting continuous variables into discrete values, `ggplot2` offers two functions that explicitly define how we want to bin the numeric vector (column).

`cut_interval()` makes `n` groups with equal range:

```{r cut-interval}
usa_fb %>%
  mutate(rate_cut = cut_interval(rate, n = 6)) %>%
  ggplot() +
  geom_sf(aes(fill = rate_cut))
```

Whereas `cut_number()` makes `n` groups with (approximately) equal numbers of observations:

```{r cut-number}
usa_fb %>%
  mutate(rate_cut = cut_number(rate, n = 6)) %>%
  ggplot() +
  geom_sf(aes(fill = rate_cut))
```

```{block2, type = "rmdnote", echo = TRUE}
See [this StackOverflow thread](https://gis.stackexchange.com/questions/86668/should-i-use-a-discrete-or-continuous-scale-for-coloring-a-chloropleth) for a more in-depth discussion on the merits of bucketizing a continuous variable and whether to use `cut_interval()` or `cut_number()`.

```

### Changing map projection

```{r west-wing, echo = FALSE}
knitr::include_url("https://www.youtube.com/embed/vVX-PrBRtTY")
```

```{r xkcd-mercator, echo = FALSE, fig.cap = "[Mercator Projection](https://xkcd.com/2082/)"}
knitr::include_graphics("https://imgs.xkcd.com/comics/mercator_projection.png")
```

Representing portions of the globe on a flat surface can be challenging. Depending on how you project the map, you can distort or emphasize certain features of the map. Fortunately, `ggplot()` includes the `coord_sf()` function which allows us to easily implement different projection methods. In order to implement coordinate transformations, you need to know the **coordinate reference system** that defines the projection method. The "easiest" approach is to provide what is known as the `proj4string` that defines the projection method. [PROJ4](https://proj4.org/) is a generic coordinate transformation software that allows you to convert between projection methods. If you get really into geospatial analysis and visualization, it is helpful to learn this system.

For our purposes here, `proj4string` is a character string in R that defines the coordinate system and includes parameters specific to a given coordinate transformation. PROJ4 includes [some documentation on common projection methods](https://proj4.org/operations/projections/index.html) that can get you started. Some projection methods are relatively simple and require just the name of the projection, like for a [Mercator projection](https://proj4.org/operations/projections/merc.html) (`"+proj=merc"`):

```{r projections}
map_proj_base <- ggplot(data = usa_48) +
  geom_sf()
```

```{r mercator-proj}
map_proj_base +
  coord_sf(crs = "+proj=merc") +
  ggtitle("Mercator projection")
```

Other coordinate systems require specification of the **standard lines**, or lines that define areas of the surface of the map that are tangent to the globe. These include [Gall-Peters](http://spatialreference.org/ref/sr-org/gall-peters-orthographic-projection/proj4/), [Albers equal-area](https://proj4.org/operations/projections/aea.html), and [Lambert azimuthal](https://proj4.org/operations/projections/laea.html).

```{r projection-rest}
map_proj_base +
  coord_sf(crs = "+proj=cea +lon_0=0 +lat_ts=45") +
  ggtitle("Gall-Peters projection")

map_proj_base +
  coord_sf(crs = "+proj=aea +lat_1=25 +lat_2=50 +lon_0=-100") +
  ggtitle("Albers equal-area projection")

map_proj_base +
  coord_sf(crs = "+proj=laea +lat_0=35 +lon_0=-100") +
  ggtitle("Lambert azimuthal projection")
```

## Practice drawing vector maps

### American Community Survey

The U.S. Census Bureau conducts the [American Community Survey](https://www.census.gov/programs-surveys/acs) which gathers detailed information on topics such as demographics, employment, educational attainment, etc. They make a vast portion of their data available through an [application programming interface (API)](/notes/application-program-interface/), which can be accessed intuitively through R via the [`tidycensus` package](https://walkerke.github.io/tidycensus/index.html). We previously discussed how to use this package to [obtain statistical data from the decennial census](/notes/application-program-interface/#census-data-with-tidycensus). However the Census Bureau also has detailed information on political and geographic boundaries which we can combine with their statistical measures to easily construct geospatial visualizations.

```{block2, type = "rmdalert", echo = TRUE}
If you have not already, [obtain an API key](https://api.census.gov/data/key_signup.html) and [store it securely](/notes/application-program-interface/#census-data-with-tidycensus) on your computer.

```

### Exercise: Visualize income data

1. Obtain information on median household income in 2017 for Cook County, IL at the tract-level using the ACS. To retrieve the geographic features for each tract, set `geometry = TRUE` in your function.

    > You can use `load_variables(year = 2017, dataset = "acs5")` to retrieve the list of variables available and search to find the correct variable name.

    <details> 
      <summary>Click for the solution</summary>
      <p>
    
    ```{r income-cook, results = "hide"}
    cook_inc <- get_acs(state = "IL",
                        county = "Cook",
                        geography = "tract", 
                        variables = c(medincome = "B19013_001"), 
                        year = 2017,
                        geometry = TRUE)
    ```
    
    ```{r income-cook-print, dependson = "income-cook"}
    cook_inc
    ```
        
      </p>
    </details>

1. Draw a choropleth using the median household income data. Use a continuous color gradient to identify each tract's median household income.

    <details> 
      <summary>Click for the solution</summary>
      <p>
    
    ```{r income-cook-map, dependson = "income-cook"}
    ggplot(data = cook_inc) +
      # use fill and color to avoid gray boundary lines
      geom_sf(aes(fill = estimate, color = estimate)) +
      # increase interpretability of graph
      scale_color_continuous(labels = scales::dollar) +
      scale_fill_continuous(labels = scales::dollar) +
      labs(title = "Median household income in Cook County, IL",
           subtitle = "In 2017",
           color = NULL,
           fill = NULL,
           caption = "Source: American Community Survey")
    ```
        
      </p>
    </details>

### Exercise: Customize your maps

1. Draw the same choropleth for Cook County, but convert median household income into a discrete variable with 6 levels.

    <details> 
      <summary>Click for the solution</summary>
      <p>
    
    * Using `cut_interval()`:
    
        ```{r cut-interval-cook, dependson = "income-cook"}
        cook_inc %>%
          mutate(inc_cut = cut_interval(estimate, n = 6)) %>%
          ggplot() +
          # use fill and color to avoid gray boundary lines
          geom_sf(aes(fill = inc_cut, color = inc_cut)) +
          # increase interpretability of graph
          labs(title = "Median household income in Cook County, IL",
               subtitle = "In 2017",
               color = NULL,
               fill = NULL,
               caption = "Source: American Community Survey")
        ```
            
    * Using `cut_number()`:
    
        ```{r cut-number-cook, dependson = "income-cook"}
        cook_inc %>%
          mutate(inc_cut = cut_number(estimate, n = 6)) %>%
          ggplot() +
          # use fill and color to avoid gray boundary lines
          geom_sf(aes(fill = inc_cut, color = inc_cut)) +
          # increase interpretability of graph
          labs(title = "Median household income in Cook County, IL",
               subtitle = "In 2017",
               color = NULL,
               fill = NULL,
               caption = "Source: American Community Survey")
        ```
            
      </p>
    </details>

1. Draw the same choropleth for Cook County using the discrete variable, but select an appropriate color palette using [Color Brewer](/notes/optimal-color-palettes/#color-brewer).

    <details> 
      <summary>Click for the solution</summary>
      <p>
    
    * Using `cut_interval()` and the Blue-Green palette:
    
        ```{r cut-interval-optimal, dependson = "income-cook"}
        cook_inc %>%
          mutate(inc_cut = cut_interval(estimate, n = 6)) %>%
          ggplot() +
          # use fill and color to avoid gray boundary lines
          geom_sf(aes(fill = inc_cut, color = inc_cut)) +
          scale_fill_brewer(type = "seq", palette = "BuGn") +
          scale_color_brewer(type = "seq", palette = "BuGn") +
          # increase interpretability of graph
          labs(title = "Median household income in Cook County, IL",
               subtitle = "In 2017",
               color = NULL,
               fill = NULL,
               caption = "Source: American Community Survey")
        ```
        
    * Using `cut_number()` and the Blue-Green palette:
    
        ```{r cut-number-optimal, dependson = "income-cook"}
        cook_inc %>%
          mutate(inc_cut = cut_number(estimate, n = 6)) %>%
          ggplot() +
          # use fill and color to avoid gray boundary lines
          geom_sf(aes(fill = inc_cut, color = inc_cut)) +
          scale_fill_brewer(type = "seq", palette = "BuGn") +
          scale_color_brewer(type = "seq", palette = "BuGn") +
         # increase interpretability of graph
          labs(title = "Median household income in Cook County, IL",
               subtitle = "In 2017",
               color = NULL,
               fill = NULL,
               caption = "Source: American Community Survey")
        ```
        
        
    You can choose any palette that is for sequential data.
    
      </p>
    </details>

1. Use the [`viridis` color palette](/notes/optimal-color-palettes/#viridis) for the Cook County map drawn using the continuous measure.

    <details> 
      <summary>Click for the solution</summary>
      <p>
    
    ```{r income-cook-map-viridis, dependson = "income-cook"}
    ggplot(data = cook_inc) +
      # use fill and color to avoid gray boundary lines
      geom_sf(aes(fill = estimate, color = estimate)) +
      # increase interpretability of graph
      scale_color_viridis(labels = scales::dollar) +
      scale_fill_viridis(labels = scales::dollar) +
      labs(title = "Median household income in Cook County, IL",
           subtitle = "In 2017",
           color = NULL,
           fill = NULL,
           caption = "Source: American Community Survey")
    ```
        
      </p>
    </details>
 
## Selecting optimal color palettes

Selection of your **color palette** is perhaps the most important decision to make when drawing a choropleth. By default, `ggplot2` picks evenly spaced hues around the [Hue-Chroma-Luminance (HCL) color space](https://en.wikipedia.org/wiki/HCL_color_space):^[Check out chapter 6.6.2 in *`ggplot2`: Elegant Graphics for Data Analysis* for a much more thorough explanation of the theory behind this selection process]

```{r color-wheel, echo = FALSE}
# generate simulated data points
sim_points <- tibble(x = factor(1:6))

plots <- purrr::map(1:6, ~ ggplot(sim_points[1:.x, ], aes(x, x, color = x)) +
  geom_point(size = 5) +
    ggtitle(paste(.x, "color")) +
  theme(legend.position = "none"))

wrap_plots(plots)
```

`ggplot2` gives you many different ways of defining and customizing your `scale_color_` and `scale_fill_` palettes, but will not tell you if they are optimal for your specific usage in the graph.

### Color Brewer

```{r get-maps, include = FALSE}
# get national median household income
usa_inc <- get_acs(geography = "us", 
                   variables = c(medincome = "B19013_001"), 
                   year = 2016) %>%
  .$estimate %>%
  nth(1)

# get state-level median household income and region
state_inc <- get_acs(geography = "state", 
                     variables = c(medincome = "B19013_001"), 
                     year = 2016,
                     geometry = TRUE) %>%
  # remove alaska, hawaii, and puerto rico
  filter(!(NAME %in% c("Alaska", "Hawaii", "Puerto Rico"))) %>%
  # calculate diff from national income
  mutate(estimate_div = estimate - usa_inc)

# get state-level region
state_region <- get_decennial(geography = "state", 
                              variables = c(region = "REGION"), 
                              year = 2010,
                              geometry = TRUE) %>%
  # remove alaska, hawaii, and puerto rico
  filter(!(NAME %in% c("Alaska", "Hawaii", "Puerto Rico"))) %>%
  mutate(value = factor(value, labels = c("Northeast", "Midwest", "South", "West")))
```

[Color Brewer](http://colorbrewer2.org/) is a diagnostic tool for selecting optimal color palettes for maps with discrete variables. The authors have generated different color palettes designed to make differentiating between categories easy depending on the scaling of your variable. All you need to do is define the number of categories in the variable, the nature of your data (sequential, diverging, or qualitative), and a color scheme. There are also options to select palettes that are colorblind safe, print friendly, and photocopy safe. Depending on the combination of options, you may not find any color palette that matches your criteria. In such a case, consider reducing the number of data classes.

#### Sequential

Sequential palettes work best with ordered data that progresses from a low to high value.

```{r cb-seq}
display.brewer.all(type = "seq")
```

```{r cb-seq-map, echo = FALSE}
cut_interval_format <- function(x, n = NULL, length = NULL, ...) {
  kimisc::cut_format(x, ggplot2:::breaks(x, "width", n, length), include.lowest = TRUE, 
      ...)
}

seq_plot <- state_inc %>%
  mutate(estimate_cut = cut_interval_format(estimate, 6, dig.lab = 5,
                                            format_fun = scales::dollar)) %>%
  ggplot() +
  geom_sf(aes(fill = estimate_cut)) +
  labs(title = "Median household income, 2016",
       caption = "Source: 2016 American Community Survey",
       fill = NULL)

seq_plot +
  scale_fill_brewer(palette = "Blues") +
  labs(subtitle = "Palette: Blues")
seq_plot +
  scale_fill_brewer(palette = "BuGn") +
  labs(subtitle = "Palette: BuGn")
seq_plot +
  scale_fill_brewer(palette = "YlGn") +
  labs(subtitle = "Palette: YlGn")
```

#### Diverging

Diverging palettes work for variables with meaningful mid-range values, as well as extreme low and high values.

```{r cb-div}
display.brewer.all(type = "div")
```

```{r cb-div-map, echo = FALSE}
div_plot <- state_inc %>%
  mutate(estimate_div_cut = cut_interval_format(estimate_div, 6, dig.lab = 5,
                                                format_fun = scales::dollar)) %>%
  ggplot() +
  geom_sf(aes(fill = estimate_div_cut)) +
  labs(title = "Difference from national median household income, 2016",
       caption = "Source: 2016 American Community Survey",
       fill = NULL)
div_plot +
  scale_fill_brewer(palette = "PiYG") +
  labs(subtitle = "Palette: PiYG")
div_plot +
  scale_fill_brewer(palette = "RdBu") +
  labs(subtitle = "Palette: RdBu")
div_plot +
  scale_fill_brewer(palette = "Spectral") +
  labs(subtitle = "Palette: Spectral")
```

#### Qualitative

Qualitative palettes are best used for nominal data where there is no inherent ordering to the categories.

```{r cb-qual}
display.brewer.all(type = "qual")
```

```{r cb-qual-map, echo = FALSE}
qual_plot <- state_region %>%
  ggplot() +
  geom_sf(aes(fill = value)) +
  labs(title = "Census region",
       caption = "Source: 2010 US decennial census",
       fill = NULL)
qual_plot +
  scale_fill_brewer(palette = "Accent") +
  labs(subtitle = "Palette: Accent")
qual_plot +
  scale_fill_brewer(palette = "Paired") +
  labs(subtitle = "Palette: Paired")
qual_plot +
  scale_fill_brewer(palette = "Set1") +
  labs(subtitle = "Palette: Set1")
```

### Viridis

The [`viridis`](https://cran.r-project.org/web/packages/viridis/) package imports several color palettes for continuous variables from the `matplotlib` package in Python. These palettes have been tested to be colorful, perceptually uniform, robust to colorblindness, and pretty. To use these with `ggplot2`, use `scale_color_viridis()` and `scale_fill_viridis()`:

```{r viridis}
library(viridis)

viridis_base <- ggplot(state_inc) +
  geom_sf(aes(fill = estimate)) +
  labs(title = "Median household income, 2016",
       subtitle = "Palette: viridis",
       caption = "Source: 2016 American Community Survey",
       fill = NULL) +
  scale_fill_viridis(labels = scales::dollar)

viridis_base
viridis_base +
  scale_fill_viridis(option = "cividis", labels = scales::dollar) +
  labs(subtitle = "Palette: cividis")
viridis_base +
  scale_fill_viridis(option = "inferno", labels = scales::dollar) +
  labs(subtitle = "Palette: inferno")
viridis_base +
  scale_fill_viridis(option = "magma", labels = scales::dollar) +
  labs(subtitle = "Palette: magma")
viridis_base +
  scale_fill_viridis(option = "plasma", labels = scales::dollar) +
  labs(subtitle = "Palette: plasma")
```

## Session info {-}

```{r}
devtools::session_info()
```
